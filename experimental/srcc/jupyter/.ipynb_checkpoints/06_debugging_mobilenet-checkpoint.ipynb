{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2651cff-fc55-484f-8c1b-f5bb9183afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a2784d-6a54-43be-a957-2920bfc81778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from habitat.config import Config as CN\n",
    "from habitat.utils.visualizations.utils import images_to_video, observations_to_image\n",
    "\n",
    "from habitat_baselines.common.baseline_registry import baseline_registry\n",
    "from habitat_baselines.common.environments import get_env_class, NavRLEnv\n",
    "from habitat_baselines.config.default import get_config\n",
    "from habitat_baselines.utils.common import batch_obs, generate_video\n",
    "from habitat_baselines.utils.env_utils import construct_envs\n",
    "\n",
    "import inspect\n",
    "import path_utils\n",
    "path_utils.add_path_to_sys_path(\"../python\", mode=\"relative_to_cwd\", frame=inspect.currentframe())\n",
    "\n",
    "from my_habitat_baselines.resnet_policy import PointNavResNetPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bb63ca-9eb0-492b-81d2-cc1c7aafbc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jupyter_dir = \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter\"\n",
    "\n",
    "jupyter_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb19fbcc-7a15-41d1-ba2a-a20deb996649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "habitat_gibson_val\n",
      "challenge_sim\n",
      "0.0\n",
      "depth_train_sliding_off_train_noise_multiplier_1.0\n",
      "depth\n",
      "/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/job_19633842.sensor_DEPTH_SENSOR.train_data_gibson.noise_multiplier_1.0.noise_model_controller_Proportional.agent_radius_0.20.success_reward_10.0.slack_reward_-0.01.collision_reward_0.0.spl_max_collisions_500_ckpt.000000057.pth\n"
     ]
    }
   ],
   "source": [
    "sim_name                  = \"habitat_gibson_val\"\n",
    "sim_eval_mode             = \"challenge_sim\"\n",
    "sim_eval_noise_multiplier = 0.0\n",
    "\n",
    "# model_name = \"rgb_train_sliding_on_train_noise_multiplier_0.0\"\n",
    "# model_type = \"rgb\"\n",
    "# model_path = \\\n",
    "#     \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "#     \"job_19888270\"                        + \".\" \\\n",
    "#     \"sensor_RGB_SENSOR\"                   + \".\" \\\n",
    "#     \"train_data_gibson\"                   + \".\" \\\n",
    "#     \"noise_multiplier_0.0\"                + \".\" \\\n",
    "#     \"noise_model_controller_Proportional\" + \".\" \\\n",
    "#     \"agent_radius_0.20\"                   + \".\" \\\n",
    "#     \"success_reward_10.0\"                 + \".\" \\\n",
    "#     \"slack_reward_-0.01\"                  + \".\" \\\n",
    "#     \"collision_reward_0.0\"                + \".\" \\\n",
    "#     \"spl_max_collisions_500\"              + \"_\" \\\n",
    "#     \"ckpt.000000055\"                      + \\\n",
    "#     \".pth\"\n",
    "\n",
    "# model_name = \"rgb_train_sliding_off_train_noise_multiplier_0.5\"\n",
    "# model_type = \"rgb\"\n",
    "# model_path = \\\n",
    "# \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "# \"job_19633792\"                        + \".\" \\\n",
    "# \"sensor_RGB_SENSOR\"                   + \".\" \\\n",
    "# \"train_data_gibson\"                   + \".\" \\\n",
    "# \"noise_multiplier_0.5\"                + \".\" \\\n",
    "# \"noise_model_controller_Proportional\" + \".\" \\\n",
    "# \"agent_radius_0.20\"                   + \".\" \\\n",
    "# \"success_reward_10.0\"                 + \".\" \\\n",
    "# \"slack_reward_-0.01\"                  + \".\" \\\n",
    "# \"collision_reward_0.0\"                + \".\" \\\n",
    "# \"spl_max_collisions_500\"              + \"_\" \\\n",
    "# \"ckpt.000000049\"                      + \\\n",
    "# \".pth\"\n",
    "\n",
    "# model_name = \"rgb_train_sliding_off_train_noise_multiplier_1.0\"\n",
    "# model_type = \"rgb\"\n",
    "# model_path = \\\n",
    "# \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "# \"job_19633834\"                        + \".\" \\\n",
    "# \"sensor_RGB_SENSOR\"                   + \".\" \\\n",
    "# \"train_data_gibson\"                   + \".\" \\\n",
    "# \"noise_multiplier_1.0\"                + \".\" \\\n",
    "# \"noise_model_controller_Proportional\" + \".\" \\\n",
    "# \"agent_radius_0.20\"                   + \".\" \\\n",
    "# \"success_reward_10.0\"                 + \".\" \\\n",
    "# \"slack_reward_-0.01\"                  + \".\" \\\n",
    "# \"collision_reward_0.0\"                + \".\" \\\n",
    "# \"spl_max_collisions_500\"              + \"_\" \\\n",
    "# \"ckpt.000000051\"                      + \\\n",
    "# \".pth\"\n",
    "\n",
    "# model_name = \"depth_train_sliding_on_train_noise_multiplier_0.0\"\n",
    "# model_type = \"depth\"\n",
    "# model_path = \\\n",
    "# \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "# \"job_19888281\"                        + \".\" \\\n",
    "# \"sensor_DEPTH_SENSOR\"                 + \".\" \\\n",
    "# \"train_data_gibson\"                   + \".\" \\\n",
    "# \"noise_multiplier_0.0\"                + \".\" \\\n",
    "# \"noise_model_controller_Proportional\" + \".\" \\\n",
    "# \"agent_radius_0.20\"                   + \".\" \\\n",
    "# \"success_reward_10.0\"                 + \".\" \\\n",
    "# \"slack_reward_-0.01\"                  + \".\" \\\n",
    "# \"collision_reward_0.0\"                + \".\" \\\n",
    "# \"spl_max_collisions_500\"              + \"_\" \\\n",
    "# \"ckpt.000000047\"                      + \\\n",
    "# \".pth\"\n",
    "\n",
    "# model_name = \"depth_train_sliding_off_train_noise_multiplier_0.5\"\n",
    "# model_type = \"depth\"\n",
    "# model_path = \\\n",
    "# \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "# \"job_19633798\"                        + \".\" \\\n",
    "# \"sensor_DEPTH_SENSOR\"                 + \".\" \\\n",
    "# \"train_data_gibson\"                   + \".\" \\\n",
    "# \"noise_multiplier_0.5\"                + \".\" \\\n",
    "# \"noise_model_controller_Proportional\" + \".\" \\\n",
    "# \"agent_radius_0.20\"                   + \".\" \\\n",
    "# \"success_reward_10.0\"                 + \".\" \\\n",
    "# \"slack_reward_-0.01\"                  + \".\" \\\n",
    "# \"collision_reward_0.0\"                + \".\" \\\n",
    "# \"spl_max_collisions_500\"              + \"_\" \\\n",
    "# \"ckpt.000000059\"                      + \\\n",
    "# \".pth\"\n",
    "\n",
    "# model_name = \"depth_train_sliding_off_train_noise_multiplier_1.0\"\n",
    "# model_type = \"depth\"\n",
    "# model_path = \\\n",
    "# \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "# \"job_19633842\"                        + \".\" \\\n",
    "# \"sensor_DEPTH_SENSOR\"                 + \".\" \\\n",
    "# \"train_data_gibson\"                   + \".\" \\\n",
    "# \"noise_multiplier_1.0\"                + \".\" \\\n",
    "# \"noise_model_controller_Proportional\" + \".\" \\\n",
    "# \"agent_radius_0.20\"                   + \".\" \\\n",
    "# \"success_reward_10.0\"                 + \".\" \\\n",
    "# \"slack_reward_-0.01\"                  + \".\" \\\n",
    "# \"collision_reward_0.0\"                + \".\" \\\n",
    "# \"spl_max_collisions_500\"              + \"_\" \\\n",
    "# \"ckpt.000000057\"                      + \\\n",
    "# \".pth\"\n",
    "\n",
    "print(sim_name)\n",
    "print(sim_eval_mode)\n",
    "print(sim_eval_noise_multiplier)\n",
    "print(model_name)\n",
    "print(model_type)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41618d93-9236-4fdf-876a-2f5281cd2599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(backbone='resnet50', hidden_size=512, model_path='/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/job_19633842.sensor_DEPTH_SENSOR.train_data_gibson.noise_multiplier_1.0.noise_model_controller_Proportional.agent_radius_0.20.success_reward_10.0.slack_reward_-0.01.collision_reward_0.0.spl_max_collisions_500_ckpt.000000057.pth', normalize_visual_inputs=0, num_recurrent_layers=2, opts=['TEST_EPISODE_COUNT', '5', 'TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER', 'Proportional', 'TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV', '45', 'TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV', '45', 'TASK_CONFIG.SIMULATOR.TURN_ANGLE', '30', 'TASK_CONFIG.SIMULATOR.AGENT_0.RADIUS', '0.20', 'TASK_CONFIG.DATASET.DATA_PATH', 'obstacle_1/{split}/{split}.json.gz', 'TASK_CONFIG.DATASET.SPLIT', 'minival', 'TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY', 'False', 'TASK_CONFIG.SIMULATOR.RGB_SENSOR.POSITION', '[0,0.6096,0]', 'TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.POSITION', '[0,0.6096,0]', 'VIDEO_OPTION', \"['disk']\", 'TASK_CONFIG.TASK.TOP_DOWN_MAP.MAP_RESOLUTION', '5000', 'TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER', '0.0'], sensors='DEPTH_SENSOR')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# specify args\n",
    "#\n",
    "\n",
    "arg_string = \"\"\n",
    "arg_string += \"--model-path %s\" % model_path\n",
    "\n",
    "if model_type == \"rgb\" or model_type == \"estimated_depth\":\n",
    "    arg_string += \" --sensors RGB_SENSOR\"\n",
    "    arg_string += \" --normalize-visual-inputs 1\"\n",
    "elif model_type == \"depth\":\n",
    "    arg_string += \" --sensors DEPTH_SENSOR\"\n",
    "    arg_string += \" --normalize-visual-inputs 0\"\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "arg_string += \\\n",
    "\"\"\"\n",
    "--hidden-size 512\n",
    "--backbone resnet50\n",
    "--num-recurrent-layers 2\n",
    "TEST_EPISODE_COUNT 5\n",
    "TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER Proportional\n",
    "TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV 45\n",
    "TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV 45\n",
    "TASK_CONFIG.SIMULATOR.TURN_ANGLE 30\n",
    "TASK_CONFIG.SIMULATOR.AGENT_0.RADIUS 0.20\n",
    "TASK_CONFIG.DATASET.DATA_PATH obstacle_1/{split}/{split}.json.gz\n",
    "TASK_CONFIG.DATASET.SPLIT minival\n",
    "TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY False\n",
    "TASK_CONFIG.SIMULATOR.RGB_SENSOR.POSITION [0,0.6096,0]\n",
    "TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.POSITION [0,0.6096,0]\n",
    "VIDEO_OPTION ['disk']\n",
    "TASK_CONFIG.TASK.TOP_DOWN_MAP.MAP_RESOLUTION 5000\n",
    "\"\"\"\n",
    "\n",
    "arg_string += \"TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER \" + str(sim_eval_noise_multiplier)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model-path\", type=str, required=True)\n",
    "parser.add_argument(\"--sensors\", type=str, required=True)\n",
    "parser.add_argument(\"--hidden-size\", type=int, required=True)\n",
    "parser.add_argument(\n",
    "    \"--normalize-visual-inputs\", type=int, required=True, choices=[0, 1]\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--backbone\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    choices=[\"resnet50\", \"se_resneXt50\"],\n",
    ")\n",
    "parser.add_argument(\"--num-recurrent-layers\", type=int, required=True)\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    "    help=\"Modify config options from command line\",\n",
    ")\n",
    "args = parser.parse_args(arg_string.split())\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef3a949-a4c3-49ba-b2a6-f6612e4faf06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_TASK_CONFIG_PATH: configs/tasks/pointnav_gibson.yaml\n",
      "CHECKPOINT_FOLDER: data/new_checkpoints\n",
      "CHECKPOINT_INTERVAL: -1\n",
      "CMD_TRAILING_OPTS: []\n",
      "ENV_NAME: NavRLEnv\n",
      "EVAL:\n",
      "  SPLIT: val\n",
      "  USE_CKPT_CONFIG: True\n",
      "EVAL_CKPT_PATH_DIR: data/new_checkpoints\n",
      "FORCE_BLIND_POLICY: False\n",
      "FORCE_TORCH_SINGLE_THREADED: True\n",
      "LOG_FILE: train.log\n",
      "LOG_INTERVAL: 25\n",
      "NUM_CHECKPOINTS: 100\n",
      "NUM_ENVIRONMENTS: 1\n",
      "NUM_PROCESSES: -1\n",
      "NUM_UPDATES: 10000\n",
      "ORBSLAM2:\n",
      "  ANGLE_TH: 0.2617993877991494\n",
      "  BETA: 100\n",
      "  CAMERA_HEIGHT: 1.25\n",
      "  DEPTH_DENORM: 10.0\n",
      "  DIST_REACHED_TH: 0.15\n",
      "  DIST_TO_STOP: 0.05\n",
      "  D_OBSTACLE_MAX: 4.0\n",
      "  D_OBSTACLE_MIN: 0.1\n",
      "  H_OBSTACLE_MAX: 1.25\n",
      "  H_OBSTACLE_MIN: 0.375\n",
      "  MAP_CELL_SIZE: 0.1\n",
      "  MAP_SIZE: 40\n",
      "  MIN_PTS_IN_OBSTACLE: 320.0\n",
      "  NEXT_WAYPOINT_TH: 0.5\n",
      "  NUM_ACTIONS: 3\n",
      "  PLANNER_MAX_STEPS: 500\n",
      "  PREPROCESS_MAP: True\n",
      "  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml\n",
      "  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt\n",
      "PROFILING:\n",
      "  CAPTURE_START_STEP: -1\n",
      "  NUM_STEPS_TO_CAPTURE: -1\n",
      "RL:\n",
      "  DDPPO:\n",
      "    backbone: resnet18\n",
      "    distrib_backend: GLOO\n",
      "    force_distributed: False\n",
      "    num_recurrent_layers: 1\n",
      "    pretrained: False\n",
      "    pretrained_encoder: False\n",
      "    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth\n",
      "    reset_critic: True\n",
      "    rnn_type: GRU\n",
      "    sync_frac: 0.6\n",
      "    train_encoder: True\n",
      "  POLICY:\n",
      "    ACTION_DIST:\n",
      "      action_activation: tanh\n",
      "      max_log_std: 2\n",
      "      max_std: 1\n",
      "      min_log_std: -5\n",
      "      min_std: 1e-06\n",
      "      use_log_std: False\n",
      "      use_softplus: False\n",
      "    OBS_TRANSFORMS:\n",
      "      CENTER_CROPPER:\n",
      "        HEIGHT: 256\n",
      "        WIDTH: 256\n",
      "      CUBE2EQ:\n",
      "        HEIGHT: 256\n",
      "        SENSOR_UUIDS: []\n",
      "        WIDTH: 512\n",
      "      CUBE2FISH:\n",
      "        FOV: 180\n",
      "        HEIGHT: 256\n",
      "        PARAMS: (0.2, 0.2, 0.2)\n",
      "        SENSOR_UUIDS: []\n",
      "        WIDTH: 256\n",
      "      ENABLED_TRANSFORMS: ()\n",
      "      EQ2CUBE:\n",
      "        HEIGHT: 256\n",
      "        SENSOR_UUIDS: []\n",
      "        WIDTH: 256\n",
      "      RESIZE_SHORTEST_EDGE:\n",
      "        SIZE: 256\n",
      "    action_distribution_type: categorical\n",
      "    name: PointNavResNetPolicy\n",
      "  PPO:\n",
      "    clip_param: 0.2\n",
      "    entropy_coef: 0.01\n",
      "    eps: 1e-05\n",
      "    gamma: 0.99\n",
      "    hidden_size: 512\n",
      "    lr: 0.00025\n",
      "    max_grad_norm: 0.5\n",
      "    num_mini_batch: 2\n",
      "    num_steps: 128\n",
      "    ppo_epoch: 4\n",
      "    reward_window_size: 50\n",
      "    tau: 0.95\n",
      "    use_double_buffered_sampler: False\n",
      "    use_gae: True\n",
      "    use_linear_clip_decay: True\n",
      "    use_linear_lr_decay: True\n",
      "    use_normalized_advantage: False\n",
      "    value_loss_coef: 0.5\n",
      "  REWARD_MEASURE: distance_to_goal\n",
      "  SLACK_REWARD: -0.01\n",
      "  SUCCESS_MEASURE: spl\n",
      "  SUCCESS_REWARD: 2.5\n",
      "  preemption:\n",
      "    append_slurm_job_id: False\n",
      "    save_resume_state_interval: 100\n",
      "    save_state_batch_only: False\n",
      "SENSORS: ['DEPTH_SENSOR']\n",
      "SIMULATOR_GPU_ID: 0\n",
      "TASK_CONFIG:\n",
      "  DATASET:\n",
      "    CONTENT_SCENES: ['*']\n",
      "    DATA_PATH: data/datasets/pointnav/gibson/v2/val/val.json.gz\n",
      "    SCENES_DIR: data/scene_datasets\n",
      "    SPLIT: minival\n",
      "    TYPE: PointNav-v1\n",
      "  ENVIRONMENT:\n",
      "    GENERATE_ON_FLY: False\n",
      "    ITERATOR_OPTIONS:\n",
      "      CYCLE: True\n",
      "      GROUP_BY_SCENE: True\n",
      "      MAX_SCENE_REPEAT_EPISODES: -1\n",
      "      MAX_SCENE_REPEAT_STEPS: 10000\n",
      "      NUM_EPISODE_SAMPLE: -1\n",
      "      SHUFFLE: False\n",
      "      STEP_REPETITION_RANGE: 0.2\n",
      "    MAX_EPISODE_SECONDS: 10000000\n",
      "    MAX_EPISODE_STEPS: 500\n",
      "  PYROBOT:\n",
      "    BASE_CONTROLLER: proportional\n",
      "    BASE_PLANNER: none\n",
      "    BUMP_SENSOR:\n",
      "      TYPE: PyRobotBumpSensor\n",
      "    DEPTH_SENSOR:\n",
      "      CENTER_CROP: False\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 5.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      TYPE: PyRobotDepthSensor\n",
      "      WIDTH: 640\n",
      "    LOCOBOT:\n",
      "      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']\n",
      "      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']\n",
      "      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']\n",
      "    RGB_SENSOR:\n",
      "      CENTER_CROP: False\n",
      "      HEIGHT: 480\n",
      "      TYPE: PyRobotRGBSensor\n",
      "      WIDTH: 640\n",
      "    ROBOT: locobot\n",
      "    ROBOTS: ['locobot']\n",
      "    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']\n",
      "  SEED: 100\n",
      "  SIMULATOR:\n",
      "    ACTION_SPACE_CONFIG: v0\n",
      "    AGENTS: ['AGENT_0']\n",
      "    AGENT_0:\n",
      "      HEIGHT: 1.5\n",
      "      IS_SET_START_STATE: False\n",
      "      RADIUS: 0.2\n",
      "      SENSORS: ['DEPTH_SENSOR']\n",
      "      START_POSITION: [0, 0, 0]\n",
      "      START_ROTATION: [0, 0, 0, 1]\n",
      "    ARM_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      UUID: robot_arm_depth\n",
      "      WIDTH: 640\n",
      "    ARM_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      UUID: robot_arm_rgb\n",
      "      WIDTH: 640\n",
      "    DEFAULT_AGENT_ID: 0\n",
      "    DEPTH_SENSOR:\n",
      "      HEIGHT: 256\n",
      "      HFOV: 45\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 0.6096, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      WIDTH: 256\n",
      "    EQUIRECT_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      TYPE: HabitatSimEquirectangularDepthSensor\n",
      "      WIDTH: 640\n",
      "    EQUIRECT_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      TYPE: HabitatSimEquirectangularRGBSensor\n",
      "      WIDTH: 640\n",
      "    EQUIRECT_SEMANTIC_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      TYPE: HabitatSimEquirectangularSemanticSensor\n",
      "      WIDTH: 640\n",
      "    FISHEYE_DEPTH_SENSOR:\n",
      "      ALPHA: 0.57\n",
      "      FOCAL_LENGTH: [364.84, 364.86]\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      PRINCIPAL_POINT_OFFSET: None\n",
      "      SENSOR_MODEL_TYPE: DOUBLE_SPHERE\n",
      "      TYPE: HabitatSimFisheyeDepthSensor\n",
      "      WIDTH: 640\n",
      "      XI: -0.27\n",
      "    FISHEYE_RGB_SENSOR:\n",
      "      ALPHA: 0.57\n",
      "      FOCAL_LENGTH: [364.84, 364.86]\n",
      "      HEIGHT: 640\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      PRINCIPAL_POINT_OFFSET: None\n",
      "      SENSOR_MODEL_TYPE: DOUBLE_SPHERE\n",
      "      TYPE: HabitatSimFisheyeRGBSensor\n",
      "      WIDTH: 640\n",
      "      XI: -0.27\n",
      "    FISHEYE_SEMANTIC_SENSOR:\n",
      "      ALPHA: 0.57\n",
      "      FOCAL_LENGTH: [364.84, 364.86]\n",
      "      HEIGHT: 640\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      PRINCIPAL_POINT_OFFSET: None\n",
      "      SENSOR_MODEL_TYPE: DOUBLE_SPHERE\n",
      "      TYPE: HabitatSimFisheyeSemanticSensor\n",
      "      WIDTH: 640\n",
      "      XI: -0.27\n",
      "    FORWARD_STEP_SIZE: 0.25\n",
      "    HABITAT_SIM_V0:\n",
      "      ALLOW_SLIDING: True\n",
      "      ENABLE_PHYSICS: False\n",
      "      GPU_DEVICE_ID: 0\n",
      "      GPU_GPU: False\n",
      "      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json\n",
      "    HEAD_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      UUID: robot_head_depth\n",
      "      WIDTH: 640\n",
      "    HEAD_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      UUID: robot_head_rgb\n",
      "      WIDTH: 640\n",
      "    NOISE_MODEL:\n",
      "      CONTROLLER: Proportional\n",
      "      NOISE_MULTIPLIER: 0.0\n",
      "    RGB_SENSOR:\n",
      "      HEIGHT: 256\n",
      "      HFOV: 45\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 0.6096, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      WIDTH: 256\n",
      "    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb\n",
      "    SEED: 100\n",
      "    SEMANTIC_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimSemanticSensor\n",
      "      WIDTH: 640\n",
      "    THIRD_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      UUID: robot_third_rgb\n",
      "      WIDTH: 640\n",
      "    THIRD_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      UUID: robot_third_rgb\n",
      "      WIDTH: 640\n",
      "    TILT_ANGLE: 15\n",
      "    TURN_ANGLE: 30\n",
      "    TYPE: Sim-v0\n",
      "  TASK:\n",
      "    ACTIONS:\n",
      "      ANSWER:\n",
      "        TYPE: AnswerAction\n",
      "      LOOK_DOWN:\n",
      "        TYPE: LookDownAction\n",
      "      LOOK_UP:\n",
      "        TYPE: LookUpAction\n",
      "      MOVE_FORWARD:\n",
      "        TYPE: MoveForwardAction\n",
      "      STOP:\n",
      "        TYPE: StopAction\n",
      "      TELEPORT:\n",
      "        TYPE: TeleportAction\n",
      "      TURN_LEFT:\n",
      "        TYPE: TurnLeftAction\n",
      "      TURN_RIGHT:\n",
      "        TYPE: TurnRightAction\n",
      "      VELOCITY_CONTROL:\n",
      "        ANG_VEL_RANGE: [-10.0, 10.0]\n",
      "        LIN_VEL_RANGE: [0.0, 0.25]\n",
      "        MIN_ABS_ANG_SPEED: 1.0\n",
      "        MIN_ABS_LIN_SPEED: 0.025\n",
      "        TIME_STEP: 1.0\n",
      "        TYPE: VelocityAction\n",
      "    ANSWER_ACCURACY:\n",
      "      TYPE: AnswerAccuracy\n",
      "    COLLISIONS:\n",
      "      TYPE: Collisions\n",
      "    COMPASS_SENSOR:\n",
      "      TYPE: CompassSensor\n",
      "    CORRECT_ANSWER:\n",
      "      TYPE: CorrectAnswer\n",
      "    DISTANCE_TO_GOAL:\n",
      "      DISTANCE_TO: POINT\n",
      "      TYPE: DistanceToGoal\n",
      "    EPISODE_INFO:\n",
      "      TYPE: EpisodeInfo\n",
      "    GOAL_SENSOR_UUID: pointgoal_with_gps_compass\n",
      "    GPS_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      TYPE: GPSSensor\n",
      "    HEADING_SENSOR:\n",
      "      TYPE: HeadingSensor\n",
      "    IMAGEGOAL_SENSOR:\n",
      "      TYPE: ImageGoalSensor\n",
      "    INSTRUCTION_SENSOR:\n",
      "      TYPE: InstructionSensor\n",
      "    INSTRUCTION_SENSOR_UUID: instruction\n",
      "    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL']\n",
      "    OBJECTGOAL_SENSOR:\n",
      "      GOAL_SPEC: TASK_CATEGORY_ID\n",
      "      GOAL_SPEC_MAX_VAL: 50\n",
      "      TYPE: ObjectGoalSensor\n",
      "    POINTGOAL_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      GOAL_FORMAT: POLAR\n",
      "      TYPE: PointGoalSensor\n",
      "    POINTGOAL_WITH_GPS_COMPASS_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      GOAL_FORMAT: POLAR\n",
      "      TYPE: PointGoalWithGPSCompassSensor\n",
      "    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT']\n",
      "    PROXIMITY_SENSOR:\n",
      "      MAX_DETECTION_RADIUS: 2.0\n",
      "      TYPE: ProximitySensor\n",
      "    QUESTION_SENSOR:\n",
      "      TYPE: QuestionSensor\n",
      "    SENSORS: ['POINTGOAL_WITH_GPS_COMPASS_SENSOR']\n",
      "    SOFT_SPL:\n",
      "      TYPE: SoftSPL\n",
      "    SPL:\n",
      "      TYPE: SPL\n",
      "    SUCCESS:\n",
      "      SUCCESS_DISTANCE: 0.2\n",
      "      TYPE: Success\n",
      "    SUCCESS_DISTANCE: 0.2\n",
      "    TOP_DOWN_MAP:\n",
      "      DRAW_BORDER: True\n",
      "      DRAW_GOAL_AABBS: True\n",
      "      DRAW_GOAL_POSITIONS: True\n",
      "      DRAW_SHORTEST_PATH: True\n",
      "      DRAW_SOURCE: True\n",
      "      DRAW_VIEW_POINTS: True\n",
      "      FOG_OF_WAR:\n",
      "        DRAW: True\n",
      "        FOV: 90\n",
      "        VISIBILITY_DIST: 5.0\n",
      "      MAP_PADDING: 3\n",
      "      MAP_RESOLUTION: 5000\n",
      "      MAX_EPISODE_STEPS: 1000\n",
      "      TYPE: TopDownMap\n",
      "    TYPE: Nav-v0\n",
      "TENSORBOARD_DIR: tb\n",
      "TEST_EPISODE_COUNT: 5\n",
      "TORCH_GPU_ID: 0\n",
      "TOTAL_NUM_STEPS: 75000000.0\n",
      "TRAINER_NAME: ppo\n",
      "VERBOSE: False\n",
      "VIDEO_DIR: video_dir\n",
      "VIDEO_OPTION: ['disk']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load and customize config\n",
    "#\n",
    "\n",
    "habitat_dir = \"/Users/mroberts/code/github/habitat-lab\"\n",
    "os.chdir(habitat_dir)\n",
    "\n",
    "config = get_config(\n",
    "    \"habitat_baselines/config/pointnav/ppo_pointnav.yaml\"\n",
    ")\n",
    "\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.SIMULATOR.NOISE_MODEL = CN()\n",
    "config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER = None\n",
    "config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER = None\n",
    "config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV = None\n",
    "config.TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV = None\n",
    "config.TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY = None\n",
    "config.freeze()\n",
    "\n",
    "config.merge_from_list(args.opts)\n",
    "\n",
    "# config.defrost()\n",
    "# config.TASK_CONFIG.SIMULATOR.ACTION_SPACE_CONFIG = \"pyrobotnoisy\"\n",
    "# config.freeze()\n",
    "\n",
    "# config.defrost()\n",
    "# config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.ROBOT = \"LoCoBot\"\n",
    "# config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER = \"ILQR\"    # our pre-trained model lists \"proportional\" in the filename, so don't change to ILQR \n",
    "# config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER = 1.0 # our pre-trained model lists \"0.5\" in the filename, so don't change to 1.0\n",
    "# config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.ENVIRONMENT.ITERATOR_OPTIONS.SHUFFLE = False\n",
    "config.freeze()\n",
    "\n",
    "if model_type == \"rgb\" or model_type == \"estimated_depth\":\n",
    "    config.defrost()\n",
    "    config.TASK_CONFIG.SIMULATOR.AGENT_0.SENSORS = [\"RGB_SENSOR\"]\n",
    "    config.freeze()\n",
    "elif model_type == \"depth\":\n",
    "    config.defrost()\n",
    "    config.TASK_CONFIG.SIMULATOR.AGENT_0.SENSORS = [\"DEPTH_SENSOR\"]\n",
    "    config.freeze()\n",
    "else:\n",
    "    assert False\n",
    "    \n",
    "if sim_eval_mode == \"challenge_sim\":\n",
    "    config.defrost()\n",
    "    config.TASK_CONFIG.SIMULATOR.HABITAT_SIM_V0.ALLOW_SLIDING = True\n",
    "    config.freeze()\n",
    "elif sim_eval_mode == \"test_sim\":\n",
    "    config.defrost()\n",
    "    config.TASK_CONFIG.SIMULATOR.HABITAT_SIM_V0.ALLOW_SLIDING = False\n",
    "    config.freeze()\n",
    "else:\n",
    "    assert False\n",
    "    \n",
    "config.defrost()\n",
    "config.TASK_CONFIG.DATASET.CONTENT_SCENES = [\"*\"]\n",
    "config.TASK_CONFIG.DATASET.DATA_PATH = \"data/datasets/pointnav/gibson/v2/val/val.json.gz\" # don't have obstacle_1 scenes, so use Gibson instead\n",
    "config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "config.NUM_ENVIRONMENTS = 1\n",
    "config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "if args.sensors == \"\":\n",
    "    config.SENSORS = []\n",
    "else:\n",
    "    config.SENSORS = args.sensors.split(\",\")\n",
    "# TODO(akadian): collisions are not working\n",
    "# config.TASK_CONFIG.TASK.MEASUREMENTS.append(\"COLLISIONS\")\n",
    "config.freeze()\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2b3d44-4712-4361-a385-79deed72992d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# create device\n",
    "#\n",
    "\n",
    "device = (\n",
    "    torch.device(\"cuda:{}\".format(config.TORCH_GPU_ID))\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00c2c16-5c9a-46c4-9e6d-99e9a287d815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 12:06:24,768 Initializing dataset PointNav-v1\n",
      "2021-11-22 12:06:24,788 initializing sim Sim-v0\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I1122 12:06:24.789633 316358080 ManagedFileBasedContainer.h:210] <Dataset>::convertFilenameToPassedExt : Filename : default changed to proposed scene_dataset_config.json filename : default.scene_dataset_config.json\n",
      "I1122 12:06:24.789664 316358080 AttributesManagerBase.h:365] <Dataset>::createFromJsonOrDefaultInternal : Proposing JSON name : default.scene_dataset_config.json from original name : default | This file  does not exist.\n",
      "I1122 12:06:24.789741 316358080 AssetAttributesManager.cpp:120] Asset attributes (capsule3DSolid : capsule3DSolid_hemiRings_4_cylRings_1_segments_12_halfLen_0.75_useTexCoords_false_useTangents_false) created and registered.\n",
      "I1122 12:06:24.789778 316358080 AssetAttributesManager.cpp:120] Asset attributes (capsule3DWireframe : capsule3DWireframe_hemiRings_8_cylRings_1_segments_16_halfLen_1) created and registered.\n",
      "I1122 12:06:24.789811 316358080 AssetAttributesManager.cpp:120] Asset attributes (coneSolid : coneSolid_segments_12_halfLen_1.25_rings_1_useTexCoordsI1122 12:06:24.915238 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Cantwell.navmesh\n",
      "_false_useTangents_false_capEnd_true) created and registered.\n",
      "I1122 12:06:24.789835 316358080 AssetAttributesManager.cpp:120] Asset attributes (coneWireframe : coneWireframe_segments_32_halfLen_1.25) created and registered.\n",
      "I1122 12:06:24.789851 316358080 AssetAttributesManager.cpp:120] Asset attributes (cubeSolid : cubeSolid) created and registered.\n",
      "I1122 12:06:24.789860 316358080 AssetAttributesManager.cpp:120] Asset attributes (cubeWireframe : cubeWireframe) created and registered.\n",
      "I1122 12:06:24.789886 316358080 AssetAttributesManager.cpp:120] Asset attributes (cylinderSolid : cylinderSolid_rings_1_segments_12_halfLen_1_useTexCoords_false_useTangents_false_capEnds_true) created and registered.\n",
      "I1122 12:06:24.789908 316358080 AssetAttributesManager.cpp:120] Asset attributes (cylinderWireframe : cylinderWireframe_rings_1_segments_32_halfLen_1) created and registered.\n",
      "I1122 12:06:24.789922 316358080 AssetAttributesManager.cpp:120] Asset attributes (icosphereSolid : icosphereSolid_subdivs_1) created and registered.\n",
      "I1122 12:06:24.789934 316358080 AssetAttributesManager.cpp:120] Asset attributes (icosphereWireframe : icosphereWireframe_subdivs_1) created and registered.\n",
      "I1122 12:06:24.789954 316358080 AssetAttributesManager.cpp:120] Asset attributes (uvSphereSolid : uvSphereSolid_rings_8_segments_16_useTexCoords_false_useTangents_false) created and registered.\n",
      "I1122 12:06:24.789973 316358080 AssetAttributesManager.cpp:120] Asset attributes (uvSphereWireframe : uvSphereWireframe_rings_16_segments_32) created and registered.\n",
      "I1122 12:06:24.789981 316358080 AssetAttributesManager.cpp:108] ::constructor : Built default primitive asset templates : 12\n",
      "I1122 12:06:24.790360 316358080 SceneDatasetAttributesManager.cpp:36] File (default) not found, so new default dataset attributes created and registered.\n",
      "I1122 12:06:24.790365 316358080 MetadataMediator.cpp:127] ::createSceneDataset : Dataset default successfully created.\n",
      "I1122 12:06:24.790376 316358080 AttributesManagerBase.I1122 12:06:24.915949 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n",
      "h:365] <Physics Manager>::createFromJsonOrDefaultInternal : Proposing JSON name : ./data/default.physics_config.json from original name : ./data/default.physics_config.json | This file  does not exist.\n",
      "I1122 12:06:24.790392 316358080 PhysicsAttributesManager.cpp:26] File (./data/default.physics_config.json) not found, so new default physics manager attributes created and registered.\n",
      "I1122 12:06:24.790398 316358080 MetadataMediator.cpp:212] ::setActiveSceneDatasetName : Previous active dataset  changed to default successfully.\n",
      "I1122 12:06:24.790402 316358080 MetadataMediator.cpp:183] ::setCurrPhysicsAttributesHandle : Old physics manager attributes  changed to ./data/default.physics_config.json successfully.\n",
      "I1122 12:06:24.790406 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Cantwell.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:06:24.866940 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Cantwell.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Cantwell.scene_instance.json\n",
      "I1122 12:06:24.866955 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Cantwell.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:06:24.866963 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Cantwell.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Cantwell.stage_config.json\n",
      "I1122 12:06:24.866968 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Cantwell.stage_config.json from original name : data/scene_datasets/gibson/Cantwell.glb | This file  does not exist.\n",
      "I1122 12:06:24.867019 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Cantwell.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:06:24.867049 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:06:24.867053 316358080 SceneDatasetAttributes.cpp:79] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes 'no_lights' specified in Scene Attributes but does not exist in dataset, so creating.\n",
      "I1122 12:06:24.867058 316358080 ManagedFileBasedContainer.h:210] <Lighting Layout>::convertFilenameToPassedExt : Filename : no_lights changed to proposed lighting_config.json filename : no_lights.lighting_config.json\n",
      "I1122 12:06:24.867063 316358080 ManagedFileBasedContainer.h:210] <Lighting Layout>::convertFilenameToPassedExt : Filename : no_lights changed to proposed lighting_config.json filename : no_lights.lighting_config.json\n",
      "I1122 12:06:24.867067 316358080 AttributesManagerBase.h:365] <Lighting Layout>::createFromJsonOrDefaultInternal : Proposing JSON name : no_lights.lighting_config.json from original name : no_lights | This file  does not exist.\n",
      "I1122 12:06:24.867081 316358080 LightLayoutAttributesManager.cpp:34] File (no_lights) not found, so new default light layout attributes created and registered.\n",
      "I1122 12:06:24.867089 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1122 12:06:24.867094 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1122 12:06:24.867223 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:06:24.867236 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:06:24.867242 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Cantwell.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Cantwell.scn\n",
      "E1122 12:06:24.867250 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Cantwell.scn does not exist.  Aborting load.\n",
      "W1122 12:06:24.867259 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Cantwell.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:06:24.867331 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:06:24.867336 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Cantwell.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:06:24.867352 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Cantwell.glb with render asset : data/scene_datasets/gibson/Cantwell.glb and collision asset : data/scene_datasets/gibson/Cantwell.glb\n",
      "I1122 12:06:24.867369 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:06:24.867374 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:06:24.867377 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Cantwell.glb \n",
      "I1122 12:06:24.867394 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Cantwell.glb\n",
      "I1122 12:06:24.914039 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Cantwell.glb\n",
      "W1122 12:06:24.914058 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:06:24.914067 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantwell.glb yields 1 candidates.  Using data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:06:24.914078 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:06:24.914083 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:06:24.914093 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantw2021-11-22 12:06:25,008 Initializing task Nav-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ell.glb yields 1 candidates.  Using data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:06:24.914099 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:06:24.914103 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:06:24.914115 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Cantwell.glb with renderer.\n",
      "I1122 12:06:24.928834 316358080 PathFinder.cpp:382] Building navmesh with 306x145 cells\n",
      "I1122 12:06:25.004814 316358080 PathFinder.cpp:652] Created navmesh with 199 vertices 94 polygons\n",
      "I1122 12:06:25.005090 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# construct a single env instead of multiple envs for simplicity\n",
    "#\n",
    "\n",
    "env = NavRLEnv(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d445e114-c2d0-4713-9483-966dc75c62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/scene_datasets/gibson/Cantwell.glb 0\n",
      "data/scene_datasets/gibson/Cantwell.glb 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# get starting episode and scene so we can reset the environment's episode iterator\n",
    "#\n",
    "\n",
    "initial_episode_id = env.current_episode.episode_id\n",
    "initial_scene_id = env.current_episode.scene_id\n",
    "\n",
    "print(initial_scene_id, initial_episode_id)\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "print(env.current_episode.scene_id, env.current_episode.episode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc32b3ab-2370-4a99-a0ca-e39920b9203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load model\n",
    "#\n",
    "\n",
    "def load_model(\n",
    "    path,\n",
    "    observation_space,\n",
    "    action_space,\n",
    "    hidden_size,\n",
    "    normalize_visual_inputs,\n",
    "    backbone,\n",
    "    num_recurrent_layers,\n",
    "    device,\n",
    "):\n",
    "\n",
    "    model = PointNavResNetPolicy(\n",
    "        observation_space=observation_space,\n",
    "        action_space=action_space,\n",
    "        hidden_size=hidden_size,\n",
    "        normalize_visual_inputs=normalize_visual_inputs,\n",
    "        backbone=backbone,\n",
    "        num_recurrent_layers=num_recurrent_layers,\n",
    "        goal_sensor_uuid=\"pointgoal_with_gps_compass\",\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    saved_model = torch.load(path, map_location=device)\n",
    "    saved_model_state_dict = {}\n",
    "    for k, v in saved_model[\"state_dict\"].items():\n",
    "        new_k = k.replace(\"actor_critic.\", \"\")\n",
    "        saved_model_state_dict[new_k] = v\n",
    "\n",
    "    model.load_state_dict(saved_model_state_dict)\n",
    "\n",
    "    model_params = 0\n",
    "    for k,v in model.state_dict().items():\n",
    "        # print(k, torch.numel(v))\n",
    "        model_params += torch.numel(v)\n",
    "    print(model_params)\n",
    "\n",
    "    saved_model_params = 0\n",
    "    for k,v in saved_model[\"state_dict\"].items():\n",
    "        # print(k, torch.numel(v))\n",
    "        saved_model_params += torch.numel(v)\n",
    "    print(saved_model_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5bad107-4828-4f2a-bb42-618a09361907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model_path, num_episodes=-1, max_num_actions_per_episode=10000):\n",
    "\n",
    "    global observation\n",
    "    \n",
    "    print(\"Resetting env to initial_episode_id and initial_scene_id...\")\n",
    "    print()\n",
    "\n",
    "    while env.current_episode.episode_id != initial_episode_id or env.current_episode.scene_id != initial_scene_id:\n",
    "        observation = env.reset()\n",
    "        \n",
    "    print()\n",
    "    print(env.current_episode.scene_id, env.current_episode.episode_id)\n",
    "    print()\n",
    "    \n",
    "    #\n",
    "    # load model\n",
    "    #\n",
    "    \n",
    "    model = load_model(\n",
    "        path=model_path,\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        hidden_size=args.hidden_size,\n",
    "        normalize_visual_inputs=bool(args.normalize_visual_inputs),\n",
    "        backbone=args.backbone,\n",
    "        num_recurrent_layers=args.num_recurrent_layers,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    #\n",
    "    # initialization before main loop\n",
    "    #\n",
    "\n",
    "    metric_name = config.TASK_CONFIG.TASK.MEASUREMENTS[0]\n",
    "    metric_cfg = getattr(config.TASK_CONFIG.TASK, metric_name)\n",
    "    measure_type = baseline_registry.get_measure(metric_cfg.TYPE)\n",
    "    metric_uuid = measure_type(None, None)._get_uuid()\n",
    "\n",
    "    assert measure_type is not None, \"invalid measurement type {}\".format(metric_cfg.TYPE)\n",
    "\n",
    "    print(metric_name)\n",
    "    print(metric_cfg)\n",
    "    print(measure_type)\n",
    "    print(metric_uuid)\n",
    "    print()\n",
    "\n",
    "    print(len(env.episodes))\n",
    "    print()\n",
    "\n",
    "    print(env.current_episode)\n",
    "    print()\n",
    "\n",
    "    print(env._env.get_metrics())\n",
    "    print()\n",
    "\n",
    "    observations = [observation]\n",
    "    batch = batch_obs(observations, device)\n",
    "\n",
    "    num_processes = 1\n",
    "\n",
    "    test_recurrent_hidden_states = torch.zeros(\n",
    "        model.net.num_recurrent_layers,\n",
    "        num_processes,\n",
    "        args.hidden_size,\n",
    "        device=device,\n",
    "    )\n",
    "    prev_actions = torch.zeros(\n",
    "        num_processes, 1, device=device, dtype=torch.long\n",
    "    )\n",
    "    not_done_masks = torch.zeros(num_processes, 1, device=device)\n",
    "    print(not_done_masks)\n",
    "\n",
    "    current_episode_num_actions = 0\n",
    "    current_episode_reward = 0.0\n",
    "    current_episode_stats_actions = defaultdict(int)\n",
    "\n",
    "    stats_episodes = dict()  # dict of dicts that stores stats per episode\n",
    "\n",
    "    #\n",
    "    # main loop\n",
    "    #\n",
    "\n",
    "    max_num_actions_per_episode = 10000\n",
    "    \n",
    "    if num_episodes == -1:\n",
    "        num_episodes = len(env.episodes)\n",
    "\n",
    "    while len(stats_episodes) < num_episodes:\n",
    "\n",
    "        #\n",
    "        # main loop: choose action\n",
    "        #\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, actions, _, test_recurrent_hidden_states = model.act(\n",
    "                batch,\n",
    "                test_recurrent_hidden_states,\n",
    "                prev_actions,\n",
    "                not_done_masks,\n",
    "                deterministic=False,\n",
    "            )\n",
    "\n",
    "            prev_actions.copy_(actions)\n",
    "\n",
    "        assert len(actions) == 1\n",
    "        action = actions[0]\n",
    "\n",
    "        # print(env.habitat_env.task.get_action_name(action.item()))\n",
    "\n",
    "        #\n",
    "        # main loop: perform action\n",
    "        #\n",
    "\n",
    "        observation, reward, done, info = env.step(action=action.item())\n",
    "\n",
    "        #\n",
    "        # main loop: update state\n",
    "        #\n",
    "\n",
    "        observations = [observation]\n",
    "        batch = batch_obs(observations, device)\n",
    "\n",
    "        dones = [done]\n",
    "        not_done_masks = torch.tensor(\n",
    "            [[0.0] if done else [1.0] for done in dones],\n",
    "            dtype=torch.float,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        current_episode_num_actions += 1\n",
    "        current_episode_reward += reward\n",
    "        current_episode_stats_actions[action.item()] += 1\n",
    "\n",
    "        assert current_episode_num_actions < max_num_actions_per_episode\n",
    "\n",
    "        if done:\n",
    "\n",
    "            # record stats\n",
    "            stats_episode = dict(info)\n",
    "            stats_episode[\"reward\"] = current_episode_reward\n",
    "            stats_episode[\"stats_actions\"] = dict(current_episode_stats_actions)\n",
    "\n",
    "            # if len(stats_episodes) % 100 == 0:\n",
    "            #     print(\"Episodes finished: {}\".format(len(stats_episodes)))\n",
    "\n",
    "            print(\"Episodes finished: {}\".format(len(stats_episodes)))\n",
    "            print(stats_episode)\n",
    "            print()\n",
    "            \n",
    "            stats_episodes[ (env.current_episode.scene_id, env.current_episode.episode_id) ] = stats_episode\n",
    "\n",
    "            # reset env\n",
    "            observation = env.reset()\n",
    "            observations = [observation]\n",
    "            batch = batch_obs(observations, device)\n",
    "\n",
    "            test_recurrent_hidden_states = torch.zeros(\n",
    "                model.net.num_recurrent_layers,\n",
    "                num_processes,\n",
    "                args.hidden_size,\n",
    "                device=device,\n",
    "            )\n",
    "            prev_actions = torch.zeros(\n",
    "                num_processes, 1, device=device, dtype=torch.long\n",
    "            )\n",
    "            not_done_masks = torch.zeros(num_processes, 1, device=device)\n",
    "\n",
    "            current_episode_num_actions = 0\n",
    "            current_episode_reward = 0.0\n",
    "            current_episode_stats_actions = defaultdict(int)\n",
    "            \n",
    "    return stats_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9ff508-4383-4e7f-a109-be429cee5c74",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file: /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/job_19633842.sensor_DEPTH_SENSOR.train_data_gibson.noise_multiplier_1.0.noise_model_controller_Proportional.agent_radius_0.20.success_reward_10.0.slack_reward_-0.01.collision_reward_0.0.spl_max_collisions_500_ckpt.000000057.pth\n",
      "\n",
      "Pickle file: /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/stats/habitat_gibson_val_challenge_sim_depth_train_sliding_off_train_noise_multiplier_1.0.pickle\n",
      "\n",
      "Resetting env to initial_episode_id and initial_scene_id...\n",
      "\n",
      "\n",
      "data/scene_datasets/gibson/Cantwell.glb 0\n",
      "\n",
      "12454917\n",
      "12454917\n",
      "DISTANCE_TO_GOAL\n",
      "DISTANCE_TO: POINT\n",
      "TYPE: DistanceToGoal\n",
      "<class 'habitat.tasks.nav.nav.DistanceToGoal'>\n",
      "distance_to_goal\n",
      "\n",
      "994\n",
      "\n",
      "NavigationEpisode(episode_id='0', scene_id='data/scene_datasets/gibson/Cantwell.glb', start_position=[0.47876065969467163, 0.1582520604133606, -4.124194145202637], start_rotation=[0, 0.13995857593396624, 0, 0.9901573597275012], info={'geodesic_distance': 11.324929237365723}, _shortest_path_cache=<habitat_sim._ext.habitat_sim_bindings.MultiGoalShortestPath object at 0x7f9318686bf0>, goals=[NavigationGoal(position=[-7.889715671539307, 0.1582520604133606, -0.6258162260055542], radius=0.2)], start_room=None, shortest_paths=None)\n",
      "\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan}\n",
      "\n",
      "tensor([[0.]])\n",
      "Episodes finished: 0\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 1\n",
      "{'distance_to_goal': 0.053148142993450165, 'success': 1.0, 'spl': 0.8708013654719546, 'reward': 7.013959591686729, 'stats_actions': {2: 4, 3: 16, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 2\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 3\n",
      "{'distance_to_goal': 0.04351968318223953, 'success': 1.0, 'spl': 0.8493969039146195, 'reward': 9.139839005172261, 'stats_actions': {2: 11, 3: 25, 1: 36, 0: 1}}\n",
      "\n",
      "Episodes finished: 4\n",
      "{'distance_to_goal': 0.060679126530885696, 'success': 1.0, 'spl': 0.9639084216521411, 'reward': 11.48407024785877, 'stats_actions': {3: 15, 1: 41, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 5\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 6\n",
      "{'distance_to_goal': 0.08453018218278885, 'success': 1.0, 'spl': 0.9505630592510113, 'reward': 9.339159373939045, 'stats_actions': {2: 13, 1: 32, 3: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 7\n",
      "{'distance_to_goal': 0.03731453791260719, 'success': 1.0, 'spl': 0.8313037018965532, 'reward': 6.662962199300531, 'stats_actions': {2: 5, 3: 9, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 8\n",
      "{'distance_to_goal': 0.03233860805630684, 'success': 1.0, 'spl': 0.8134545456758083, 'reward': 10.12465914890171, 'stats_actions': {3: 20, 2: 5, 1: 41, 0: 1}}\n",
      "\n",
      "Episodes finished: 9\n",
      "{'distance_to_goal': 0.0754309669137001, 'success': 1.0, 'spl': 0.8953291604292536, 'reward': 9.638699320256718, 'stats_actions': {3: 15, 1: 35, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 10\n",
      "{'distance_to_goal': 0.08312167972326279, 'success': 1.0, 'spl': 0.8855362405628744, 'reward': 6.929785005152229, 'stats_actions': {3: 8, 1: 22, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 11\n",
      "{'distance_to_goal': 0.016963426023721695, 'success': 1.0, 'spl': 0.9207966710879552, 'reward': 5.828119057267906, 'stats_actions': {3: 10, 1: 16, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 12\n",
      "{'distance_to_goal': 0.12313293665647507, 'success': 1.0, 'spl': 0.942437819090293, 'reward': 10.550518262684355, 'stats_actions': {3: 30, 1: 38, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 13\n",
      "{'distance_to_goal': 0.12484521418809891, 'success': 1.0, 'spl': 0.9852437309595805, 'reward': 8.786017746627337, 'stats_actions': {2: 10, 1: 28, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 14\n",
      "{'distance_to_goal': 0.043101582676172256, 'success': 1.0, 'spl': 0.6734184477830479, 'reward': 10.271888575404889, 'stats_actions': {2: 12, 3: 46, 1: 54, 0: 1}}\n",
      "\n",
      "Episodes finished: 15\n",
      "{'distance_to_goal': 0.12583313882350922, 'success': 1.0, 'spl': 0.8910503563937718, 'reward': 10.768373480439195, 'stats_actions': {3: 32, 1: 44, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 16\n",
      "{'distance_to_goal': 0.12792065739631653, 'success': 1.0, 'spl': 0.9585093290102806, 'reward': 15.611351383924497, 'stats_actions': {3: 16, 1: 59, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 17\n",
      "{'distance_to_goal': 0.07170304656028748, 'success': 1.0, 'spl': 0.1453552366372548, 'reward': 4.019205175638201, 'stats_actions': {2: 40, 3: 90, 1: 101, 0: 1}}\n",
      "\n",
      "Episodes finished: 18\n",
      "{'distance_to_goal': 0.04780163988471031, 'success': 1.0, 'spl': 0.8485690068567414, 'reward': 6.6265231396257915, 'stats_actions': {3: 19, 1: 24, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 19\n",
      "{'distance_to_goal': 0.0061628976836800575, 'success': 1.0, 'spl': 0.9546149961818619, 'reward': 6.759029019735756, 'stats_actions': {3: 8, 1: 20, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 20\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 21\n",
      "{'distance_to_goal': 0.1371423602104187, 'success': 1.0, 'spl': 0.7508110897006601, 'reward': 12.248477375507363, 'stats_actions': {2: 7, 3: 48, 1: 59, 0: 1}}\n",
      "\n",
      "Episodes finished: 22\n",
      "{'distance_to_goal': 0.15556825697422028, 'success': 1.0, 'spl': 0.9756330455888903, 'reward': 11.022370547652253, 'stats_actions': {3: 9, 2: 15, 1: 39, 0: 1}}\n",
      "\n",
      "Episodes finished: 23\n",
      "{'distance_to_goal': 0.11933396011590958, 'success': 1.0, 'spl': 0.21418485546592045, 'reward': 6.574841206967863, 'stats_actions': {2: 60, 3: 128, 1: 144, 0: 1}}\n",
      "\n",
      "Episodes finished: 24\n",
      "{'distance_to_goal': 0.09315742552280426, 'success': 1.0, 'spl': 0.8902406728094027, 'reward': 8.587680930495267, 'stats_actions': {2: 8, 3: 10, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 25\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 26\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 27\n",
      "{'distance_to_goal': 0.11533108353614807, 'success': 1.0, 'spl': 0.7534669232990298, 'reward': 8.85489375472071, 'stats_actions': {3: 38, 1: 66, 2: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 28\n",
      "{'distance_to_goal': 0.05928358435630798, 'success': 1.0, 'spl': 0.6979154850739336, 'reward': 8.252396942377095, 'stats_actions': {3: 38, 1: 51, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 29\n",
      "{'distance_to_goal': 5.22402286529541, 'success': 0.0, 'spl': 0.0, 'reward': -1.7023210525512515, 'stats_actions': {2: 46, 3: 260, 1: 194}}\n",
      "\n",
      "Episodes finished: 30\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 31\n",
      "{'distance_to_goal': 0.04214205965399742, 'success': 1.0, 'spl': 0.49028345401452594, 'reward': 10.687074363380727, 'stats_actions': {3: 108, 1: 127, 2: 55, 0: 1}}\n",
      "\n",
      "Episodes finished: 32\n",
      "{'distance_to_goal': 0.030853448435664177, 'success': 1.0, 'spl': 0.8861237605884255, 'reward': 6.66211114354432, 'stats_actions': {2: 9, 3: 15, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 33\n",
      "{'distance_to_goal': 0.020017126575112343, 'success': 1.0, 'spl': 0.9491752323244489, 'reward': 5.077536603435875, 'stats_actions': {3: 11, 1: 12, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 34\n",
      "{'distance_to_goal': 0.1011536717414856, 'success': 1.0, 'spl': 0.8296085406705657, 'reward': 10.868742263317117, 'stats_actions': {3: 15, 1: 40, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 35\n",
      "{'distance_to_goal': 0.14745646715164185, 'success': 1.0, 'spl': 0.9858996777782338, 'reward': 9.62446850538255, 'stats_actions': {2: 18, 1: 34, 3: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 36\n",
      "{'distance_to_goal': 0.08386621624231339, 'success': 1.0, 'spl': 0.8948187085536731, 'reward': 15.752154329717172, 'stats_actions': {3: 21, 1: 64, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 37\n",
      "{'distance_to_goal': 0.1043836921453476, 'success': 1.0, 'spl': 0.8789833089822906, 'reward': 5.561549583077432, 'stats_actions': {2: 4, 3: 14, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 38\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 39\n",
      "{'distance_to_goal': 0.12199660390615463, 'success': 1.0, 'spl': 0.9515590936789302, 'reward': 12.948952874243272, 'stats_actions': {2: 13, 3: 21, 1: 48, 0: 1}}\n",
      "\n",
      "Episodes finished: 40\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 41\n",
      "{'distance_to_goal': 0.11207868158817291, 'success': 1.0, 'spl': 0.9511186370073996, 'reward': 7.999762749075895, 'stats_actions': {3: 14, 1: 26, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 42\n",
      "{'distance_to_goal': 0.0941736251115799, 'success': 1.0, 'spl': 0.5944597619137121, 'reward': 8.516230694651611, 'stats_actions': {3: 83, 2: 31, 1: 78, 0: 1}}\n",
      "\n",
      "Episodes finished: 43\n",
      "{'distance_to_goal': 0.05333872139453888, 'success': 1.0, 'spl': 0.9371185852773161, 'reward': 14.119568459391607, 'stats_actions': {2: 13, 3: 25, 1: 54, 0: 1}}\n",
      "\n",
      "Episodes finished: 44\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 45\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 46\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 47\n",
      "{'distance_to_goal': 0.04406064748764038, 'success': 1.0, 'spl': 0.96748131216877, 'reward': 8.026310541629798, 'stats_actions': {2: 10, 3: 10, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 48\n",
      "{'distance_to_goal': 0.10533937066793442, 'success': 1.0, 'spl': 0.8659681545525277, 'reward': 7.6081357994675685, 'stats_actions': {3: 23, 2: 5, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 49\n",
      "{'distance_to_goal': 0.059577520936727524, 'success': 1.0, 'spl': 0.1900834426796195, 'reward': 7.124078751951514, 'stats_actions': {2: 98, 1: 208, 3: 187, 0: 1}}\n",
      "\n",
      "Episodes finished: 50\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 51\n",
      "{'distance_to_goal': 0.10546311736106873, 'success': 1.0, 'spl': 0.9347016438933772, 'reward': 16.039697290658964, 'stats_actions': {2: 13, 3: 26, 1: 63, 0: 1}}\n",
      "\n",
      "Episodes finished: 52\n",
      "{'distance_to_goal': 0.11654610186815262, 'success': 1.0, 'spl': 0.9714264841057382, 'reward': 15.986423868834985, 'stats_actions': {2: 11, 3: 19, 1: 60, 0: 1}}\n",
      "\n",
      "Episodes finished: 53\n",
      "{'distance_to_goal': 0.11828220635652542, 'success': 1.0, 'spl': 0.9455225827748617, 'reward': 10.62653606146575, 'stats_actions': {2: 7, 3: 23, 1: 38, 0: 1}}\n",
      "\n",
      "Episodes finished: 54\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 55\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 56\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 57\n",
      "{'distance_to_goal': 0.08514712750911713, 'success': 1.0, 'spl': 1.0, 'reward': 5.425847077965738, 'stats_actions': {3: 5, 1: 13, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 58\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 59\n",
      "{'distance_to_goal': 0.08937034755945206, 'success': 1.0, 'spl': 0.9777872107830462, 'reward': 8.052211721837525, 'stats_actions': {3: 10, 1: 25, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 60\n",
      "{'distance_to_goal': 0.11688591539859772, 'success': 1.0, 'spl': 0.9411410908176759, 'reward': 14.212214846014989, 'stats_actions': {2: 9, 3: 20, 1: 54, 0: 1}}\n",
      "\n",
      "Episodes finished: 61\n",
      "{'distance_to_goal': 0.07783177495002747, 'success': 1.0, 'spl': 0.9627954308311666, 'reward': 17.166649273633972, 'stats_actions': {3: 44, 1: 68, 2: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 62\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 63\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 64\n",
      "{'distance_to_goal': 0.07513386756181717, 'success': 1.0, 'spl': 0.9712766950664906, 'reward': 7.552673043906693, 'stats_actions': {3: 14, 1: 24, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 65\n",
      "{'distance_to_goal': 0.11205974966287613, 'success': 1.0, 'spl': 0.9444407645251556, 'reward': 8.708140254914767, 'stats_actions': {2: 9, 3: 31, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 66\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 67\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 68\n",
      "{'distance_to_goal': 0.11953256279230118, 'success': 1.0, 'spl': 0.93097987497899, 'reward': 9.75910990089179, 'stats_actions': {3: 12, 2: 12, 1: 35, 0: 1}}\n",
      "\n",
      "Episodes finished: 69\n",
      "{'distance_to_goal': 0.09279234707355499, 'success': 1.0, 'spl': 0.9003540447499535, 'reward': 12.36736985385419, 'stats_actions': {2: 9, 3: 32, 1: 54, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:08:51.446659 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Denmark.navmesh\n",
      "I1122 12:08:51.386533 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:08:51.386566 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:08:51.386571 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:08:51.386574 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:08:51.386708 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:08:51.388574 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:08:51.388586 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:08:51.389644 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Denmark.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:08:51.426156 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Denmark.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Denmark.scene_instance.json\n",
      "I1122 12:08:51.426177 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Denmark.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:08:51.426182 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Denmark.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Denmark.stage_config.json\n",
      "I1122 12:08:51.426187 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Denmark.stage_config.json from original name : data/scene_datasets/gibson/Denmark.glb | This file  does not exist.\n",
      "I1122 12:08:51.426240 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Denmark.glb) exists but is not a recognized coI1122 12:08:51.447736 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 70\n",
      "{'distance_to_goal': 0.0, 'success': 0.0, 'spl': 0.0, 'reward': 5.804700851440531, 'stats_actions': {2: 115, 3: 112, 1: 273}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nfig filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:08:51.426265 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Denmark.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:08:51.426268 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:08:51.426273 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Denmark.navmesh\n",
      "I1122 12:08:51.426278 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Denmark.navmesh\n",
      "I1122 12:08:51.426367 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:08:51.426373 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:08:51.426378 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Denmark.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Denmark.scn\n",
      "E1122 12:08:51.426383 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Denmark.scn does not exist.  Aborting load.\n",
      "W1122 12:08:51.426390 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Denmark.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:08:51.426441 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:08:51.426446 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Denmark.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:08:51.426460 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Denmark.glb with render asset : data/scene_datasets/gibson/Denmark.glb and collision asset : data/scene_datasets/gibson/Denmark.glb\n",
      "I1122 12:08:51.426470 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:08:51.426474 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Denmark.glb.\n",
      "I1122 12:08:51.426476 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Denmark.glb \n",
      "I1122 12:08:51.426486 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Denmark.glb\n",
      "I1122 12:08:51.445869 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Denmark.glb\n",
      "W1122 12:08:51.445886 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:08:51.445894 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Denmark.glb yields 1 candidates.  Using data/scene_datasets/gibson/Denmark.glb.\n",
      "I1122 12:08:51.445904 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Denmark.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:08:51.445909 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:08:51.445917 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Denmark.glb yields 1 candidates.  Using data/scene_datasets/gibson/Denmark.glb.\n",
      "I1122 12:08:51.445924 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Denmark.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:08:51.445926 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:08:51.445937 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Denmark.glb with renderer.\n",
      "I1122 12:08:51.454211 316358080 PathFinder.cpp:382] Building navmesh with 163x109 cells\n",
      "I1122 12:08:51.503237 316358080 PathFinder.cpp:652] Created navmesh with 67 vertices 34 polygons\n",
      "I1122 12:08:51.503257 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 71\n",
      "{'distance_to_goal': 0.05346140265464783, 'success': 1.0, 'spl': 0.9620284543375693, 'reward': 9.733447166681298, 'stats_actions': {3: 10, 2: 12, 1: 33, 0: 1}}\n",
      "\n",
      "Episodes finished: 72\n",
      "{'distance_to_goal': 0.08674946427345276, 'success': 1.0, 'spl': 0.9554860526782539, 'reward': 6.541484292745593, 'stats_actions': {2: 5, 3: 16, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 73\n",
      "{'distance_to_goal': 0.09316471964120865, 'success': 1.0, 'spl': 0.9208716641368789, 'reward': 7.101630297601226, 'stats_actions': {3: 9, 1: 22, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 74\n",
      "{'distance_to_goal': 0.09302472323179245, 'success': 1.0, 'spl': 0.9041927187146611, 'reward': 8.763467319309719, 'stats_actions': {3: 10, 2: 6, 1: 33, 0: 1}}\n",
      "\n",
      "Episodes finished: 75\n",
      "{'distance_to_goal': 0.07811887562274933, 'success': 1.0, 'spl': 0.9508833643653463, 'reward': 4.833513242602349, 'stats_actions': {2: 5, 3: 2, 1: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 76\n",
      "{'distance_to_goal': 0.04533259570598602, 'success': 1.0, 'spl': 0.959075594631924, 'reward': 6.457402237057688, 'stats_actions': {3: 6, 1: 18, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 77\n",
      "{'distance_to_goal': 0.0734584704041481, 'success': 1.0, 'spl': 0.9580089484504672, 'reward': 4.942095185220242, 'stats_actions': {3: 10, 1: 17, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 78\n",
      "{'distance_to_goal': 0.028912287205457687, 'success': 1.0, 'spl': 0.8610403273481753, 'reward': 7.9283704276382965, 'stats_actions': {3: 25, 2: 3, 1: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 79\n",
      "{'distance_to_goal': 0.08637651801109314, 'success': 1.0, 'spl': 0.9113621673688833, 'reward': 7.125030628442768, 'stats_actions': {2: 2, 3: 28, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 80\n",
      "{'distance_to_goal': 0.1439468115568161, 'success': 1.0, 'spl': 0.997220947441269, 'reward': 8.073542259335522, 'stats_actions': {3: 11, 1: 25, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 81\n",
      "{'distance_to_goal': 0.07681527733802795, 'success': 1.0, 'spl': 0.838412346678344, 'reward': 4.808024886846543, 'stats_actions': {2: 3, 3: 17, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 82\n",
      "{'distance_to_goal': 0.09366383403539658, 'success': 1.0, 'spl': 0.9512425765783593, 'reward': 5.730825282633306, 'stats_actions': {2: 6, 3: 3, 1: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 83\n",
      "{'distance_to_goal': 0.1363675743341446, 'success': 1.0, 'spl': 0.9844831558567696, 'reward': 5.753324922919275, 'stats_actions': {3: 10, 1: 15, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 84\n",
      "{'distance_to_goal': 0.1341276317834854, 'success': 1.0, 'spl': 0.8617503932817903, 'reward': 6.018264603018764, 'stats_actions': {2: 1, 3: 20, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 85\n",
      "{'distance_to_goal': 0.0725918635725975, 'success': 1.0, 'spl': 0.7328453773396879, 'reward': 6.9038719502091555, 'stats_actions': {3: 29, 1: 55, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 86\n",
      "{'distance_to_goal': 0.06333871185779572, 'success': 1.0, 'spl': 0.9342441316396236, 'reward': 4.970805193781854, 'stats_actions': {3: 12, 1: 12, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 87\n",
      "{'distance_to_goal': 0.03207595646381378, 'success': 1.0, 'spl': 0.9564344175434553, 'reward': 8.909211351275449, 'stats_actions': {2: 10, 1: 29, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 88\n",
      "{'distance_to_goal': 0.13500523567199707, 'success': 1.0, 'spl': 0.9671711339477373, 'reward': 7.958364610672001, 'stats_actions': {2: 7, 1: 25, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 89\n",
      "{'distance_to_goal': 0.019233055412769318, 'success': 1.0, 'spl': 0.9259599704038459, 'reward': 6.509076652228836, 'stats_actions': {2: 9, 3: 8, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 90\n",
      "{'distance_to_goal': 0.06363265216350555, 'success': 1.0, 'spl': 1.0, 'reward': 5.219796989560129, 'stats_actions': {3: 7, 1: 12, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 91\n",
      "{'distance_to_goal': 0.09286472201347351, 'success': 1.0, 'spl': 0.9848114333400099, 'reward': 8.019250489473349, 'stats_actions': {2: 10, 3: 7, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 92\n",
      "{'distance_to_goal': 0.10439488291740417, 'success': 1.0, 'spl': 0.9205459826910861, 'reward': 6.385978633165362, 'stats_actions': {3: 8, 1: 19, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 93\n",
      "{'distance_to_goal': 0.028056634590029716, 'success': 1.0, 'spl': 0.9517020921354378, 'reward': 4.839124189689755, 'stats_actions': {3: 9, 1: 11, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 94\n",
      "{'distance_to_goal': 0.10604171454906464, 'success': 1.0, 'spl': 0.884985452204856, 'reward': 6.438885520100597, 'stats_actions': {2: 9, 1: 20, 3: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 95\n",
      "{'distance_to_goal': 0.13774050772190094, 'success': 1.0, 'spl': 0.985662964257975, 'reward': 5.711328362822534, 'stats_actions': {2: 7, 1: 15, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 96\n",
      "{'distance_to_goal': 0.03179505094885826, 'success': 1.0, 'spl': 0.9453717185913849, 'reward': 6.432377274185422, 'stats_actions': {3: 5, 1: 18, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 97\n",
      "{'distance_to_goal': 0.11968859285116196, 'success': 1.0, 'spl': 0.8766354353380951, 'reward': 6.075171388685705, 'stats_actions': {3: 5, 2: 1, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 98\n",
      "{'distance_to_goal': 0.13148148357868195, 'success': 1.0, 'spl': 0.9814247094080378, 'reward': 8.821490508914, 'stats_actions': {2: 8, 1: 28, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 99\n",
      "{'distance_to_goal': 0.12034094333648682, 'success': 1.0, 'spl': 0.8249861038730656, 'reward': 7.9670551061630315, 'stats_actions': {2: 11, 3: 18, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 100\n",
      "{'distance_to_goal': 0.09247680008411407, 'success': 1.0, 'spl': 0.9397164968040439, 'reward': 8.68394737899304, 'stats_actions': {3: 15, 1: 29, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 101\n",
      "{'distance_to_goal': 0.10416579991579056, 'success': 1.0, 'spl': 0.9924340197611604, 'reward': 4.915027887523174, 'stats_actions': {3: 6, 1: 11, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 102\n",
      "{'distance_to_goal': 0.1846134513616562, 'success': 1.0, 'spl': 0.9547555552504837, 'reward': 5.98976152956486, 'stats_actions': {3: 10, 1: 17, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 103\n",
      "{'distance_to_goal': 0.03714075684547424, 'success': 1.0, 'spl': 0.9588361990406572, 'reward': 6.486278833150866, 'stats_actions': {3: 4, 1: 18, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 104\n",
      "{'distance_to_goal': 0.12216941267251968, 'success': 1.0, 'spl': 0.9199882512119258, 'reward': 4.868234697282316, 'stats_actions': {3: 11, 1: 12, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 105\n",
      "{'distance_to_goal': 0.08560129255056381, 'success': 1.0, 'spl': 0.9018039080718405, 'reward': 4.714359387457371, 'stats_actions': {1: 11, 3: 5, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 106\n",
      "{'distance_to_goal': 0.05818593502044678, 'success': 1.0, 'spl': 0.8952991314830946, 'reward': 7.487433743476871, 'stats_actions': {3: 29, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 107\n",
      "{'distance_to_goal': 0.06053449213504791, 'success': 1.0, 'spl': 0.8919469586431269, 'reward': 9.532923550009734, 'stats_actions': {3: 21, 1: 36, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 108\n",
      "{'distance_to_goal': 0.05322694033384323, 'success': 1.0, 'spl': 0.8722945119063423, 'reward': 6.706319988071922, 'stats_actions': {2: 5, 1: 21, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 109\n",
      "{'distance_to_goal': 0.09137845039367676, 'success': 1.0, 'spl': 0.8705091987982078, 'reward': 5.738285903930666, 'stats_actions': {2: 5, 3: 14, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 110\n",
      "{'distance_to_goal': 0.1512933075428009, 'success': 1.0, 'spl': 0.7159466666640756, 'reward': 5.462138241529466, 'stats_actions': {3: 11, 2: 8, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 111\n",
      "{'distance_to_goal': 0.08306122571229935, 'success': 1.0, 'spl': 0.8151093746718594, 'reward': 6.226295768916611, 'stats_actions': {2: 3, 3: 18, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 112\n",
      "{'distance_to_goal': 0.0654558464884758, 'success': 1.0, 'spl': 0.9100751641331498, 'reward': 5.067614641487599, 'stats_actions': {3: 7, 1: 14, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 113\n",
      "{'distance_to_goal': 0.03937772661447525, 'success': 1.0, 'spl': 0.8421364307421213, 'reward': 6.20130418866873, 'stats_actions': {3: 22, 1: 20, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 114\n",
      "{'distance_to_goal': 0.032736461609601974, 'success': 1.0, 'spl': 0.9446333914959536, 'reward': 6.975105258971456, 'stats_actions': {2: 9, 1: 21, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 115\n",
      "{'distance_to_goal': 0.09608689695596695, 'success': 1.0, 'spl': 0.9334292626122589, 'reward': 5.857052389085294, 'stats_actions': {2: 5, 3: 5, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 116\n",
      "{'distance_to_goal': 0.02706250734627247, 'success': 1.0, 'spl': 0.9701968559590963, 'reward': 6.2088020556420105, 'stats_actions': {3: 8, 1: 17, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 117\n",
      "{'distance_to_goal': 0.07227484881877899, 'success': 1.0, 'spl': 0.9626993174595799, 'reward': 8.117740028500563, 'stats_actions': {3: 11, 1: 26, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 118\n",
      "{'distance_to_goal': 0.05832619592547417, 'success': 1.0, 'spl': 0.9678603120483925, 'reward': 7.967175799161201, 'stats_actions': {2: 13, 3: 8, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 119\n",
      "{'distance_to_goal': 0.06619977205991745, 'success': 1.0, 'spl': 0.9151953794569934, 'reward': 6.818575942814353, 'stats_actions': {3: 18, 1: 21, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 120\n",
      "{'distance_to_goal': 0.07793658971786499, 'success': 1.0, 'spl': 0.9114318883129164, 'reward': 6.1335076546669045, 'stats_actions': {2: 3, 3: 17, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 121\n",
      "{'distance_to_goal': 0.0987606793642044, 'success': 1.0, 'spl': 0.8144354361436745, 'reward': 5.205372497439385, 'stats_actions': {2: 3, 1: 15, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 122\n",
      "{'distance_to_goal': 0.08781231939792633, 'success': 1.0, 'spl': 0.9716341390123948, 'reward': 6.879773148894313, 'stats_actions': {3: 6, 2: 7, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 123\n",
      "{'distance_to_goal': 0.12417138367891312, 'success': 1.0, 'spl': 0.9781193661759199, 'reward': 8.130362593829638, 'stats_actions': {2: 10, 3: 16, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 124\n",
      "{'distance_to_goal': 0.09791921824216843, 'success': 1.0, 'spl': 0.9433872777590773, 'reward': 7.640589311420923, 'stats_actions': {2: 10, 3: 8, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 125\n",
      "{'distance_to_goal': 0.08066830039024353, 'success': 1.0, 'spl': 0.8890661266246386, 'reward': 6.216732517480852, 'stats_actions': {3: 18, 1: 19, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 126\n",
      "{'distance_to_goal': 0.1363016664981842, 'success': 1.0, 'spl': 0.8066386836673046, 'reward': 6.865189841985707, 'stats_actions': {3: 25, 1: 25, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 127\n",
      "{'distance_to_goal': 0.11694446951150894, 'success': 1.0, 'spl': 0.29342751024277325, 'reward': 3.777479358613493, 'stats_actions': {2: 20, 3: 22, 1: 46, 0: 1}}\n",
      "\n",
      "Episodes finished: 128\n",
      "{'distance_to_goal': 0.07460582256317139, 'success': 1.0, 'spl': 0.9080772129274245, 'reward': 7.039818997383121, 'stats_actions': {3: 10, 2: 5, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 129\n",
      "{'distance_to_goal': 0.1504397690296173, 'success': 1.0, 'spl': 1.0, 'reward': 5.633398255109789, 'stats_actions': {2: 7, 3: 4, 1: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 130\n",
      "{'distance_to_goal': 0.057573504745960236, 'success': 1.0, 'spl': 0.48098799616738624, 'reward': 6.0309356352686905, 'stats_actions': {3: 34, 1: 41, 2: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 131\n",
      "{'distance_to_goal': 0.07082062214612961, 'success': 1.0, 'spl': 0.892835504508283, 'reward': 5.620521369278433, 'stats_actions': {2: 5, 3: 16, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 132\n",
      "{'distance_to_goal': 0.035776473581790924, 'success': 1.0, 'spl': 0.9845269441613347, 'reward': 5.667281063497067, 'stats_actions': {3: 5, 1: 14, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 133\n",
      "{'distance_to_goal': 0.062355510890483856, 'success': 1.0, 'spl': 0.9865173734009073, 'reward': 6.974996688663962, 'stats_actions': {3: 10, 1: 20, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 134\n",
      "{'distance_to_goal': 0.11239879578351974, 'success': 1.0, 'spl': 0.9197788844330783, 'reward': 6.568174057304864, 'stats_actions': {3: 14, 2: 4, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 135\n",
      "{'distance_to_goal': 0.1578671634197235, 'success': 1.0, 'spl': 1.0, 'reward': 4.595880557298662, 'stats_actions': {2: 10, 3: 2, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 136\n",
      "{'distance_to_goal': 0.1341576874256134, 'success': 1.0, 'spl': 0.9618863188296009, 'reward': 6.814308727979663, 'stats_actions': {2: 12, 3: 5, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 137\n",
      "{'distance_to_goal': 0.019706115126609802, 'success': 1.0, 'spl': 0.9371473026278564, 'reward': 6.691743279099467, 'stats_actions': {2: 1, 1: 19, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 138\n",
      "{'distance_to_goal': 0.030881261453032494, 'success': 1.0, 'spl': 0.9433843910992471, 'reward': 5.95265685118735, 'stats_actions': {2: 7, 3: 5, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 139\n",
      "{'distance_to_goal': 0.08478530496358871, 'success': 1.0, 'spl': 0.9508242250454194, 'reward': 6.395812381803993, 'stats_actions': {2: 4, 3: 7, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 140\n",
      "{'distance_to_goal': 0.09065236151218414, 'success': 1.0, 'spl': 0.9736094638758723, 'reward': 5.088711385130884, 'stats_actions': {3: 9, 1: 12, 2: 1, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:10:06.832574 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:10:06.832618 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:10:06.832626 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:10:06.832633 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:10:06.899228 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Eastville.navmesh\n",
      "I1122 12:10:06.832826 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:10:06.834890 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:10:06.834900 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:10:06.835572 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Eastville.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:10:06.873162 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Eastville.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Eastville.scene_instance.json\n",
      "I1122 12:10:06.873176 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Eastville.glb so loading/creating a new StageAttributes with this name, and tI1122 12:10:06.899945 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 141\n",
      "{'distance_to_goal': 0.10366756469011307, 'success': 1.0, 'spl': 0.9501255568489247, 'reward': 6.321897582709792, 'stats_actions': {3: 13, 1: 18, 2: 3, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hen creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:10:06.873209 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Eastville.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Eastville.stage_config.json\n",
      "I1122 12:10:06.873214 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Eastville.stage_config.json from original name : data/scene_datasets/gibson/Eastville.glb | This file  does not exist.\n",
      "I1122 12:10:06.873281 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Eastville.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:10:06.873304 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eastville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:10:06.873308 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:10:06.873314 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Eastville.navmesh\n",
      "I1122 12:10:06.873319 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Eastville.navmesh\n",
      "I1122 12:10:06.873474 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:10:06.873502 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:10:06.873507 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Eastville.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Eastville.scn\n",
      "E1122 12:10:06.873528 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Eastville.scn does not exist.  Aborting load.\n",
      "W1122 12:10:06.873535 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Eastville.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:10:06.873579 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:10:06.873585 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Eastville.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:10:06.873598 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Eastville.glb with render asset : data/scene_datasets/gibson/Eastville.glb and collision asset : data/scene_datasets/gibson/Eastville.glb\n",
      "I1122 12:10:06.873608 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:10:06.873612 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Eastville.glb.\n",
      "I1122 12:10:06.873615 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Eastville.glb \n",
      "I1122 12:10:06.873625 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Eastville.glb\n",
      "I1122 12:10:06.898496 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Eastville.glb\n",
      "W1122 12:10:06.898515 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:10:06.898523 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eastville.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eastville.glb.\n",
      "I1122 12:10:06.898535 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eastville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:10:06.898538 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:10:06.898547 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eastville.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eastville.glb.\n",
      "I1122 12:10:06.898553 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eastville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:10:06.898557 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:10:06.898567 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Eastville.glb with renderer.\n",
      "I1122 12:10:06.909976 316358080 PathFinder.cpp:382] Building navmesh with 208x281 cells\n",
      "I1122 12:10:06.979066 316358080 PathFinder.cpp:652] Created navmesh with 209 vertices 104 polygons\n",
      "I1122 12:10:06.979084 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 142\n",
      "{'distance_to_goal': 0.16148850321769714, 'success': 1.0, 'spl': 0.5280920519399155, 'reward': 8.293210631608972, 'stats_actions': {1: 55, 3: 46, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 143\n",
      "{'distance_to_goal': 0.1352018117904663, 'success': 1.0, 'spl': 0.7950815561680931, 'reward': 11.138116936683668, 'stats_actions': {3: 14, 1: 49, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 144\n",
      "{'distance_to_goal': 0.11686450988054276, 'success': 1.0, 'spl': 0.972653619502745, 'reward': 8.25608322113753, 'stats_actions': {3: 12, 1: 28, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 145\n",
      "{'distance_to_goal': 0.09100434184074402, 'success': 1.0, 'spl': 0.9696820749555746, 'reward': 9.703415881395347, 'stats_actions': {3: 10, 1: 33, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 146\n",
      "{'distance_to_goal': 0.01764201931655407, 'success': 1.0, 'spl': 0.8992043598831416, 'reward': 10.609632188752302, 'stats_actions': {2: 5, 3: 35, 1: 41, 0: 1}}\n",
      "\n",
      "Episodes finished: 147\n",
      "{'distance_to_goal': 0.13306695222854614, 'success': 1.0, 'spl': 0.9680575353209341, 'reward': 12.880922343730937, 'stats_actions': {1: 47, 3: 8, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 148\n",
      "{'distance_to_goal': 0.050887465476989746, 'success': 1.0, 'spl': 0.5095266328332884, 'reward': 7.6606885385513435, 'stats_actions': {2: 23, 3: 23, 1: 51, 0: 1}}\n",
      "\n",
      "Episodes finished: 149\n",
      "{'distance_to_goal': 0.08140037953853607, 'success': 1.0, 'spl': 0.34091544838373045, 'reward': 7.954737430214895, 'stats_actions': {2: 16, 3: 51, 1: 83, 0: 1}}\n",
      "\n",
      "Episodes finished: 150\n",
      "{'distance_to_goal': 0.07729154080152512, 'success': 1.0, 'spl': 0.976320711379731, 'reward': 7.6568465855717704, 'stats_actions': {3: 9, 1: 23, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 151\n",
      "{'distance_to_goal': 0.05178546905517578, 'success': 1.0, 'spl': 0.8244810310422224, 'reward': 6.151212863922123, 'stats_actions': {2: 22, 1: 44, 3: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 152\n",
      "{'distance_to_goal': 0.0447920560836792, 'success': 1.0, 'spl': 0.9476884739636069, 'reward': 8.591457486152654, 'stats_actions': {2: 5, 3: 16, 1: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 153\n",
      "{'distance_to_goal': 0.10127938538789749, 'success': 1.0, 'spl': 0.9428541623085184, 'reward': 7.6672315284609835, 'stats_actions': {3: 8, 1: 24, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 154\n",
      "{'distance_to_goal': 0.06519930064678192, 'success': 1.0, 'spl': 0.5683946658110947, 'reward': 6.757785013318065, 'stats_actions': {2: 8, 3: 21, 1: 35, 0: 1}}\n",
      "\n",
      "Episodes finished: 155\n",
      "{'distance_to_goal': 0.13294386863708496, 'success': 1.0, 'spl': 0.7962126948948296, 'reward': 6.098057165145883, 'stats_actions': {2: 11, 3: 27, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 156\n",
      "{'distance_to_goal': 0.11774235963821411, 'success': 1.0, 'spl': 0.8332044416907594, 'reward': 13.630378596782696, 'stats_actions': {2: 3, 3: 44, 1: 59, 0: 1}}\n",
      "\n",
      "Episodes finished: 157\n",
      "{'distance_to_goal': 0.1472196727991104, 'success': 1.0, 'spl': 0.967226362111476, 'reward': 10.577124008536346, 'stats_actions': {3: 11, 1: 39, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 158\n",
      "{'distance_to_goal': 0.10505561530590057, 'success': 1.0, 'spl': 0.8105032481825786, 'reward': 11.742643817067158, 'stats_actions': {3: 41, 1: 51, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 159\n",
      "{'distance_to_goal': 0.10901033878326416, 'success': 1.0, 'spl': 0.5214761222067404, 'reward': 5.749981341362002, 'stats_actions': {2: 11, 3: 26, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 160\n",
      "{'distance_to_goal': 0.11411698162555695, 'success': 1.0, 'spl': 0.6980647573847165, 'reward': 5.8329421919584306, 'stats_actions': {3: 18, 1: 24, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 161\n",
      "{'distance_to_goal': 0.1898735761642456, 'success': 1.0, 'spl': 0.9298694340933167, 'reward': 7.064409031867984, 'stats_actions': {2: 1, 3: 12, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 162\n",
      "{'distance_to_goal': 0.06895311921834946, 'success': 1.0, 'spl': 0.8637489686607456, 'reward': 7.772388204634194, 'stats_actions': {3: 13, 1: 27, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 163\n",
      "{'distance_to_goal': 0.051096346229314804, 'success': 1.0, 'spl': 0.5438363381349669, 'reward': 8.184297025352723, 'stats_actions': {2: 7, 3: 34, 1: 49, 0: 1}}\n",
      "\n",
      "Episodes finished: 164\n",
      "{'distance_to_goal': 0.024173546582460403, 'success': 1.0, 'spl': 0.9044970208678174, 'reward': 9.986872519701727, 'stats_actions': {3: 20, 1: 36, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 165\n",
      "{'distance_to_goal': 0.060670480132102966, 'success': 1.0, 'spl': 0.6171800974121664, 'reward': 12.03139769613745, 'stats_actions': {2: 20, 3: 29, 1: 77, 0: 1}}\n",
      "\n",
      "Episodes finished: 166\n",
      "{'distance_to_goal': 0.06203368306159973, 'success': 1.0, 'spl': 0.9647374406346944, 'reward': 9.663531540632254, 'stats_actions': {3: 10, 1: 32, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 167\n",
      "{'distance_to_goal': 0.13825362920761108, 'success': 1.0, 'spl': 0.9372281871180648, 'reward': 13.199616549015056, 'stats_actions': {3: 13, 1: 50, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 168\n",
      "{'distance_to_goal': 0.10506410896778107, 'success': 1.0, 'spl': 0.8504575769263345, 'reward': 10.429604012370124, 'stats_actions': {3: 19, 1: 42, 2: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 169\n",
      "{'distance_to_goal': 5.881596565246582, 'success': 0.0, 'spl': 0.0, 'reward': 1.5932331085206022, 'stats_actions': {3: 105, 1: 296, 2: 99}}\n",
      "\n",
      "Episodes finished: 170\n",
      "{'distance_to_goal': 0.09281996637582779, 'success': 1.0, 'spl': 0.1777045553236054, 'reward': 2.464411555230646, 'stats_actions': {3: 85, 1: 157, 2: 47, 0: 1}}\n",
      "\n",
      "Episodes finished: 171\n",
      "{'distance_to_goal': 0.07650740444660187, 'success': 1.0, 'spl': 0.4242081202222746, 'reward': 7.077701160311707, 'stats_actions': {3: 26, 1: 56, 2: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 172\n",
      "{'distance_to_goal': 0.174441397190094, 'success': 1.0, 'spl': 0.9746485668369146, 'reward': 7.976631639003759, 'stats_actions': {2: 12, 3: 6, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 173\n",
      "{'distance_to_goal': 0.12363719940185547, 'success': 1.0, 'spl': 0.7159742864912861, 'reward': 6.2767749786376985, 'stats_actions': {2: 5, 3: 10, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 174\n",
      "{'distance_to_goal': 0.0964207723736763, 'success': 1.0, 'spl': 0.6754661251613542, 'reward': 11.930883037745973, 'stats_actions': {3: 32, 1: 66, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 175\n",
      "{'distance_to_goal': 0.054440371692180634, 'success': 1.0, 'spl': 0.9509129792921761, 'reward': 5.06266110688448, 'stats_actions': {2: 6, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 176\n",
      "{'distance_to_goal': 0.0892600566148758, 'success': 1.0, 'spl': 0.3033552583418753, 'reward': 11.921763235926694, 'stats_actions': {2: 46, 1: 173, 3: 129, 0: 1}}\n",
      "\n",
      "Episodes finished: 177\n",
      "{'distance_to_goal': 0.13969561457633972, 'success': 1.0, 'spl': 0.7354768164770533, 'reward': 8.129010783433923, 'stats_actions': {3: 29, 1: 35, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 178\n",
      "{'distance_to_goal': 0.1166553795337677, 'success': 1.0, 'spl': 0.9079640552425507, 'reward': 11.488098610639582, 'stats_actions': {3: 19, 1: 44, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 179\n",
      "{'distance_to_goal': 0.018728110939264297, 'success': 1.0, 'spl': 0.8847561186896128, 'reward': 13.939981911033408, 'stats_actions': {3: 26, 1: 56, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 180\n",
      "{'distance_to_goal': 0.17260341346263885, 'success': 1.0, 'spl': 0.9262670741388412, 'reward': 12.057020190358173, 'stats_actions': {2: 10, 1: 45, 3: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 181\n",
      "{'distance_to_goal': 0.018441542983055115, 'success': 1.0, 'spl': 0.9308182574377398, 'reward': 10.501609612107284, 'stats_actions': {3: 14, 2: 7, 1: 37, 0: 1}}\n",
      "\n",
      "Episodes finished: 182\n",
      "{'distance_to_goal': 0.11168094724416733, 'success': 1.0, 'spl': 0.8031563574888043, 'reward': 5.98409997850657, 'stats_actions': {3: 17, 1: 20, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 183\n",
      "{'distance_to_goal': 0.13747906684875488, 'success': 1.0, 'spl': 0.8734972810313212, 'reward': 6.151634111404424, 'stats_actions': {3: 12, 1: 19, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 184\n",
      "{'distance_to_goal': 0.09200754761695862, 'success': 1.0, 'spl': 0.6152436226571082, 'reward': 6.85322877287865, 'stats_actions': {2: 9, 3: 20, 1: 33, 0: 1}}\n",
      "\n",
      "Episodes finished: 185\n",
      "{'distance_to_goal': 0.06849435716867447, 'success': 1.0, 'spl': 0.8415463817492366, 'reward': 8.44659919828177, 'stats_actions': {2: 3, 3: 16, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 186\n",
      "{'distance_to_goal': 0.0867365226149559, 'success': 1.0, 'spl': 0.8687502361794978, 'reward': 12.683192028105275, 'stats_actions': {2: 15, 1: 62, 3: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 187\n",
      "{'distance_to_goal': 0.053281839936971664, 'success': 1.0, 'spl': 0.976789316483322, 'reward': 9.119977513700729, 'stats_actions': {1: 29, 3: 4, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 188\n",
      "{'distance_to_goal': 4.985774993896484, 'success': 0.0, 'spl': 0.0, 'reward': 2.078359603881938, 'stats_actions': {3: 98, 1: 305, 2: 97}}\n",
      "\n",
      "Episodes finished: 189\n",
      "{'distance_to_goal': 0.0721556544303894, 'success': 1.0, 'spl': 0.6754195653923373, 'reward': 10.652819435596482, 'stats_actions': {3: 21, 1: 56, 2: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 190\n",
      "{'distance_to_goal': 0.06914670765399933, 'success': 1.0, 'spl': 0.9108896618992973, 'reward': 7.278401433825497, 'stats_actions': {2: 6, 3: 6, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 191\n",
      "{'distance_to_goal': 0.08394037187099457, 'success': 1.0, 'spl': 0.7081493871773429, 'reward': 8.374573841691028, 'stats_actions': {3: 28, 1: 38, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 192\n",
      "{'distance_to_goal': 6.429783821105957, 'success': 0.0, 'spl': 0.0, 'reward': 0.8249654769898038, 'stats_actions': {3: 200, 1: 225, 2: 75}}\n",
      "\n",
      "Episodes finished: 193\n",
      "{'distance_to_goal': 0.13985367119312286, 'success': 1.0, 'spl': 0.6288881188804311, 'reward': 8.06874892890455, 'stats_actions': {3: 50, 1: 87, 2: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 194\n",
      "{'distance_to_goal': 0.08984220027923584, 'success': 1.0, 'spl': 0.8704220466270483, 'reward': 8.280719933509832, 'stats_actions': {3: 12, 1: 29, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 195\n",
      "{'distance_to_goal': 0.06940831243991852, 'success': 1.0, 'spl': 0.8665146225321902, 'reward': 12.83528017938138, 'stats_actions': {3: 30, 1: 52, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 196\n",
      "{'distance_to_goal': 0.10910031944513321, 'success': 1.0, 'spl': 0.7653966410675268, 'reward': 12.912670272290736, 'stats_actions': {3: 30, 1: 108, 2: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 197\n",
      "{'distance_to_goal': 0.10104665160179138, 'success': 1.0, 'spl': 0.5439683938558296, 'reward': 9.9031359732152, 'stats_actions': {3: 99, 1: 273, 2: 97, 0: 1}}\n",
      "\n",
      "Episodes finished: 198\n",
      "{'distance_to_goal': 0.08296036720275879, 'success': 1.0, 'spl': 0.5067164906062096, 'reward': 8.50273146629337, 'stats_actions': {2: 42, 1: 110, 3: 32, 0: 1}}\n",
      "\n",
      "Episodes finished: 199\n",
      "{'distance_to_goal': 0.13929858803749084, 'success': 1.0, 'spl': 0.5880849560706489, 'reward': 10.774341663122197, 'stats_actions': {2: 20, 3: 31, 1: 74, 0: 1}}\n",
      "\n",
      "Episodes finished: 200\n",
      "{'distance_to_goal': 7.226285457611084, 'success': 0.0, 'spl': 0.0, 'reward': -3.0423350334166965, 'stats_actions': {2: 77, 3: 154, 1: 269}}\n",
      "\n",
      "Episodes finished: 201\n",
      "{'distance_to_goal': 0.07267381995916367, 'success': 1.0, 'spl': 0.23695840217974046, 'reward': 8.698496719896857, 'stats_actions': {2: 47, 1: 164, 3: 121, 0: 1}}\n",
      "\n",
      "Episodes finished: 202\n",
      "{'distance_to_goal': 1.2975506782531738, 'success': 0.0, 'spl': 0.0, 'reward': -4.692605495452826, 'stats_actions': {2: 145, 1: 215, 3: 140}}\n",
      "\n",
      "Episodes finished: 203\n",
      "{'distance_to_goal': 0.08819074183702469, 'success': 1.0, 'spl': 0.9626560175018205, 'reward': 5.944007925689223, 'stats_actions': {1: 16, 3: 5, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 204\n",
      "{'distance_to_goal': 0.10573270171880722, 'success': 1.0, 'spl': 0.9187074860750246, 'reward': 13.39090227752925, 'stats_actions': {3: 13, 1: 51, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 205\n",
      "{'distance_to_goal': 0.14015503227710724, 'success': 1.0, 'spl': 0.8558855751493742, 'reward': 6.121616360545161, 'stats_actions': {3: 8, 1: 20, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 206\n",
      "{'distance_to_goal': 0.13623569905757904, 'success': 1.0, 'spl': 0.8633032765229257, 'reward': 8.51409890711308, 'stats_actions': {3: 14, 1: 31, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 207\n",
      "{'distance_to_goal': 0.18411561846733093, 'success': 1.0, 'spl': 0.255165687598007, 'reward': 5.614206296205529, 'stats_actions': {3: 27, 2: 28, 1: 74, 0: 1}}\n",
      "\n",
      "Episodes finished: 208\n",
      "{'distance_to_goal': 0.1523076742887497, 'success': 1.0, 'spl': 0.6276723854014096, 'reward': 11.174173534512557, 'stats_actions': {3: 41, 1: 111, 2: 36, 0: 1}}\n",
      "\n",
      "Episodes finished: 209\n",
      "{'distance_to_goal': 0.042328376322984695, 'success': 1.0, 'spl': 0.6193896861552133, 'reward': 8.596459064930684, 'stats_actions': {2: 11, 3: 25, 1: 45, 0: 1}}\n",
      "\n",
      "Episodes finished: 210\n",
      "{'distance_to_goal': 0.009948077611625195, 'success': 1.0, 'spl': 0.9322525180367315, 'reward': 6.140008835382761, 'stats_actions': {3: 7, 2: 3, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 211\n",
      "{'distance_to_goal': 0.09934117645025253, 'success': 1.0, 'spl': 0.8904552360221533, 'reward': 11.100437952578076, 'stats_actions': {2: 4, 3: 18, 1: 42, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:13:59.915829 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Elmira.navmesh\n",
      "I1122 12:13:59.858276 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:13:59.858302 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:13:59.858306 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:13:59.858309 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:13:59.858445 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:13:59.859383 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:13:59.859390 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:13:59.860247 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Elmira.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:13:59.896029 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Elmira.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Elmira.scene_instance.json\n",
      "I1122 12:13:59.896045 316358080 MetadataMedI1122 12:13:59.916685 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 212\n",
      "{'distance_to_goal': 0.11069879680871964, 'success': 1.0, 'spl': 0.7988535543292575, 'reward': 9.417328089177616, 'stats_actions': {2: 8, 3: 20, 1: 39, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Elmira.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:13:59.896051 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Elmira.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Elmira.stage_config.json\n",
      "I1122 12:13:59.896055 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Elmira.stage_config.json from original name : data/scene_datasets/gibson/Elmira.glb | This file  does not exist.\n",
      "I1122 12:13:59.896104 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Elmira.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:13:59.896127 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Elmira.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:13:59.896131 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:13:59.896137 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Elmira.navmesh\n",
      "I1122 12:13:59.896142 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Elmira.navmesh\n",
      "I1122 12:13:59.896209 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:13:59.896214 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:13:59.896219 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Elmira.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Elmira.scn\n",
      "E1122 12:13:59.896224 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Elmira.scn does not exist.  Aborting load.\n",
      "W1122 12:13:59.896231 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Elmira.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:13:59.896349 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:13:59.896356 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Elmira.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:13:59.896385 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Elmira.glb with render asset : data/scene_datasets/gibson/Elmira.glb and collision asset : data/scene_datasets/gibson/Elmira.glb\n",
      "I1122 12:13:59.896416 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:13:59.896420 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Elmira.glb.\n",
      "I1122 12:13:59.896423 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Elmira.glb \n",
      "I1122 12:13:59.896457 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Elmira.glb\n",
      "I1122 12:13:59.915033 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Elmira.glb\n",
      "W1122 12:13:59.915052 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:13:59.915060 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Elmira.glb yields 1 candidates.  Using data/scene_datasets/gibson/Elmira.glb.\n",
      "I1122 12:13:59.915071 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Elmira.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:13:59.915076 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:13:59.915086 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Elmira.glb yields 1 candidates.  Using data/scene_datasets/gibson/Elmira.glb.\n",
      "I1122 12:13:59.915092 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Elmira.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:13:59.915096 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:13:59.915107 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Elmira.glb with renderer.\n",
      "I1122 12:13:59.921346 316358080 PathFinder.cpp:382] Building navmesh with 107x169 cells\n",
      "I1122 12:13:59.974170 316358080 PathFinder.cpp:652] Created navmesh with 52 vertices 24 polygons\n",
      "I1122 12:13:59.974349 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 213\n",
      "{'distance_to_goal': 0.08309789001941681, 'success': 1.0, 'spl': 0.9456649466529679, 'reward': 5.494251534342768, 'stats_actions': {3: 9, 1: 14, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 214\n",
      "{'distance_to_goal': 0.09351222217082977, 'success': 1.0, 'spl': 0.9245968561514795, 'reward': 4.991838510632516, 'stats_actions': {3: 8, 1: 13, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 215\n",
      "{'distance_to_goal': 0.07115107029676437, 'success': 1.0, 'spl': 0.8619979572413596, 'reward': 6.312009387314322, 'stats_actions': {3: 25, 1: 28, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 216\n",
      "{'distance_to_goal': 0.07231642305850983, 'success': 1.0, 'spl': 0.8747916087631825, 'reward': 5.5460391944646865, 'stats_actions': {3: 13, 2: 9, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 217\n",
      "{'distance_to_goal': 0.0701940730214119, 'success': 1.0, 'spl': 0.8346339120591435, 'reward': 6.488535823524002, 'stats_actions': {2: 20, 3: 27, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 218\n",
      "{'distance_to_goal': 0.04935001954436302, 'success': 1.0, 'spl': 0.9627246639418382, 'reward': 5.427602991014719, 'stats_actions': {3: 7, 1: 15, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 219\n",
      "{'distance_to_goal': 0.08513739705085754, 'success': 1.0, 'spl': 0.9378688943887324, 'reward': 7.40760952830315, 'stats_actions': {2: 3, 3: 13, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 220\n",
      "{'distance_to_goal': 0.10183417052030563, 'success': 1.0, 'spl': 0.9297971150877319, 'reward': 6.500574219524864, 'stats_actions': {2: 9, 3: 20, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 221\n",
      "{'distance_to_goal': 0.04881235957145691, 'success': 1.0, 'spl': 0.9173945380259998, 'reward': 7.628023577928547, 'stats_actions': {3: 7, 1: 24, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 222\n",
      "{'distance_to_goal': 0.05892825126647949, 'success': 1.0, 'spl': 0.919125226071098, 'reward': 5.542897653579714, 'stats_actions': {3: 10, 1: 15, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 223\n",
      "{'distance_to_goal': 0.1453746110200882, 'success': 1.0, 'spl': 0.6169153645262633, 'reward': 5.970079528689387, 'stats_actions': {3: 19, 1: 28, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 224\n",
      "{'distance_to_goal': 0.06909278780221939, 'success': 1.0, 'spl': 0.9379476657510045, 'reward': 7.239131852090362, 'stats_actions': {2: 17, 3: 11, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 225\n",
      "{'distance_to_goal': 0.09674808382987976, 'success': 1.0, 'spl': 0.9905915346135123, 'reward': 6.093176118135454, 'stats_actions': {2: 9, 3: 3, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 226\n",
      "{'distance_to_goal': 0.05565385892987251, 'success': 1.0, 'spl': 0.9561847423607593, 'reward': 6.716223410815003, 'stats_actions': {3: 7, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 227\n",
      "{'distance_to_goal': 0.03381988778710365, 'success': 1.0, 'spl': 0.9776285210631902, 'reward': 6.01472871527076, 'stats_actions': {3: 11, 1: 16, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 228\n",
      "{'distance_to_goal': 0.03958002105355263, 'success': 1.0, 'spl': 0.9622882272333511, 'reward': 5.671687316745521, 'stats_actions': {3: 21, 1: 15, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 229\n",
      "{'distance_to_goal': 0.12445234507322311, 'success': 1.0, 'spl': 0.9769366032878783, 'reward': 6.188257863819601, 'stats_actions': {3: 7, 1: 17, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 230\n",
      "{'distance_to_goal': 0.021325647830963135, 'success': 1.0, 'spl': 0.9049986247276983, 'reward': 9.03102840185166, 'stats_actions': {2: 3, 3: 19, 1: 32, 0: 1}}\n",
      "\n",
      "Episodes finished: 231\n",
      "{'distance_to_goal': 0.09295085072517395, 'success': 1.0, 'spl': 0.9782713223445028, 'reward': 4.098591545820236, 'stats_actions': {3: 8, 1: 11, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 232\n",
      "{'distance_to_goal': 0.12619532644748688, 'success': 1.0, 'spl': 0.7744957228161401, 'reward': 6.411549271941188, 'stats_actions': {3: 18, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 233\n",
      "{'distance_to_goal': 0.09380937367677689, 'success': 1.0, 'spl': 1.0, 'reward': 5.1546216031909, 'stats_actions': {3: 7, 1: 12, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 234\n",
      "{'distance_to_goal': 0.0753258615732193, 'success': 1.0, 'spl': 0.9443004257590407, 'reward': 8.027938413023955, 'stats_actions': {2: 15, 3: 11, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 235\n",
      "{'distance_to_goal': 0.10750151425600052, 'success': 1.0, 'spl': 0.9359541413043966, 'reward': 5.010361244380475, 'stats_actions': {3: 6, 1: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 236\n",
      "{'distance_to_goal': 0.0310717411339283, 'success': 1.0, 'spl': 0.702068454671076, 'reward': 5.849833190888169, 'stats_actions': {2: 4, 3: 21, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 237\n",
      "{'distance_to_goal': 0.13522428274154663, 'success': 1.0, 'spl': 0.8848476580754203, 'reward': 5.795376760959629, 'stats_actions': {3: 12, 1: 17, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 238\n",
      "{'distance_to_goal': 0.1175718829035759, 'success': 1.0, 'spl': 0.8149761089768073, 'reward': 5.945641255676748, 'stats_actions': {2: 8, 3: 18, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 239\n",
      "{'distance_to_goal': 0.09546366333961487, 'success': 1.0, 'spl': 0.9399393789871308, 'reward': 7.996385015249257, 'stats_actions': {2: 2, 3: 14, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 240\n",
      "{'distance_to_goal': 0.013662569224834442, 'success': 1.0, 'spl': 0.9635067428781886, 'reward': 3.9903535202145575, 'stats_actions': {3: 5, 1: 9, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 241\n",
      "{'distance_to_goal': 0.10475953668355942, 'success': 1.0, 'spl': 1.0, 'reward': 5.772028993666174, 'stats_actions': {3: 10, 1: 16, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 242\n",
      "{'distance_to_goal': 0.13137872517108917, 'success': 1.0, 'spl': 0.6292213644597724, 'reward': 5.5941848772764216, 'stats_actions': {3: 10, 1: 24, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 243\n",
      "{'distance_to_goal': 0.10706216096878052, 'success': 1.0, 'spl': 0.9250015420556461, 'reward': 7.6285755419731185, 'stats_actions': {3: 26, 1: 29, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 244\n",
      "{'distance_to_goal': 0.12325490266084671, 'success': 1.0, 'spl': 0.7714095930860786, 'reward': 4.919531600177288, 'stats_actions': {2: 5, 1: 15, 3: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 245\n",
      "{'distance_to_goal': 0.0900670513510704, 'success': 1.0, 'spl': 0.8944701799513876, 'reward': 6.863300525248054, 'stats_actions': {3: 8, 1: 22, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 246\n",
      "{'distance_to_goal': 0.12176378816366196, 'success': 1.0, 'spl': 0.9789922420963855, 'reward': 6.151795648634438, 'stats_actions': {3: 11, 1: 18, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 247\n",
      "{'distance_to_goal': 0.19213229417800903, 'success': 1.0, 'spl': 0.6909820169157155, 'reward': 5.088936469554902, 'stats_actions': {2: 20, 1: 35, 3: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 248\n",
      "{'distance_to_goal': 0.11000705510377884, 'success': 1.0, 'spl': 0.9505517784638016, 'reward': 6.9687059804797205, 'stats_actions': {3: 9, 1: 23, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 249\n",
      "{'distance_to_goal': 0.06984231621026993, 'success': 1.0, 'spl': 0.9454546000048261, 'reward': 8.144841178357606, 'stats_actions': {3: 15, 2: 11, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 250\n",
      "{'distance_to_goal': 0.06237572059035301, 'success': 1.0, 'spl': 0.9514489006915001, 'reward': 9.684448524862535, 'stats_actions': {3: 8, 1: 34, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 251\n",
      "{'distance_to_goal': 0.14632141590118408, 'success': 1.0, 'spl': 0.9234680482056671, 'reward': 6.45323123455048, 'stats_actions': {3: 16, 1: 22, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 252\n",
      "{'distance_to_goal': 0.0588780976831913, 'success': 1.0, 'spl': 0.9605582793332316, 'reward': 4.99941680893302, 'stats_actions': {2: 7, 3: 13, 1: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 253\n",
      "{'distance_to_goal': 0.11192169040441513, 'success': 1.0, 'spl': 0.9904745902069241, 'reward': 6.634315702021124, 'stats_actions': {2: 12, 3: 5, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 254\n",
      "{'distance_to_goal': 0.066621795296669, 'success': 1.0, 'spl': 0.8292464974805379, 'reward': 6.683027004599575, 'stats_actions': {3: 23, 1: 23, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 255\n",
      "{'distance_to_goal': 0.13367053866386414, 'success': 1.0, 'spl': 0.9459159316517471, 'reward': 6.568843594789509, 'stats_actions': {3: 18, 1: 22, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 256\n",
      "{'distance_to_goal': 0.08643735200166702, 'success': 1.0, 'spl': 0.5737992453567564, 'reward': 5.124064786136152, 'stats_actions': {3: 20, 1: 23, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 257\n",
      "{'distance_to_goal': 0.01132859755307436, 'success': 1.0, 'spl': 0.9695425660903482, 'reward': 6.929228519909087, 'stats_actions': {3: 9, 1: 21, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 258\n",
      "{'distance_to_goal': 0.03090503439307213, 'success': 1.0, 'spl': 0.9354123228405244, 'reward': 6.486953089386227, 'stats_actions': {3: 8, 1: 21, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 259\n",
      "{'distance_to_goal': 0.10108687728643417, 'success': 1.0, 'spl': 0.9591048509716655, 'reward': 9.115516115725047, 'stats_actions': {3: 12, 1: 33, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 260\n",
      "{'distance_to_goal': 0.1143474280834198, 'success': 1.0, 'spl': 0.9821187419703253, 'reward': 5.762523146867753, 'stats_actions': {3: 8, 1: 15, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 261\n",
      "{'distance_to_goal': 0.0689893513917923, 'success': 1.0, 'spl': 0.9011217874645147, 'reward': 6.236179830431941, 'stats_actions': {3: 18, 2: 4, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 262\n",
      "{'distance_to_goal': 0.08387496322393417, 'success': 1.0, 'spl': 0.7043202420908404, 'reward': 6.512080618441107, 'stats_actions': {3: 22, 1: 38, 2: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 263\n",
      "{'distance_to_goal': 0.17560236155986786, 'success': 1.0, 'spl': 0.9632771175317884, 'reward': 6.516101320385936, 'stats_actions': {3: 11, 1: 19, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 264\n",
      "{'distance_to_goal': 0.022527078166604042, 'success': 1.0, 'spl': 0.5378744016026984, 'reward': 6.117889410480858, 'stats_actions': {2: 10, 3: 21, 1: 32, 0: 1}}\n",
      "\n",
      "Episodes finished: 265\n",
      "{'distance_to_goal': 0.04821094870567322, 'success': 1.0, 'spl': 0.8829189511041391, 'reward': 4.3890863764286046, 'stats_actions': {2: 3, 3: 13, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 266\n",
      "{'distance_to_goal': 0.044152457267045975, 'success': 1.0, 'spl': 0.9674667373237659, 'reward': 6.659111245125534, 'stats_actions': {3: 5, 1: 20, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 267\n",
      "{'distance_to_goal': 0.03181975334882736, 'success': 1.0, 'spl': 0.8926543699804018, 'reward': 6.71722355872393, 'stats_actions': {3: 16, 1: 21, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 268\n",
      "{'distance_to_goal': 0.1064690500497818, 'success': 1.0, 'spl': 0.6764032799823286, 'reward': 6.410793599486353, 'stats_actions': {3: 50, 1: 42, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 269\n",
      "{'distance_to_goal': 0.14740276336669922, 'success': 1.0, 'spl': 0.7057008989233879, 'reward': 5.678053646087648, 'stats_actions': {3: 16, 1: 22, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 270\n",
      "{'distance_to_goal': 0.06286852806806564, 'success': 1.0, 'spl': 0.9512195378616329, 'reward': 6.3700113394856475, 'stats_actions': {3: 5, 1: 18, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 271\n",
      "{'distance_to_goal': 0.05797608196735382, 'success': 1.0, 'spl': 0.9450298763328362, 'reward': 7.088073665499691, 'stats_actions': {3: 14, 1: 23, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 272\n",
      "{'distance_to_goal': 0.02835320122539997, 'success': 1.0, 'spl': 0.976707570486031, 'reward': 4.703414968177677, 'stats_actions': {3: 8, 1: 10, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 273\n",
      "{'distance_to_goal': 0.10056176036596298, 'success': 1.0, 'spl': 0.8541862865797559, 'reward': 5.628472549021246, 'stats_actions': {3: 18, 1: 17, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 274\n",
      "{'distance_to_goal': 0.12396492063999176, 'success': 1.0, 'spl': 0.9193724192406902, 'reward': 4.518562259078026, 'stats_actions': {2: 2, 1: 10, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 275\n",
      "{'distance_to_goal': 0.018385915085673332, 'success': 1.0, 'spl': 0.8342666958555982, 'reward': 4.575847883895039, 'stats_actions': {3: 8, 1: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 276\n",
      "{'distance_to_goal': 0.08571797609329224, 'success': 1.0, 'spl': 0.9226362651750989, 'reward': 5.482677590847018, 'stats_actions': {3: 7, 1: 16, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 277\n",
      "{'distance_to_goal': 0.017189687117934227, 'success': 1.0, 'spl': 0.4056504282199242, 'reward': 5.309172045364978, 'stats_actions': {3: 38, 1: 56, 2: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 278\n",
      "{'distance_to_goal': 0.05923373997211456, 'success': 1.0, 'spl': 0.8783455758132218, 'reward': 5.015389577746392, 'stats_actions': {2: 2, 3: 12, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 279\n",
      "{'distance_to_goal': 0.05376080796122551, 'success': 1.0, 'spl': 0.5565368781910351, 'reward': 6.454090754538777, 'stats_actions': {3: 35, 1: 35, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 280\n",
      "{'distance_to_goal': 0.31592056155204773, 'success': 0.0, 'spl': 0.0, 'reward': -1.0818106830119383, 'stats_actions': {3: 220, 1: 208, 2: 72}}\n",
      "\n",
      "Episodes finished: 281\n",
      "{'distance_to_goal': 0.047537174075841904, 'success': 1.0, 'spl': 0.9401525455289428, 'reward': 6.314849243313077, 'stats_actions': {3: 9, 1: 18, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 282\n",
      "{'distance_to_goal': 0.1374385803937912, 'success': 1.0, 'spl': 0.968523764528709, 'reward': 5.15007697403431, 'stats_actions': {3: 10, 1: 14, 2: 9, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:15:35.923528 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Eudora.navmesh\n",
      "I1122 12:15:35.865998 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:15:35.866024 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:15:35.866029 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:15:35.866032 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:15:35.866161 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:15:35.867233 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:15:35.867239 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:15:35.868240 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Eudora.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:15:35.903474 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Eudora.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Eudora.scene_instance.json\n",
      "I1122 12:15:35.903488 316358080 MetadataMedI1122 12:15:35.924472 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 283\n",
      "{'distance_to_goal': 0.08251208811998367, 'success': 1.0, 'spl': 0.9747842717592944, 'reward': 6.906895832717422, 'stats_actions': {2: 7, 3: 7, 1: 20, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Eudora.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:15:35.903493 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Eudora.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Eudora.stage_config.json\n",
      "I1122 12:15:35.903497 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Eudora.stage_config.json from original name : data/scene_datasets/gibson/Eudora.glb | This file  does not exist.\n",
      "I1122 12:15:35.903545 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Eudora.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:15:35.903569 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eudora.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:15:35.903573 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:15:35.903579 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Eudora.navmesh\n",
      "I1122 12:15:35.903584 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Eudora.navmesh\n",
      "I1122 12:15:35.903661 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:15:35.903666 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:15:35.903671 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Eudora.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Eudora.scn\n",
      "E1122 12:15:35.903676 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Eudora.scn does not exist.  Aborting load.\n",
      "W1122 12:15:35.903682 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Eudora.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:15:35.903766 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:15:35.903771 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Eudora.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:15:35.903785 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Eudora.glb with render asset : data/scene_datasets/gibson/Eudora.glb and collision asset : data/scene_datasets/gibson/Eudora.glb\n",
      "I1122 12:15:35.903795 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:15:35.903798 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:15:35.903800 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Eudora.glb \n",
      "I1122 12:15:35.903810 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Eudora.glb\n",
      "I1122 12:15:35.922927 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Eudora.glb\n",
      "W1122 12:15:35.922945 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:15:35.922953 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eudora.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:15:35.922966 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eudora.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:15:35.922969 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:15:35.922979 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eudora.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:15:35.922986 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eudora.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:15:35.922989 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:15:35.923000 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Eudora.glb with renderer.\n",
      "I1122 12:15:35.931638 316358080 PathFinder.cpp:382] Building navmesh with 142x112 cells\n",
      "I1122 12:15:35.981775 316358080 PathFinder.cpp:652] Created navmesh with 63 vertices 27 polygons\n",
      "I1122 12:15:35.981948 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 284\n",
      "{'distance_to_goal': 0.06260564178228378, 'success': 1.0, 'spl': 0.5189104325727789, 'reward': 6.487117773592475, 'stats_actions': {2: 23, 3: 96, 1: 77, 0: 1}}\n",
      "\n",
      "Episodes finished: 285\n",
      "{'distance_to_goal': 0.09398368000984192, 'success': 1.0, 'spl': 0.9352807540558022, 'reward': 5.43351502299309, 'stats_actions': {3: 7, 1: 14, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 286\n",
      "{'distance_to_goal': 0.05308609828352928, 'success': 1.0, 'spl': 0.8295022763212747, 'reward': 6.170924731642011, 'stats_actions': {3: 12, 1: 20, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 287\n",
      "{'distance_to_goal': 0.04300776869058609, 'success': 1.0, 'spl': 0.12846791613401767, 'reward': 3.3938510569930136, 'stats_actions': {2: 62, 3: 213, 1: 181, 0: 1}}\n",
      "\n",
      "Episodes finished: 288\n",
      "{'distance_to_goal': 0.15115751326084137, 'success': 1.0, 'spl': 0.48754627039577025, 'reward': 5.30134149491787, 'stats_actions': {3: 187, 1: 167, 2: 35, 0: 1}}\n",
      "\n",
      "Episodes finished: 289\n",
      "{'distance_to_goal': 0.06601656228303909, 'success': 1.0, 'spl': 0.9831891195802381, 'reward': 5.326769683063032, 'stats_actions': {3: 9, 2: 4, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 290\n",
      "{'distance_to_goal': 0.14324700832366943, 'success': 1.0, 'spl': 0.719364715074551, 'reward': 4.950214743614199, 'stats_actions': {3: 26, 1: 19, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 291\n",
      "{'distance_to_goal': 0.029275434091687202, 'success': 1.0, 'spl': 0.6334969757736313, 'reward': 6.690644037649038, 'stats_actions': {3: 45, 2: 13, 1: 38, 0: 1}}\n",
      "\n",
      "Episodes finished: 292\n",
      "{'distance_to_goal': 0.12853385508060455, 'success': 1.0, 'spl': 0.8326413718936003, 'reward': 5.68302946507931, 'stats_actions': {3: 22, 1: 18, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 293\n",
      "{'distance_to_goal': 0.12086030840873718, 'success': 1.0, 'spl': 0.9756862172797562, 'reward': 6.685587102174762, 'stats_actions': {3: 9, 1: 19, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 294\n",
      "{'distance_to_goal': 0.10606169700622559, 'success': 1.0, 'spl': 0.46760351694407265, 'reward': 5.1234682559967055, 'stats_actions': {3: 70, 1: 55, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 295\n",
      "{'distance_to_goal': 0.06220650300383568, 'success': 1.0, 'spl': 0.8420531535770713, 'reward': 6.502100786119702, 'stats_actions': {3: 12, 1: 22, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 296\n",
      "{'distance_to_goal': 0.08067967742681503, 'success': 1.0, 'spl': 0.7467830789082295, 'reward': 6.1507898965477965, 'stats_actions': {3: 29, 2: 3, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 297\n",
      "{'distance_to_goal': 0.10026850551366806, 'success': 1.0, 'spl': 0.9851849968760911, 'reward': 4.983553306162358, 'stats_actions': {3: 6, 2: 1, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 298\n",
      "{'distance_to_goal': 0.10393289476633072, 'success': 1.0, 'spl': 0.8219816795812854, 'reward': 6.065975209176545, 'stats_actions': {3: 18, 1: 20, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 299\n",
      "{'distance_to_goal': 0.04445479065179825, 'success': 1.0, 'spl': 0.898984098611394, 'reward': 6.368724606931212, 'stats_actions': {2: 7, 3: 19, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 300\n",
      "{'distance_to_goal': 0.013568449765443802, 'success': 1.0, 'spl': 0.805910807278834, 'reward': 6.886489190310243, 'stats_actions': {3: 12, 1: 24, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 301\n",
      "{'distance_to_goal': 0.13874657452106476, 'success': 1.0, 'spl': 0.19245919930133032, 'reward': 3.7597427290678, 'stats_actions': {3: 158, 1: 102, 2: 32, 0: 1}}\n",
      "\n",
      "Episodes finished: 302\n",
      "{'distance_to_goal': 0.06430255621671677, 'success': 1.0, 'spl': 0.8692185171853143, 'reward': 4.5064493396878245, 'stats_actions': {3: 11, 1: 11, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 303\n",
      "{'distance_to_goal': 0.12768974900245667, 'success': 1.0, 'spl': 0.9624442079880616, 'reward': 6.846807473897937, 'stats_actions': {3: 9, 1: 20, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 304\n",
      "{'distance_to_goal': 0.08764301240444183, 'success': 1.0, 'spl': 0.5992799100713213, 'reward': 5.8265412336587925, 'stats_actions': {3: 68, 2: 15, 1: 50, 0: 1}}\n",
      "\n",
      "Episodes finished: 305\n",
      "{'distance_to_goal': 0.0840497836470604, 'success': 1.0, 'spl': 0.531168849752523, 'reward': 5.514173797667038, 'stats_actions': {3: 41, 1: 30, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 306\n",
      "{'distance_to_goal': 0.1479194313287735, 'success': 1.0, 'spl': 0.9137801229027254, 'reward': 4.657505201697352, 'stats_actions': {3: 14, 1: 12, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 307\n",
      "{'distance_to_goal': 0.05750535428524017, 'success': 1.0, 'spl': 0.995624960723386, 'reward': 6.473070550560954, 'stats_actions': {2: 9, 3: 6, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 308\n",
      "{'distance_to_goal': 7.058978080749512, 'success': 0.0, 'spl': 0.0, 'reward': -5.6835999488830105, 'stats_actions': {3: 250, 1: 205, 2: 45}}\n",
      "\n",
      "Episodes finished: 309\n",
      "{'distance_to_goal': 4.222917079925537, 'success': 0.0, 'spl': 0.0, 'reward': -5.659919261932294, 'stats_actions': {2: 38, 3: 259, 1: 203}}\n",
      "\n",
      "Episodes finished: 310\n",
      "{'distance_to_goal': 0.1421038657426834, 'success': 1.0, 'spl': 0.9544394679261472, 'reward': 5.319258143305781, 'stats_actions': {3: 12, 2: 10, 1: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 311\n",
      "{'distance_to_goal': 0.09772437065839767, 'success': 1.0, 'spl': 0.5354923549183496, 'reward': 6.858670149147513, 'stats_actions': {2: 25, 3: 148, 1: 92, 0: 1}}\n",
      "\n",
      "Episodes finished: 312\n",
      "{'distance_to_goal': 0.10414071381092072, 'success': 1.0, 'spl': 0.8595905092985014, 'reward': 5.6191190403699895, 'stats_actions': {3: 24, 1: 17, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 313\n",
      "{'distance_to_goal': 3.977184295654297, 'success': 0.0, 'spl': 0.0, 'reward': -2.404402256011939, 'stats_actions': {3: 257, 1: 203, 2: 40}}\n",
      "\n",
      "Episodes finished: 314\n",
      "{'distance_to_goal': 0.09909640997648239, 'success': 1.0, 'spl': 0.9423252884047015, 'reward': 6.494534266293051, 'stats_actions': {3: 12, 1: 19, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 315\n",
      "{'distance_to_goal': 0.1119375079870224, 'success': 1.0, 'spl': 0.5746086058414444, 'reward': 5.002840896248819, 'stats_actions': {2: 14, 1: 23, 3: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 316\n",
      "{'distance_to_goal': 0.0743488147854805, 'success': 1.0, 'spl': 0.759768668939665, 'reward': 4.962912728488447, 'stats_actions': {3: 23, 1: 18, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 317\n",
      "{'distance_to_goal': 0.09352479130029678, 'success': 1.0, 'spl': 0.8982803124402595, 'reward': 6.815963600575927, 'stats_actions': {3: 26, 2: 5, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 318\n",
      "{'distance_to_goal': 0.14847567677497864, 'success': 1.0, 'spl': 0.9488611537763539, 'reward': 6.762614067792897, 'stats_actions': {3: 16, 1: 21, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 319\n",
      "{'distance_to_goal': 0.09274782985448837, 'success': 1.0, 'spl': 0.9612572044361657, 'reward': 4.576481286585331, 'stats_actions': {2: 2, 1: 10, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 320\n",
      "{'distance_to_goal': 0.013148111291229725, 'success': 1.0, 'spl': 0.8132664077192503, 'reward': 6.384359079413119, 'stats_actions': {3: 24, 1: 22, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 321\n",
      "{'distance_to_goal': 0.12244898825883865, 'success': 1.0, 'spl': 0.9289919148520515, 'reward': 4.969654950797558, 'stats_actions': {3: 7, 2: 5, 1: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 322\n",
      "{'distance_to_goal': 6.563882827758789, 'success': 0.0, 'spl': 0.0, 'reward': -6.7404403686522585, 'stats_actions': {3: 258, 1: 204, 2: 38}}\n",
      "\n",
      "Episodes finished: 323\n",
      "{'distance_to_goal': 0.0733613595366478, 'success': 1.0, 'spl': 0.9565829478211022, 'reward': 7.12671575456858, 'stats_actions': {3: 14, 1: 22, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 324\n",
      "{'distance_to_goal': 0.0533713735640049, 'success': 1.0, 'spl': 0.5090999092223676, 'reward': 6.459360064119101, 'stats_actions': {2: 25, 3: 108, 1: 78, 0: 1}}\n",
      "\n",
      "Episodes finished: 325\n",
      "{'distance_to_goal': 5.406020641326904, 'success': 0.0, 'spl': 0.0, 'reward': -4.5535445213317205, 'stats_actions': {3: 248, 1: 197, 2: 55}}\n",
      "\n",
      "Episodes finished: 326\n",
      "{'distance_to_goal': 6.033493995666504, 'success': 0.0, 'spl': 0.0, 'reward': -5.4364094734191415, 'stats_actions': {3: 252, 1: 192, 2: 56}}\n",
      "\n",
      "Episodes finished: 327\n",
      "{'distance_to_goal': 0.06503599882125854, 'success': 1.0, 'spl': 0.965427134610526, 'reward': 5.495445978641511, 'stats_actions': {3: 9, 1: 15, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 328\n",
      "{'distance_to_goal': 0.10002240538597107, 'success': 1.0, 'spl': 0.36405262564224256, 'reward': 4.795068556070327, 'stats_actions': {3: 75, 1: 47, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 329\n",
      "{'distance_to_goal': 0.17561522126197815, 'success': 1.0, 'spl': 0.8425341841016105, 'reward': 7.407215970754628, 'stats_actions': {3: 29, 2: 11, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 330\n",
      "{'distance_to_goal': 5.541906356811523, 'success': 0.0, 'spl': 0.0, 'reward': -2.4627189636230167, 'stats_actions': {2: 66, 3: 229, 1: 205}}\n",
      "\n",
      "Episodes finished: 331\n",
      "{'distance_to_goal': 4.740743160247803, 'success': 0.0, 'spl': 0.0, 'reward': -4.129209041595403, 'stats_actions': {2: 47, 3: 246, 1: 207}}\n",
      "\n",
      "Episodes finished: 332\n",
      "{'distance_to_goal': 0.03687085956335068, 'success': 1.0, 'spl': 0.7511070249526409, 'reward': 4.943685037195683, 'stats_actions': {3: 10, 1: 19, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 333\n",
      "{'distance_to_goal': 4.933176040649414, 'success': 0.0, 'spl': 0.0, 'reward': -4.316113471984802, 'stats_actions': {3: 259, 1: 186, 2: 55}}\n",
      "\n",
      "Episodes finished: 334\n",
      "{'distance_to_goal': 0.11623935401439667, 'success': 1.0, 'spl': 0.3244764881807421, 'reward': 3.893866427540808, 'stats_actions': {2: 42, 3: 238, 1: 176, 0: 1}}\n",
      "\n",
      "Episodes finished: 335\n",
      "{'distance_to_goal': 0.15238326787948608, 'success': 1.0, 'spl': 0.9510562299156342, 'reward': 5.535456888675693, 'stats_actions': {3: 9, 1: 15, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 336\n",
      "{'distance_to_goal': 3.9074482917785645, 'success': 0.0, 'spl': 0.0, 'reward': -2.8633265495299955, 'stats_actions': {2: 62, 1: 192, 3: 246}}\n",
      "\n",
      "Episodes finished: 337\n",
      "{'distance_to_goal': 0.13224980235099792, 'success': 1.0, 'spl': 0.9748171111802822, 'reward': 6.587950164079669, 'stats_actions': {3: 8, 1: 19, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 338\n",
      "{'distance_to_goal': 0.03543345630168915, 'success': 1.0, 'spl': 0.9631053162892609, 'reward': 6.917135437130931, 'stats_actions': {3: 10, 1: 20, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 339\n",
      "{'distance_to_goal': 0.06990109384059906, 'success': 1.0, 'spl': 0.7129220132703384, 'reward': 6.9063465791940715, 'stats_actions': {3: 23, 2: 8, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 340\n",
      "{'distance_to_goal': 0.1398657113313675, 'success': 1.0, 'spl': 0.8385516003872164, 'reward': 6.43932772815228, 'stats_actions': {3: 34, 1: 23, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 341\n",
      "{'distance_to_goal': 5.000419616699219, 'success': 0.0, 'spl': 0.0, 'reward': -3.474555492401085, 'stats_actions': {2: 32, 3: 262, 1: 206}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:20:08.730756 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:20:08.730787 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:20:08.730792 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:20:08.730796 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:20:08.796030 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Greigsville.navmesh\n",
      "I1122 12:20:08.731001 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:20:08.732683 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:20:08.732692 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:20:08.734012 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Greigsville.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:20:08.771651 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Greigsville.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Greigsville.scene_instance.json\n",
      "I1122 12:20:08.771664 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Greigsville.glb so loading/creating a new StageAttributes with this namI1122 12:20:08.796853 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 342\n",
      "{'distance_to_goal': 0.036091431975364685, 'success': 1.0, 'spl': 0.3178085512815606, 'reward': 4.139911757111557, 'stats_actions': {3: 176, 1: 136, 2: 40, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:20:08.771670 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Greigsville.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Greigsville.stage_config.json\n",
      "I1122 12:20:08.771675 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Greigsville.stage_config.json from original name : data/scene_datasets/gibson/Greigsville.glb | This file  does not exist.\n",
      "I1122 12:20:08.771726 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Greigsville.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:20:08.771752 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Greigsville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:20:08.771755 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:20:08.771762 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Greigsville.navmesh\n",
      "I1122 12:20:08.771766 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Greigsville.navmesh\n",
      "I1122 12:20:08.771853 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:20:08.771859 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:20:08.771864 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Greigsville.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Greigsville.scn\n",
      "E1122 12:20:08.771870 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Greigsville.scn does not exist.  Aborting load.\n",
      "W1122 12:20:08.771878 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Greigsville.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:20:08.771922 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:20:08.771927 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Greigsville.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:20:08.771941 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Greigsville.glb with render asset : data/scene_datasets/gibson/Greigsville.glb and collision asset : data/scene_datasets/gibson/Greigsville.glb\n",
      "I1122 12:20:08.771951 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:20:08.771955 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Greigsville.glb.\n",
      "I1122 12:20:08.771957 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Greigsville.glb \n",
      "I1122 12:20:08.771966 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Greigsville.glb\n",
      "I1122 12:20:08.795279 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Greigsville.glb\n",
      "W1122 12:20:08.795296 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:20:08.795305 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Greigsville.glb yields 1 candidates.  Using data/scene_datasets/gibson/Greigsville.glb.\n",
      "I1122 12:20:08.795317 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Greigsville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:20:08.795321 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:20:08.795331 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Greigsville.glb yields 1 candidates.  Using data/scene_datasets/gibson/Greigsville.glb.\n",
      "I1122 12:20:08.795338 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Greigsville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:20:08.795341 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:20:08.795352 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Greigsville.glb with renderer.\n",
      "I1122 12:20:08.804536 316358080 PathFinder.cpp:382] Building navmesh with 156x139 cells\n",
      "I1122 12:20:08.854676 316358080 PathFinder.cpp:652] Created navmesh with 75 vertices 36 polygons\n",
      "I1122 12:20:08.854900 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 343\n",
      "{'distance_to_goal': 0.1560560166835785, 'success': 1.0, 'spl': 0.8843988323798593, 'reward': 8.57256435990334, 'stats_actions': {2: 3, 3: 7, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 344\n",
      "{'distance_to_goal': 0.1166025698184967, 'success': 1.0, 'spl': 0.9270095401267849, 'reward': 6.913772834539417, 'stats_actions': {3: 6, 1: 21, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 345\n",
      "{'distance_to_goal': 0.12726785242557526, 'success': 1.0, 'spl': 0.9327649758480505, 'reward': 6.606352924704554, 'stats_actions': {3: 9, 1: 20, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 346\n",
      "{'distance_to_goal': 0.038081347942352295, 'success': 1.0, 'spl': 0.9528920980495285, 'reward': 8.89674340486527, 'stats_actions': {3: 11, 1: 29, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 347\n",
      "{'distance_to_goal': 0.03929947316646576, 'success': 1.0, 'spl': 0.9381509750204758, 'reward': 7.388927341103558, 'stats_actions': {3: 11, 1: 23, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 348\n",
      "{'distance_to_goal': 0.09490908682346344, 'success': 1.0, 'spl': 0.9084845904967146, 'reward': 5.551908587813379, 'stats_actions': {2: 4, 1: 15, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 349\n",
      "{'distance_to_goal': 0.07165337353944778, 'success': 1.0, 'spl': 0.7398889394376538, 'reward': 4.6358548089861875, 'stats_actions': {3: 12, 1: 19, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 350\n",
      "{'distance_to_goal': 0.09783732146024704, 'success': 1.0, 'spl': 0.916323666661399, 'reward': 6.823888771831993, 'stats_actions': {2: 10, 1: 21, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 351\n",
      "{'distance_to_goal': 0.04640405252575874, 'success': 1.0, 'spl': 0.9362874737681515, 'reward': 7.19469585821033, 'stats_actions': {2: 12, 1: 22, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 352\n",
      "{'distance_to_goal': 0.15785573422908783, 'success': 1.0, 'spl': 0.929015485410885, 'reward': 8.340688901543626, 'stats_actions': {2: 16, 3: 10, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 353\n",
      "{'distance_to_goal': 0.10511831939220428, 'success': 1.0, 'spl': 0.3211012079925908, 'reward': 4.451463425755502, 'stats_actions': {3: 27, 1: 35, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 354\n",
      "{'distance_to_goal': 0.08117178082466125, 'success': 1.0, 'spl': 0.8631236489844423, 'reward': 6.42444673418999, 'stats_actions': {3: 7, 1: 20, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 355\n",
      "{'distance_to_goal': 0.12464532256126404, 'success': 1.0, 'spl': 0.9642432384252639, 'reward': 4.482985121011734, 'stats_actions': {2: 4, 3: 15, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 356\n",
      "{'distance_to_goal': 0.13652965426445007, 'success': 1.0, 'spl': 0.7448087209770384, 'reward': 6.952682992219936, 'stats_actions': {2: 18, 1: 29, 3: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 357\n",
      "{'distance_to_goal': 0.17259566485881805, 'success': 1.0, 'spl': 0.8414382904520383, 'reward': 6.011775577664378, 'stats_actions': {3: 15, 2: 13, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 358\n",
      "{'distance_to_goal': 0.1360546052455902, 'success': 1.0, 'spl': 0.9711960740126309, 'reward': 4.582421489953996, 'stats_actions': {2: 6, 1: 10, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 359\n",
      "{'distance_to_goal': 0.05211333930492401, 'success': 1.0, 'spl': 0.9443655800520201, 'reward': 5.881178000569345, 'stats_actions': {3: 10, 1: 16, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 360\n",
      "{'distance_to_goal': 0.1296994388103485, 'success': 1.0, 'spl': 0.9825640743332122, 'reward': 4.857170125246049, 'stats_actions': {3: 8, 1: 11, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 361\n",
      "{'distance_to_goal': 0.10791665315628052, 'success': 1.0, 'spl': 0.8362176463281975, 'reward': 8.104360625743873, 'stats_actions': {2: 11, 3: 21, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 362\n",
      "{'distance_to_goal': 0.07670947909355164, 'success': 1.0, 'spl': 0.974701926765087, 'reward': 8.146558915376666, 'stats_actions': {3: 6, 1: 25, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 363\n",
      "{'distance_to_goal': 0.08823917806148529, 'success': 1.0, 'spl': 1.0, 'reward': 3.681981483101845, 'stats_actions': {2: 4, 1: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 364\n",
      "{'distance_to_goal': 0.05678195878863335, 'success': 1.0, 'spl': 0.7715368421263972, 'reward': 5.7480186851322665, 'stats_actions': {2: 3, 3: 13, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 365\n",
      "{'distance_to_goal': 0.0884702205657959, 'success': 1.0, 'spl': 0.6087562170639008, 'reward': 4.67752200126648, 'stats_actions': {2: 11, 1: 22, 3: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 366\n",
      "{'distance_to_goal': 0.12867121398448944, 'success': 1.0, 'spl': 0.9857582554129938, 'reward': 5.136370671391488, 'stats_actions': {2: 3, 1: 12, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 367\n",
      "{'distance_to_goal': 0.07565316557884216, 'success': 1.0, 'spl': 0.8553078074996137, 'reward': 8.003235098123556, 'stats_actions': {3: 9, 1: 28, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 368\n",
      "{'distance_to_goal': 0.06882291287183762, 'success': 1.0, 'spl': 0.9146018632503276, 'reward': 7.807632890045649, 'stats_actions': {3: 11, 2: 10, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 369\n",
      "{'distance_to_goal': 0.03993615135550499, 'success': 1.0, 'spl': 1.0, 'reward': 3.6660468150675296, 'stats_actions': {1: 5, 3: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 370\n",
      "{'distance_to_goal': 0.030954839661717415, 'success': 1.0, 'spl': 0.605818964130105, 'reward': 5.839573057219388, 'stats_actions': {3: 25, 2: 27, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 371\n",
      "{'distance_to_goal': 0.0801624283194542, 'success': 1.0, 'spl': 0.9801558200346705, 'reward': 5.352619258463384, 'stats_actions': {2: 8, 3: 4, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 372\n",
      "{'distance_to_goal': 0.03691371530294418, 'success': 1.0, 'spl': 0.8236809491932824, 'reward': 6.678996738493446, 'stats_actions': {3: 14, 1: 23, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 373\n",
      "{'distance_to_goal': 0.05746270343661308, 'success': 1.0, 'spl': 0.9075890756891677, 'reward': 8.967363231927164, 'stats_actions': {3: 17, 1: 33, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 374\n",
      "{'distance_to_goal': 0.07711208611726761, 'success': 1.0, 'spl': 0.9045544372946112, 'reward': 5.664430119693281, 'stats_actions': {3: 15, 1: 17, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 375\n",
      "{'distance_to_goal': 0.11067725718021393, 'success': 1.0, 'spl': 0.9435413394154387, 'reward': 4.452398809790611, 'stats_actions': {2: 6, 3: 3, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 376\n",
      "{'distance_to_goal': 0.053124018013477325, 'success': 1.0, 'spl': 0.8466908559274162, 'reward': 6.086114473044875, 'stats_actions': {2: 3, 3: 13, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 377\n",
      "{'distance_to_goal': 0.09737877547740936, 'success': 1.0, 'spl': 0.8585677945446497, 'reward': 7.40406022369862, 'stats_actions': {2: 3, 1: 25, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 378\n",
      "{'distance_to_goal': 0.057755760848522186, 'success': 1.0, 'spl': 0.9380739935159896, 'reward': 9.223839011490352, 'stats_actions': {3: 11, 1: 31, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 379\n",
      "{'distance_to_goal': 0.028165683150291443, 'success': 1.0, 'spl': 0.7572477967514638, 'reward': 5.8180744177103065, 'stats_actions': {3: 21, 1: 20, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 380\n",
      "{'distance_to_goal': 0.042343445122241974, 'success': 1.0, 'spl': 0.9094942498108062, 'reward': 10.293824538886556, 'stats_actions': {3: 13, 1: 37, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 381\n",
      "{'distance_to_goal': 0.06251101195812225, 'success': 1.0, 'spl': 0.9600272188382628, 'reward': 8.20211032211781, 'stats_actions': {3: 6, 1: 26, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 382\n",
      "{'distance_to_goal': 0.12047655880451202, 'success': 1.0, 'spl': 0.7390928564217741, 'reward': 3.9333539789915086, 'stats_actions': {3: 20, 1: 21, 2: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 383\n",
      "{'distance_to_goal': 0.07934324443340302, 'success': 1.0, 'spl': 0.9141348320205781, 'reward': 8.002256467938428, 'stats_actions': {3: 14, 1: 27, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 384\n",
      "{'distance_to_goal': 0.008084828965365887, 'success': 1.0, 'spl': 0.8748056450397081, 'reward': 5.859409134276213, 'stats_actions': {3: 9, 1: 20, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 385\n",
      "{'distance_to_goal': 0.03458702564239502, 'success': 1.0, 'spl': 0.837758684550056, 'reward': 7.892583651542671, 'stats_actions': {3: 16, 2: 11, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 386\n",
      "{'distance_to_goal': 0.06707800924777985, 'success': 1.0, 'spl': 0.7605930098612527, 'reward': 6.806683282256129, 'stats_actions': {2: 3, 1: 25, 3: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 387\n",
      "{'distance_to_goal': 0.11358434706926346, 'success': 1.0, 'spl': 0.9119430564233274, 'reward': 4.912244767844677, 'stats_actions': {3: 6, 2: 2, 1: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 388\n",
      "{'distance_to_goal': 0.12213993072509766, 'success': 1.0, 'spl': 0.5666019274506369, 'reward': 4.5639737033843994, 'stats_actions': {3: 15, 1: 20, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 389\n",
      "{'distance_to_goal': 0.14289438724517822, 'success': 1.0, 'spl': 0.9867853071973802, 'reward': 5.560355057716371, 'stats_actions': {3: 8, 1: 14, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 390\n",
      "{'distance_to_goal': 0.07506006956100464, 'success': 1.0, 'spl': 0.9715724789798131, 'reward': 4.62604487657547, 'stats_actions': {3: 4, 1: 10, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 391\n",
      "{'distance_to_goal': 0.0879698321223259, 'success': 1.0, 'spl': 0.6925870499152817, 'reward': 6.913892197906974, 'stats_actions': {3: 22, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 392\n",
      "{'distance_to_goal': 0.10949470102787018, 'success': 1.0, 'spl': 0.6107902693783239, 'reward': 6.444830269217495, 'stats_actions': {2: 7, 3: 25, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 393\n",
      "{'distance_to_goal': 0.1660032421350479, 'success': 1.0, 'spl': 1.0, 'reward': 6.5089459079504035, 'stats_actions': {3: 3, 1: 18, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 394\n",
      "{'distance_to_goal': 0.08357204496860504, 'success': 1.0, 'spl': 0.8924447987712427, 'reward': 9.0673809427023, 'stats_actions': {3: 11, 1: 40, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 395\n",
      "{'distance_to_goal': 0.05644945800304413, 'success': 1.0, 'spl': 0.9449676921954487, 'reward': 5.703464406132699, 'stats_actions': {2: 4, 3: 11, 1: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 396\n",
      "{'distance_to_goal': 0.12781265377998352, 'success': 1.0, 'spl': 0.618025760490141, 'reward': 6.060023649930956, 'stats_actions': {3: 18, 1: 29, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 397\n",
      "{'distance_to_goal': 0.05807594582438469, 'success': 1.0, 'spl': 0.8377910565181877, 'reward': 6.717349411994221, 'stats_actions': {3: 9, 1: 22, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 398\n",
      "{'distance_to_goal': 0.03396892920136452, 'success': 1.0, 'spl': 0.9635703066597415, 'reward': 4.022278777211905, 'stats_actions': {3: 3, 1: 7, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 399\n",
      "{'distance_to_goal': 0.025485510006546974, 'success': 1.0, 'spl': 0.9840122969594355, 'reward': 9.316458459720021, 'stats_actions': {3: 14, 1: 30, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 400\n",
      "{'distance_to_goal': 0.012424152344465256, 'success': 1.0, 'spl': 0.9607703021248607, 'reward': 4.471864387542009, 'stats_actions': {2: 5, 1: 9, 3: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 401\n",
      "{'distance_to_goal': 0.10995038598775864, 'success': 1.0, 'spl': 0.8921540591751783, 'reward': 8.373190406858926, 'stats_actions': {3: 8, 2: 3, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 402\n",
      "{'distance_to_goal': 0.13825450837612152, 'success': 1.0, 'spl': 0.9960155880342483, 'reward': 5.109459572434427, 'stats_actions': {3: 6, 1: 12, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 403\n",
      "{'distance_to_goal': 0.12272869050502777, 'success': 1.0, 'spl': 0.8830375114094678, 'reward': 5.84018096983433, 'stats_actions': {3: 9, 1: 17, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 404\n",
      "{'distance_to_goal': 0.021103523671627045, 'success': 1.0, 'spl': 0.9774661128739017, 'reward': 6.814410735666755, 'stats_actions': {3: 7, 1: 19, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 405\n",
      "{'distance_to_goal': 0.09648022055625916, 'success': 1.0, 'spl': 0.9408957313044187, 'reward': 5.701878715753557, 'stats_actions': {2: 4, 1: 15, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 406\n",
      "{'distance_to_goal': 0.09020118415355682, 'success': 1.0, 'spl': 0.8569531306807354, 'reward': 5.079134581685069, 'stats_actions': {2: 3, 3: 15, 1: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 407\n",
      "{'distance_to_goal': 0.05319807678461075, 'success': 1.0, 'spl': 0.8149221055479547, 'reward': 7.383713868558411, 'stats_actions': {3: 8, 2: 2, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 408\n",
      "{'distance_to_goal': 0.15082107484340668, 'success': 1.0, 'spl': 0.9601311408712134, 'reward': 7.4655744940042545, 'stats_actions': {2: 11, 1: 23, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 409\n",
      "{'distance_to_goal': 0.07412644475698471, 'success': 1.0, 'spl': 0.9947084757959738, 'reward': 4.972037428915501, 'stats_actions': {3: 5, 1: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 410\n",
      "{'distance_to_goal': 0.009423240087926388, 'success': 1.0, 'spl': 0.938039233645117, 'reward': 6.911995712853972, 'stats_actions': {2: 15, 1: 21, 3: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 411\n",
      "{'distance_to_goal': 0.1254192441701889, 'success': 1.0, 'spl': 0.5499098888708875, 'reward': 7.98906580984593, 'stats_actions': {3: 53, 1: 54, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 412\n",
      "{'distance_to_goal': 0.0734812393784523, 'success': 1.0, 'spl': 0.7935384939908545, 'reward': 6.656848674714569, 'stats_actions': {2: 2, 1: 23, 3: 7, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:21:27.735723 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:21:27.735750 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:21:27.735755 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:21:27.735759 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:21:27.823706 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Mosquito.navmesh\n",
      "I1122 12:21:27.735894 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:21:27.737561 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:21:27.737568 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:21:27.738374 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Mosquito.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:21:27.774752 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Mosquito.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Mosquito.scene_instance.json\n",
      "I1122 12:21:27.774766 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Mosquito.glb so loading/creating a new StageAttributes with this name, and then I1122 12:21:27.824439 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 413\n",
      "{'distance_to_goal': 0.04055021330714226, 'success': 1.0, 'spl': 0.570918142224332, 'reward': 8.101135959178215, 'stats_actions': {2: 10, 1: 45, 3: 22, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:21:27.774772 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Mosquito.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Mosquito.stage_config.json\n",
      "I1122 12:21:27.774777 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Mosquito.stage_config.json from original name : data/scene_datasets/gibson/Mosquito.glb | This file  does not exist.\n",
      "I1122 12:21:27.776595 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Mosquito.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:21:27.776650 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Mosquito.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:21:27.776655 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:21:27.776662 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Mosquito.navmesh\n",
      "I1122 12:21:27.776667 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Mosquito.navmesh\n",
      "I1122 12:21:27.776933 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:21:27.776942 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:21:27.776947 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Mosquito.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Mosquito.scn\n",
      "E1122 12:21:27.776953 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Mosquito.scn does not exist.  Aborting load.\n",
      "W1122 12:21:27.776962 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Mosquito.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:21:27.777024 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:21:27.777030 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Mosquito.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:21:27.777045 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Mosquito.glb with render asset : data/scene_datasets/gibson/Mosquito.glb and collision asset : data/scene_datasets/gibson/Mosquito.glb\n",
      "I1122 12:21:27.777056 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:21:27.777060 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:21:27.777062 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Mosquito.glb \n",
      "I1122 12:21:27.777073 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Mosquito.glb\n",
      "I1122 12:21:27.822609 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Mosquito.glb\n",
      "W1122 12:21:27.822628 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:21:27.822638 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Mosquito.glb yields 1 candidates.  Using data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:21:27.822650 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Mosquito.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:21:27.822654 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:21:27.822665 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Mosquito.glb yields 1 candidates.  Using data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:21:27.822672 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Mosquito.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:21:27.822675 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:21:27.822687 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Mosquito.glb with renderer.\n",
      "I1122 12:21:27.827917 316358080 PathFinder.cpp:382] Building navmesh with 224x469 cells\n",
      "I1122 12:21:27.927521 316358080 PathFinder.cpp:652] Created navmesh with 588 vertices 287 polygons\n",
      "I1122 12:21:27.927553 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 414\n",
      "{'distance_to_goal': 0.11033136397600174, 'success': 1.0, 'spl': 0.898899795076079, 'reward': 9.84019140213729, 'stats_actions': {3: 15, 1: 36, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 415\n",
      "{'distance_to_goal': 0.07302741706371307, 'success': 1.0, 'spl': 0.9227160277351885, 'reward': 4.742298339009285, 'stats_actions': {3: 6, 1: 11, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 416\n",
      "{'distance_to_goal': 8.989777565002441, 'success': 0.0, 'spl': 0.0, 'reward': -5.066333770751889, 'stats_actions': {3: 154, 1: 257, 2: 89}}\n",
      "\n",
      "Episodes finished: 417\n",
      "{'distance_to_goal': 0.11206920444965363, 'success': 1.0, 'spl': 0.8361530862283713, 'reward': 8.338040716052062, 'stats_actions': {3: 19, 2: 3, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 418\n",
      "{'distance_to_goal': 0.07502364367246628, 'success': 1.0, 'spl': 0.635514037432492, 'reward': 14.036835792362718, 'stats_actions': {3: 55, 1: 84, 2: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 419\n",
      "{'distance_to_goal': 0.09122693538665771, 'success': 1.0, 'spl': 0.3357714379259162, 'reward': 11.576428666114866, 'stats_actions': {3: 146, 1: 163, 2: 51, 0: 1}}\n",
      "\n",
      "Episodes finished: 420\n",
      "{'distance_to_goal': 0.1101924479007721, 'success': 1.0, 'spl': 0.8967747748941428, 'reward': 13.49654781699182, 'stats_actions': {3: 22, 1: 58, 2: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 421\n",
      "{'distance_to_goal': 0.20582634210586548, 'success': 0.0, 'spl': 0.0, 'reward': 7.6495027899742185, 'stats_actions': {3: 78, 2: 27, 1: 84, 0: 1}}\n",
      "\n",
      "Episodes finished: 422\n",
      "{'distance_to_goal': 17.593463897705078, 'success': 0.0, 'spl': 0.0, 'reward': -3.8682479858398064, 'stats_actions': {3: 187, 1: 187, 2: 126}}\n",
      "\n",
      "Episodes finished: 423\n",
      "{'distance_to_goal': 0.12506206333637238, 'success': 1.0, 'spl': 0.6396039195120429, 'reward': 7.455459672808652, 'stats_actions': {2: 27, 1: 92, 3: 64, 0: 1}}\n",
      "\n",
      "Episodes finished: 424\n",
      "{'distance_to_goal': 19.611146926879883, 'success': 0.0, 'spl': 0.0, 'reward': -5.098651885986265, 'stats_actions': {3: 293, 2: 109, 1: 98}}\n",
      "\n",
      "Episodes finished: 425\n",
      "{'distance_to_goal': 0.09848290681838989, 'success': 1.0, 'spl': 0.678110019321114, 'reward': 8.37764010190965, 'stats_actions': {2: 11, 3: 22, 1: 50, 0: 1}}\n",
      "\n",
      "Episodes finished: 426\n",
      "{'distance_to_goal': 0.08045250922441483, 'success': 1.0, 'spl': 0.9007338349600772, 'reward': 8.741540403068072, 'stats_actions': {2: 2, 3: 13, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 427\n",
      "{'distance_to_goal': 7.305103778839111, 'success': 0.0, 'spl': 0.0, 'reward': 2.2167859077453906, 'stats_actions': {3: 232, 1: 195, 2: 73}}\n",
      "\n",
      "Episodes finished: 428\n",
      "{'distance_to_goal': 0.15443134307861328, 'success': 1.0, 'spl': 0.9128527284678685, 'reward': 10.310098457336437, 'stats_actions': {3: 15, 1: 38, 2: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 429\n",
      "{'distance_to_goal': 14.575469970703125, 'success': 0.0, 'spl': 0.0, 'reward': -5.598794937133713, 'stats_actions': {3: 154, 1: 246, 2: 100}}\n",
      "\n",
      "Episodes finished: 430\n",
      "{'distance_to_goal': 16.803672790527344, 'success': 0.0, 'spl': 0.0, 'reward': 1.8457603454590832, 'stats_actions': {3: 252, 1: 188, 2: 60}}\n",
      "\n",
      "Episodes finished: 431\n",
      "{'distance_to_goal': 25.705305099487305, 'success': 0.0, 'spl': 0.0, 'reward': -8.687171936035059, 'stats_actions': {3: 280, 1: 116, 2: 104}}\n",
      "\n",
      "Episodes finished: 432\n",
      "{'distance_to_goal': 0.030275965109467506, 'success': 1.0, 'spl': 0.9729945870742116, 'reward': 6.305801400765779, 'stats_actions': {1: 19, 3: 4, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 433\n",
      "{'distance_to_goal': 5.931253433227539, 'success': 0.0, 'spl': 0.0, 'reward': 8.64189147949228, 'stats_actions': {2: 86, 3: 214, 1: 200}}\n",
      "\n",
      "Episodes finished: 434\n",
      "{'distance_to_goal': 12.129467010498047, 'success': 0.0, 'spl': 0.0, 'reward': 2.2792606353760663, 'stats_actions': {3: 218, 1: 205, 2: 77}}\n",
      "\n",
      "Episodes finished: 435\n",
      "{'distance_to_goal': 0.06592479348182678, 'success': 1.0, 'spl': 0.9394796790398737, 'reward': 8.43531381964684, 'stats_actions': {3: 11, 1: 28, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 436\n",
      "{'distance_to_goal': 0.16421248018741608, 'success': 1.0, 'spl': 0.9659409215495423, 'reward': 5.478089699149135, 'stats_actions': {3: 8, 2: 10, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 437\n",
      "{'distance_to_goal': 0.019552601501345634, 'success': 1.0, 'spl': 0.7792427969401376, 'reward': 13.957662822082657, 'stats_actions': {2: 18, 1: 67, 3: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 438\n",
      "{'distance_to_goal': 14.339542388916016, 'success': 0.0, 'spl': 0.0, 'reward': -6.990985870361243, 'stats_actions': {3: 230, 1: 185, 2: 85}}\n",
      "\n",
      "Episodes finished: 439\n",
      "{'distance_to_goal': 0.029577136039733887, 'success': 1.0, 'spl': 0.7091429791059161, 'reward': 7.540670533180242, 'stats_actions': {3: 27, 2: 10, 1: 35, 0: 1}}\n",
      "\n",
      "Episodes finished: 440\n",
      "{'distance_to_goal': 15.215983390808105, 'success': 0.0, 'spl': 0.0, 'reward': -3.3313512802123837, 'stats_actions': {2: 77, 3: 243, 1: 180}}\n",
      "\n",
      "Episodes finished: 441\n",
      "{'distance_to_goal': 5.197968006134033, 'success': 0.0, 'spl': 0.0, 'reward': -3.7897257804869975, 'stats_actions': {3: 251, 1: 145, 2: 104}}\n",
      "\n",
      "Episodes finished: 442\n",
      "{'distance_to_goal': 0.11175583302974701, 'success': 1.0, 'spl': 0.9122603051788626, 'reward': 6.7012095981836355, 'stats_actions': {3: 19, 1: 21, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 443\n",
      "{'distance_to_goal': 0.09930409491062164, 'success': 1.0, 'spl': 0.7445227015972388, 'reward': 17.131966504454645, 'stats_actions': {3: 55, 1: 90, 2: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 444\n",
      "{'distance_to_goal': 15.581215858459473, 'success': 0.0, 'spl': 0.0, 'reward': 0.8385152816773227, 'stats_actions': {2: 134, 1: 221, 3: 145}}\n",
      "\n",
      "Episodes finished: 445\n",
      "{'distance_to_goal': 7.695119857788086, 'success': 0.0, 'spl': 0.0, 'reward': -5.5680370330809925, 'stats_actions': {2: 90, 1: 232, 3: 178}}\n",
      "\n",
      "Episodes finished: 446\n",
      "{'distance_to_goal': 15.450406074523926, 'success': 0.0, 'spl': 0.0, 'reward': -4.12358188629144, 'stats_actions': {3: 265, 1: 169, 2: 66}}\n",
      "\n",
      "Episodes finished: 447\n",
      "{'distance_to_goal': 0.09094496071338654, 'success': 1.0, 'spl': 0.47955775735162914, 'reward': 3.534248444438001, 'stats_actions': {2: 109, 3: 146, 1: 189, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:26:06.123317 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Pablo.navmesh\n",
      "I1122 12:26:06.066715 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:26:06.066740 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:26:06.066745 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:26:06.066747 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:26:06.066890 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:26:06.068222 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:26:06.068230 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:26:06.068753 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Pablo.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:26:06.104735 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Pablo.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Pablo.scene_instance.json\n",
      "I1122 12:26:06.104751 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Pablo.glb so loading/creating a new StageAttributes with this name, and then creating a SI1122 12:26:06.124180 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 448\n",
      "{'distance_to_goal': 7.702499866485596, 'success': 0.0, 'spl': 0.0, 'reward': -1.2624077796935727, 'stats_actions': {2: 39, 3: 262, 1: 199}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ceneAttributes with the same name that references this stage.\n",
      "I1122 12:26:06.104756 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Pablo.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Pablo.stage_config.json\n",
      "I1122 12:26:06.104761 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Pablo.stage_config.json from original name : data/scene_datasets/gibson/Pablo.glb | This file  does not exist.\n",
      "I1122 12:26:06.104811 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Pablo.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:26:06.104837 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Pablo.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:26:06.104841 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:26:06.104847 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Pablo.navmesh\n",
      "I1122 12:26:06.104852 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Pablo.navmesh\n",
      "I1122 12:26:06.104933 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:26:06.104939 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:26:06.104944 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Pablo.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Pablo.scn\n",
      "E1122 12:26:06.104950 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Pablo.scn does not exist.  Aborting load.\n",
      "W1122 12:26:06.104957 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Pablo.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:26:06.105005 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:26:06.105010 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Pablo.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:26:06.105024 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Pablo.glb with render asset : data/scene_datasets/gibson/Pablo.glb and collision asset : data/scene_datasets/gibson/Pablo.glb\n",
      "I1122 12:26:06.105034 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:26:06.105037 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Pablo.glb.\n",
      "I1122 12:26:06.105041 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Pablo.glb \n",
      "I1122 12:26:06.105049 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Pablo.glb\n",
      "I1122 12:26:06.122648 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Pablo.glb\n",
      "W1122 12:26:06.122666 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:26:06.122675 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Pablo.glb yields 1 candidates.  Using data/scene_datasets/gibson/Pablo.glb.\n",
      "I1122 12:26:06.122687 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Pablo.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:26:06.122691 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:26:06.122702 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Pablo.glb yields 1 candidates.  Using data/scene_datasets/gibson/Pablo.glb.\n",
      "I1122 12:26:06.122710 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Pablo.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:26:06.122714 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:26:06.122725 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Pablo.glb with renderer.\n",
      "I1122 12:26:06.128487 316358080 PathFinder.cpp:382] Building navmesh with 200x88 cells\n",
      "I1122 12:26:06.181073 316358080 PathFinder.cpp:652] Created navmesh with 63 vertices 31 polygons\n",
      "I1122 12:26:06.181092 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 449\n",
      "{'distance_to_goal': 0.12297816574573517, 'success': 1.0, 'spl': 0.9269464009727775, 'reward': 7.647068049311643, 'stats_actions': {3: 19, 1: 27, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 450\n",
      "{'distance_to_goal': 0.09458788484334946, 'success': 1.0, 'spl': 0.9159798835033426, 'reward': 6.6036217442154905, 'stats_actions': {3: 18, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 451\n",
      "{'distance_to_goal': 0.05101783946156502, 'success': 1.0, 'spl': 0.7321463736402194, 'reward': 6.954596822708849, 'stats_actions': {3: 22, 1: 28, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 452\n",
      "{'distance_to_goal': 0.11763332039117813, 'success': 1.0, 'spl': 0.959405039077982, 'reward': 5.687326911389829, 'stats_actions': {3: 6, 1: 15, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 453\n",
      "{'distance_to_goal': 0.058994196355342865, 'success': 1.0, 'spl': 0.8638412607147811, 'reward': 6.466325704157355, 'stats_actions': {3: 17, 1: 21, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 454\n",
      "{'distance_to_goal': 0.01777573488652706, 'success': 1.0, 'spl': 0.9775134073445586, 'reward': 3.942016173377633, 'stats_actions': {3: 11, 1: 7, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 455\n",
      "{'distance_to_goal': 0.10456238687038422, 'success': 1.0, 'spl': 0.728863070284569, 'reward': 6.466374884247782, 'stats_actions': {3: 30, 1: 28, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 456\n",
      "{'distance_to_goal': 0.07451251149177551, 'success': 1.0, 'spl': 0.9940748396536833, 'reward': 7.015386875867848, 'stats_actions': {2: 12, 3: 7, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 457\n",
      "{'distance_to_goal': 0.07419552654027939, 'success': 1.0, 'spl': 0.978414473034252, 'reward': 6.817012931406503, 'stats_actions': {3: 11, 1: 22, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 458\n",
      "{'distance_to_goal': 0.05245007574558258, 'success': 1.0, 'spl': 0.978264348097659, 'reward': 4.913333033919335, 'stats_actions': {2: 9, 1: 12, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 459\n",
      "{'distance_to_goal': 0.05957593396306038, 'success': 1.0, 'spl': 0.845185909690935, 'reward': 4.767496133297683, 'stats_actions': {2: 2, 3: 17, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 460\n",
      "{'distance_to_goal': 0.11965273320674896, 'success': 1.0, 'spl': 0.8406926410529724, 'reward': 5.91360671579838, 'stats_actions': {3: 22, 1: 20, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 461\n",
      "{'distance_to_goal': 0.10362192243337631, 'success': 1.0, 'spl': 1.0, 'reward': 5.007198561728001, 'stats_actions': {2: 5, 3: 12, 1: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 462\n",
      "{'distance_to_goal': 0.1339809000492096, 'success': 1.0, 'spl': 1.0, 'reward': 3.2865702664852146, 'stats_actions': {3: 8, 1: 4, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 463\n",
      "{'distance_to_goal': 0.07203458249568939, 'success': 1.0, 'spl': 0.806010751889563, 'reward': 6.951039186120036, 'stats_actions': {3: 32, 1: 30, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 464\n",
      "{'distance_to_goal': 0.06471728533506393, 'success': 1.0, 'spl': 0.9562825592724338, 'reward': 4.556845500767231, 'stats_actions': {3: 3, 1: 10, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 465\n",
      "{'distance_to_goal': 0.051509108394384384, 'success': 1.0, 'spl': 0.9559982761080954, 'reward': 8.147161355167633, 'stats_actions': {2: 9, 1: 26, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 466\n",
      "{'distance_to_goal': 0.09320592135190964, 'success': 1.0, 'spl': 0.8162737493961899, 'reward': 6.352090862095358, 'stats_actions': {2: 9, 1: 22, 3: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 467\n",
      "{'distance_to_goal': 0.11590267717838287, 'success': 1.0, 'spl': 0.9660249975938436, 'reward': 5.128687996268274, 'stats_actions': {3: 17, 1: 13, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 468\n",
      "{'distance_to_goal': 0.032768044620752335, 'success': 1.0, 'spl': 0.7981129461127994, 'reward': 7.42201810345054, 'stats_actions': {3: 30, 1: 33, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 469\n",
      "{'distance_to_goal': 0.09132428467273712, 'success': 1.0, 'spl': 0.8966192315358, 'reward': 3.613604575991631, 'stats_actions': {2: 6, 1: 6, 3: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 470\n",
      "{'distance_to_goal': 0.13167952001094818, 'success': 1.0, 'spl': 0.9246130430173709, 'reward': 7.304025092720989, 'stats_actions': {3: 28, 1: 27, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 471\n",
      "{'distance_to_goal': 0.07240496575832367, 'success': 1.0, 'spl': 0.9568626377260593, 'reward': 7.299154501557353, 'stats_actions': {3: 15, 1: 24, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 472\n",
      "{'distance_to_goal': 0.15917488932609558, 'success': 1.0, 'spl': 1.0, 'reward': 4.636988173723221, 'stats_actions': {3: 12, 2: 4, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 473\n",
      "{'distance_to_goal': 0.06714142858982086, 'success': 1.0, 'spl': 0.9513338810836761, 'reward': 8.068040952086454, 'stats_actions': {3: 12, 1: 26, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 474\n",
      "{'distance_to_goal': 0.1272786259651184, 'success': 1.0, 'spl': 0.6131750410722789, 'reward': 5.857939040660861, 'stats_actions': {3: 27, 1: 27, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 475\n",
      "{'distance_to_goal': 0.04171527549624443, 'success': 1.0, 'spl': 0.9392803812919447, 'reward': 5.686796229630709, 'stats_actions': {3: 14, 1: 15, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 476\n",
      "{'distance_to_goal': 0.01118185929954052, 'success': 1.0, 'spl': 0.9014248193941535, 'reward': 6.3331353671103745, 'stats_actions': {3: 24, 1: 20, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 477\n",
      "{'distance_to_goal': 0.07769401371479034, 'success': 1.0, 'spl': 0.9398412802238545, 'reward': 6.596660863757136, 'stats_actions': {3: 18, 1: 21, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 478\n",
      "{'distance_to_goal': 0.0654078796505928, 'success': 1.0, 'spl': 0.9385917069636369, 'reward': 5.638259474933149, 'stats_actions': {3: 8, 1: 15, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 479\n",
      "{'distance_to_goal': 0.11816690862178802, 'success': 1.0, 'spl': 0.9748626765913809, 'reward': 9.15910375177861, 'stats_actions': {3: 26, 1: 32, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 480\n",
      "{'distance_to_goal': 0.04613681882619858, 'success': 1.0, 'spl': 0.9699429765166795, 'reward': 8.25174528032542, 'stats_actions': {3: 11, 1: 26, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 481\n",
      "{'distance_to_goal': 0.09181185066699982, 'success': 1.0, 'spl': 0.9281690019411079, 'reward': 7.793164975047115, 'stats_actions': {2: 4, 3: 22, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 482\n",
      "{'distance_to_goal': 0.06703998148441315, 'success': 1.0, 'spl': 0.8659865715541962, 'reward': 5.8577046817541145, 'stats_actions': {3: 19, 1: 18, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 483\n",
      "{'distance_to_goal': 0.029796959832310677, 'success': 1.0, 'spl': 0.964368683660768, 'reward': 6.291712363287809, 'stats_actions': {3: 7, 1: 17, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 484\n",
      "{'distance_to_goal': 0.07146700471639633, 'success': 1.0, 'spl': 0.948152807581319, 'reward': 6.5922590008378075, 'stats_actions': {1: 19, 3: 6, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 485\n",
      "{'distance_to_goal': 0.09113291651010513, 'success': 1.0, 'spl': 0.7515171707461438, 'reward': 8.86201951116324, 'stats_actions': {2: 7, 3: 49, 1: 42, 0: 1}}\n",
      "\n",
      "Episodes finished: 486\n",
      "{'distance_to_goal': 0.06533902883529663, 'success': 1.0, 'spl': 0.8675771972713944, 'reward': 5.648755962848664, 'stats_actions': {3: 16, 1: 17, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 487\n",
      "{'distance_to_goal': 0.10304494202136993, 'success': 1.0, 'spl': 0.8224464854347538, 'reward': 3.6931444519758223, 'stats_actions': {3: 6, 1: 8, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 488\n",
      "{'distance_to_goal': 0.008720197714865208, 'success': 1.0, 'spl': 0.9436894053446956, 'reward': 6.106357431374492, 'stats_actions': {3: 16, 1: 17, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 489\n",
      "{'distance_to_goal': 0.06184667721390724, 'success': 1.0, 'spl': 0.8600137711961198, 'reward': 5.723212183564903, 'stats_actions': {2: 4, 3: 15, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 490\n",
      "{'distance_to_goal': 0.053901053965091705, 'success': 1.0, 'spl': 0.8635675012314307, 'reward': 10.67866711467506, 'stats_actions': {3: 27, 1: 43, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 491\n",
      "{'distance_to_goal': 0.06798689067363739, 'success': 1.0, 'spl': 0.8959912427362026, 'reward': 7.106815660595897, 'stats_actions': {2: 3, 3: 22, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 492\n",
      "{'distance_to_goal': 0.031631819903850555, 'success': 1.0, 'spl': 0.8678961463775833, 'reward': 7.429068291485312, 'stats_actions': {2: 2, 3: 36, 1: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 493\n",
      "{'distance_to_goal': 0.0652380958199501, 'success': 1.0, 'spl': 0.7373659263145921, 'reward': 9.238477114140991, 'stats_actions': {3: 70, 1: 47, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 494\n",
      "{'distance_to_goal': 0.09571029245853424, 'success': 1.0, 'spl': 0.9385522949089641, 'reward': 9.508580974936496, 'stats_actions': {3: 18, 1: 34, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 495\n",
      "{'distance_to_goal': 0.030891884118318558, 'success': 1.0, 'spl': 0.9350145180914621, 'reward': 6.580427104681734, 'stats_actions': {3: 9, 1: 19, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 496\n",
      "{'distance_to_goal': 0.10587483644485474, 'success': 1.0, 'spl': 1.0, 'reward': 4.068626954555512, 'stats_actions': {3: 2, 1: 7, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 497\n",
      "{'distance_to_goal': 0.1434253752231598, 'success': 1.0, 'spl': 0.8380412668085614, 'reward': 10.473049157857902, 'stats_actions': {3: 58, 1: 45, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 498\n",
      "{'distance_to_goal': 0.07381118834018707, 'success': 1.0, 'spl': 0.9511985176184661, 'reward': 7.030650863051419, 'stats_actions': {3: 8, 1: 21, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 499\n",
      "{'distance_to_goal': 0.009963161312043667, 'success': 1.0, 'spl': 0.8580721869060375, 'reward': 9.977446125186985, 'stats_actions': {3: 36, 1: 43, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 500\n",
      "{'distance_to_goal': 0.13668161630630493, 'success': 1.0, 'spl': 1.0, 'reward': 4.042872087955475, 'stats_actions': {3: 8, 1: 7, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 501\n",
      "{'distance_to_goal': 0.0971650704741478, 'success': 1.0, 'spl': 1.0, 'reward': 4.544863013327122, 'stats_actions': {2: 11, 3: 4, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 502\n",
      "{'distance_to_goal': 0.12534087896347046, 'success': 1.0, 'spl': 1.0, 'reward': 4.0193712162971496, 'stats_actions': {2: 4, 1: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 503\n",
      "{'distance_to_goal': 0.08092193305492401, 'success': 1.0, 'spl': 0.8700260236765632, 'reward': 10.306858485341078, 'stats_actions': {3: 31, 1: 40, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 504\n",
      "{'distance_to_goal': 0.12295787036418915, 'success': 1.0, 'spl': 0.8185853339303887, 'reward': 5.443888843655588, 'stats_actions': {2: 4, 3: 17, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 505\n",
      "{'distance_to_goal': 0.019308077171444893, 'success': 1.0, 'spl': 0.9219624030568094, 'reward': 9.327721379920845, 'stats_actions': {2: 3, 3: 37, 1: 33, 0: 1}}\n",
      "\n",
      "Episodes finished: 506\n",
      "{'distance_to_goal': 0.04186662286520004, 'success': 1.0, 'spl': 0.7558833148659612, 'reward': 7.194333824217322, 'stats_actions': {3: 24, 1: 29, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 507\n",
      "{'distance_to_goal': 0.0858980119228363, 'success': 1.0, 'spl': 0.8084358044076322, 'reward': 6.288027006387713, 'stats_actions': {3: 21, 1: 22, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 508\n",
      "{'distance_to_goal': 0.022055702283978462, 'success': 1.0, 'spl': 0.9875969125879377, 'reward': 4.286316771432757, 'stats_actions': {3: 3, 1: 8, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 509\n",
      "{'distance_to_goal': 0.013581761159002781, 'success': 1.0, 'spl': 0.5968823907492736, 'reward': 5.873639517985286, 'stats_actions': {2: 7, 3: 42, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 510\n",
      "{'distance_to_goal': 0.09176245331764221, 'success': 1.0, 'spl': 0.7916957213928636, 'reward': 6.278933385610583, 'stats_actions': {3: 23, 1: 23, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 511\n",
      "{'distance_to_goal': 0.02904696576297283, 'success': 1.0, 'spl': 0.9684378626214227, 'reward': 5.603835438564421, 'stats_actions': {3: 5, 1: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 512\n",
      "{'distance_to_goal': 0.12648171186447144, 'success': 1.0, 'spl': 0.879798384320779, 'reward': 5.986338798999791, 'stats_actions': {2: 5, 1: 18, 3: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 513\n",
      "{'distance_to_goal': 0.13266877830028534, 'success': 1.0, 'spl': 0.9592419685535913, 'reward': 7.278734667897228, 'stats_actions': {3: 19, 1: 23, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 514\n",
      "{'distance_to_goal': 0.133662149310112, 'success': 1.0, 'spl': 0.8327511133137816, 'reward': 3.5936618787050247, 'stats_actions': {2: 2, 3: 13, 1: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 515\n",
      "{'distance_to_goal': 0.022802259773015976, 'success': 1.0, 'spl': 0.9576931571520962, 'reward': 7.151249120384458, 'stats_actions': {3: 15, 1: 22, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 516\n",
      "{'distance_to_goal': 0.059365734457969666, 'success': 1.0, 'spl': 0.9071990644141461, 'reward': 9.73951854288579, 'stats_actions': {3: 13, 1: 35, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 517\n",
      "{'distance_to_goal': 5.266281604766846, 'success': 0.0, 'spl': 0.0, 'reward': -4.975374698638856, 'stats_actions': {3: 264, 1: 204, 2: 32}}\n",
      "\n",
      "Episodes finished: 518\n",
      "{'distance_to_goal': 0.09932215511798859, 'success': 1.0, 'spl': 0.8226736113850242, 'reward': 6.9664165419340165, 'stats_actions': {2: 7, 3: 15, 1: 25, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:27:46.555090 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Ribera.navmesh\n",
      "I1122 12:27:46.487649 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:27:46.487677 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:27:46.487682 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:27:46.487685 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:27:46.487839 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:27:46.489284 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:27:46.489292 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:27:46.490177 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Ribera.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:27:46.530046 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Ribera.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Ribera.scene_instance.json\n",
      "I1122 12:27:46.530071 316358080 MetadataMedI1122 12:27:46.556108 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 519\n",
      "{'distance_to_goal': 0.0553528293967247, 'success': 1.0, 'spl': 0.9769232408922592, 'reward': 6.440118552744391, 'stats_actions': {3: 8, 1: 18, 2: 8, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Ribera.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:27:46.530077 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Ribera.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Ribera.stage_config.json\n",
      "I1122 12:27:46.530082 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Ribera.stage_config.json from original name : data/scene_datasets/gibson/Ribera.glb | This file  does not exist.\n",
      "I1122 12:27:46.530143 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Ribera.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:27:46.530174 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Ribera.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:27:46.530179 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:27:46.530185 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Ribera.navmesh\n",
      "I1122 12:27:46.530191 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Ribera.navmesh\n",
      "I1122 12:27:46.530324 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:27:46.530336 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:27:46.530344 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Ribera.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Ribera.scn\n",
      "E1122 12:27:46.530356 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Ribera.scn does not exist.  Aborting load.\n",
      "W1122 12:27:46.530369 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Ribera.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:27:46.530436 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:27:46.530444 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Ribera.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:27:46.530462 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Ribera.glb with render asset : data/scene_datasets/gibson/Ribera.glb and collision asset : data/scene_datasets/gibson/Ribera.glb\n",
      "I1122 12:27:46.530475 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:27:46.530479 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Ribera.glb.\n",
      "I1122 12:27:46.530481 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Ribera.glb \n",
      "I1122 12:27:46.530493 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Ribera.glb\n",
      "I1122 12:27:46.554487 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Ribera.glb\n",
      "W1122 12:27:46.554507 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:27:46.554518 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Ribera.glb yields 1 candidates.  Using data/scene_datasets/gibson/Ribera.glb.\n",
      "I1122 12:27:46.554531 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Ribera.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:27:46.554535 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:27:46.554548 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Ribera.glb yields 1 candidates.  Using data/scene_datasets/gibson/Ribera.glb.\n",
      "I1122 12:27:46.554555 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Ribera.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:27:46.554558 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:27:46.554571 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Ribera.glb with renderer.\n",
      "I1122 12:27:46.562052 316358080 PathFinder.cpp:382] Building navmesh with 127x175 cells\n",
      "I1122 12:27:46.609447 316358080 PathFinder.cpp:652] Created navmesh with 100 vertices 50 polygons\n",
      "I1122 12:27:46.609750 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 520\n",
      "{'distance_to_goal': 0.16637049615383148, 'success': 1.0, 'spl': 1.0, 'reward': 5.275756207108499, 'stats_actions': {3: 11, 1: 13, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 521\n",
      "{'distance_to_goal': 0.139168843626976, 'success': 1.0, 'spl': 0.8046520370838703, 'reward': 5.066472578644754, 'stats_actions': {2: 11, 3: 6, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 522\n",
      "{'distance_to_goal': 0.017117273062467575, 'success': 1.0, 'spl': 0.7529272001444459, 'reward': 9.599302595406776, 'stats_actions': {3: 82, 1: 56, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 523\n",
      "{'distance_to_goal': 0.10614021867513657, 'success': 1.0, 'spl': 0.9929773160762189, 'reward': 5.102791685163976, 'stats_actions': {3: 8, 1: 12, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 524\n",
      "{'distance_to_goal': 0.02768155001103878, 'success': 1.0, 'spl': 0.9399237374968618, 'reward': 7.362483893409375, 'stats_actions': {3: 8, 1: 22, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 525\n",
      "{'distance_to_goal': 0.06607893109321594, 'success': 1.0, 'spl': 0.8862918625341489, 'reward': 6.79368211627007, 'stats_actions': {3: 10, 1: 22, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 526\n",
      "{'distance_to_goal': 0.07539419084787369, 'success': 1.0, 'spl': 0.7324183258474978, 'reward': 5.191682196557523, 'stats_actions': {3: 13, 1: 19, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 527\n",
      "{'distance_to_goal': 0.15886852145195007, 'success': 1.0, 'spl': 0.8561094960643396, 'reward': 8.966119614839563, 'stats_actions': {3: 19, 1: 39, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 528\n",
      "{'distance_to_goal': 0.06619823724031448, 'success': 1.0, 'spl': 0.9982347087853437, 'reward': 5.674008938968182, 'stats_actions': {3: 6, 1: 15, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 529\n",
      "{'distance_to_goal': 0.05150431767106056, 'success': 1.0, 'spl': 0.9217024132320931, 'reward': 6.196774490922692, 'stats_actions': {3: 10, 1: 18, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 530\n",
      "{'distance_to_goal': 0.0736614540219307, 'success': 1.0, 'spl': 0.8784495794136397, 'reward': 10.183761260211474, 'stats_actions': {2: 3, 3: 29, 1: 39, 0: 1}}\n",
      "\n",
      "Episodes finished: 531\n",
      "{'distance_to_goal': 0.11235328018665314, 'success': 1.0, 'spl': 0.9559470760413906, 'reward': 5.500784212946893, 'stats_actions': {3: 7, 1: 14, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 532\n",
      "{'distance_to_goal': 0.03050406649708748, 'success': 1.0, 'spl': 0.6174506276645131, 'reward': 7.280883033722644, 'stats_actions': {3: 26, 1: 37, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 533\n",
      "{'distance_to_goal': 0.08180700242519379, 'success': 1.0, 'spl': 0.9918825643932673, 'reward': 5.713480568528177, 'stats_actions': {3: 9, 1: 15, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 534\n",
      "{'distance_to_goal': 0.07673492282629013, 'success': 1.0, 'spl': 0.684135951317125, 'reward': 7.81825964123011, 'stats_actions': {3: 25, 1: 36, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 535\n",
      "{'distance_to_goal': 0.048343464732170105, 'success': 1.0, 'spl': 0.7852378554201015, 'reward': 6.526774180531506, 'stats_actions': {2: 4, 3: 16, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 536\n",
      "{'distance_to_goal': 0.14485354721546173, 'success': 1.0, 'spl': 0.9376856128637673, 'reward': 5.202624890208245, 'stats_actions': {3: 5, 1: 13, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 537\n",
      "{'distance_to_goal': 0.09105149656534195, 'success': 1.0, 'spl': 0.7625344135739027, 'reward': 7.516693864762788, 'stats_actions': {3: 15, 1: 30, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 538\n",
      "{'distance_to_goal': 0.07029262185096741, 'success': 1.0, 'spl': 0.7677990438578005, 'reward': 7.607302592992789, 'stats_actions': {3: 41, 1: 33, 2: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 539\n",
      "{'distance_to_goal': 0.10384123027324677, 'success': 1.0, 'spl': 1.0, 'reward': 5.634164865612986, 'stats_actions': {3: 6, 1: 14, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 540\n",
      "{'distance_to_goal': 0.14890730381011963, 'success': 1.0, 'spl': 0.9632355797317282, 'reward': 7.002109065055851, 'stats_actions': {2: 7, 3: 7, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 541\n",
      "{'distance_to_goal': 0.15591523051261902, 'success': 1.0, 'spl': 0.2950591591415122, 'reward': 4.934558936357497, 'stats_actions': {3: 130, 1: 97, 2: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 542\n",
      "{'distance_to_goal': 0.024404259398579597, 'success': 1.0, 'spl': 0.8374019313821784, 'reward': 6.79022014550865, 'stats_actions': {2: 11, 1: 23, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 543\n",
      "{'distance_to_goal': 0.11705849319696426, 'success': 1.0, 'spl': 0.9866278832890871, 'reward': 8.326940625607975, 'stats_actions': {3: 10, 1: 27, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 544\n",
      "{'distance_to_goal': 0.08734534680843353, 'success': 1.0, 'spl': 0.8654133962215713, 'reward': 8.762657819390302, 'stats_actions': {3: 23, 1: 32, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 545\n",
      "{'distance_to_goal': 0.05842877924442291, 'success': 1.0, 'spl': 0.8045772648403319, 'reward': 6.094457497000697, 'stats_actions': {3: 15, 1: 20, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 546\n",
      "{'distance_to_goal': 0.1112559512257576, 'success': 1.0, 'spl': 0.8360140924140361, 'reward': 8.636461486518389, 'stats_actions': {3: 36, 1: 49, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 547\n",
      "{'distance_to_goal': 0.04257941618561745, 'success': 1.0, 'spl': 0.935996578030835, 'reward': 7.932093664258723, 'stats_actions': {2: 4, 3: 13, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 548\n",
      "{'distance_to_goal': 0.13331280648708344, 'success': 1.0, 'spl': 0.969731137859359, 'reward': 5.026935711503031, 'stats_actions': {3: 11, 1: 12, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 549\n",
      "{'distance_to_goal': 0.08871038258075714, 'success': 1.0, 'spl': 0.9610176225395307, 'reward': 6.716789705157285, 'stats_actions': {2: 16, 1: 20, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 550\n",
      "{'distance_to_goal': 0.03374659642577171, 'success': 1.0, 'spl': 0.7013629943079459, 'reward': 8.815390957742943, 'stats_actions': {2: 18, 3: 26, 1: 54, 0: 1}}\n",
      "\n",
      "Episodes finished: 551\n",
      "{'distance_to_goal': 0.013810675591230392, 'success': 1.0, 'spl': 0.9892331736406719, 'reward': 4.554072882682085, 'stats_actions': {3: 8, 1: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 552\n",
      "{'distance_to_goal': 0.18100957572460175, 'success': 1.0, 'spl': 0.6282739011597571, 'reward': 7.533638537526135, 'stats_actions': {3: 32, 1: 39, 2: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 553\n",
      "{'distance_to_goal': 0.15298664569854736, 'success': 1.0, 'spl': 0.9274123851381463, 'reward': 9.802768855094918, 'stats_actions': {2: 9, 3: 25, 1: 37, 0: 1}}\n",
      "\n",
      "Episodes finished: 554\n",
      "{'distance_to_goal': 0.06905020028352737, 'success': 1.0, 'spl': 0.9808545935683312, 'reward': 6.77878341406584, 'stats_actions': {3: 4, 1: 19, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 555\n",
      "{'distance_to_goal': 0.14003172516822815, 'success': 1.0, 'spl': 0.7105539543123195, 'reward': 5.849080365896227, 'stats_actions': {2: 6, 3: 45, 1: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 556\n",
      "{'distance_to_goal': 0.019773466512560844, 'success': 1.0, 'spl': 0.5775444240179982, 'reward': 5.920835473611953, 'stats_actions': {3: 18, 1: 28, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 557\n",
      "{'distance_to_goal': 0.07023099064826965, 'success': 1.0, 'spl': 0.8923074022616612, 'reward': 9.522382153272638, 'stats_actions': {3: 13, 1: 34, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 558\n",
      "{'distance_to_goal': 0.08997106552124023, 'success': 1.0, 'spl': 0.7239150878378037, 'reward': 7.214000835418704, 'stats_actions': {3: 25, 1: 31, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 559\n",
      "{'distance_to_goal': 0.17876003682613373, 'success': 1.0, 'spl': 0.3015616599075252, 'reward': 8.14443652689458, 'stats_actions': {3: 133, 1: 119, 2: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 560\n",
      "{'distance_to_goal': 0.09064780920743942, 'success': 1.0, 'spl': 0.7428524271925923, 'reward': 6.381949942409996, 'stats_actions': {2: 9, 3: 24, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 561\n",
      "{'distance_to_goal': 0.12372086197137833, 'success': 1.0, 'spl': 0.7498659601159771, 'reward': 5.29473444312811, 'stats_actions': {3: 7, 1: 18, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 562\n",
      "{'distance_to_goal': 0.024540379643440247, 'success': 1.0, 'spl': 0.9540757178232828, 'reward': 7.8015073841810265, 'stats_actions': {3: 6, 1: 24, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 563\n",
      "{'distance_to_goal': 0.05502434819936752, 'success': 1.0, 'spl': 1.0, 'reward': 5.622637757360937, 'stats_actions': {3: 8, 1: 14, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 564\n",
      "{'distance_to_goal': 0.009108723141252995, 'success': 1.0, 'spl': 0.9755682193197631, 'reward': 4.854598866961897, 'stats_actions': {3: 4, 1: 11, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 565\n",
      "{'distance_to_goal': 0.1029273122549057, 'success': 1.0, 'spl': 0.8412238879535975, 'reward': 9.132129107117667, 'stats_actions': {3: 32, 1: 44, 2: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 566\n",
      "{'distance_to_goal': 0.05849752202630043, 'success': 1.0, 'spl': 0.4900588410990598, 'reward': 7.498245107978585, 'stats_actions': {3: 76, 1: 66, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 567\n",
      "{'distance_to_goal': 0.06314907222986221, 'success': 1.0, 'spl': 0.9540621668313257, 'reward': 6.909596918523317, 'stats_actions': {2: 7, 1: 21, 3: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 568\n",
      "{'distance_to_goal': 0.00408625602722168, 'success': 1.0, 'spl': 0.7253438751994521, 'reward': 7.239958391189582, 'stats_actions': {3: 20, 1: 33, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 569\n",
      "{'distance_to_goal': 0.04549158737063408, 'success': 1.0, 'spl': 1.0, 'reward': 5.862828076630833, 'stats_actions': {3: 6, 1: 15, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 570\n",
      "{'distance_to_goal': 0.08018475025892258, 'success': 1.0, 'spl': 0.42183281257006133, 'reward': 4.321374345123767, 'stats_actions': {2: 9, 3: 19, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 571\n",
      "{'distance_to_goal': 0.1098339855670929, 'success': 1.0, 'spl': 0.9614665109300446, 'reward': 4.543832033872604, 'stats_actions': {2: 2, 3: 12, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 572\n",
      "{'distance_to_goal': 0.03839299827814102, 'success': 1.0, 'spl': 0.9409461089463887, 'reward': 9.02224418967963, 'stats_actions': {3: 11, 2: 12, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 573\n",
      "{'distance_to_goal': 0.010533260181546211, 'success': 1.0, 'spl': 0.714150382582259, 'reward': 4.576266266033054, 'stats_actions': {2: 3, 3: 17, 1: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 574\n",
      "{'distance_to_goal': 0.024816613644361496, 'success': 1.0, 'spl': 0.8726893453954834, 'reward': 5.42776901677251, 'stats_actions': {2: 3, 3: 13, 1: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 575\n",
      "{'distance_to_goal': 0.10521633177995682, 'success': 1.0, 'spl': 0.31617681913119455, 'reward': 3.9078691288828846, 'stats_actions': {2: 13, 1: 28, 3: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 576\n",
      "{'distance_to_goal': 0.052931785583496094, 'success': 0.0, 'spl': 0.0, 'reward': -1.6002955436706305, 'stats_actions': {3: 120, 1: 266, 2: 114}}\n",
      "\n",
      "Episodes finished: 577\n",
      "{'distance_to_goal': 0.10508781671524048, 'success': 1.0, 'spl': 0.9533921811124546, 'reward': 5.069845120906832, 'stats_actions': {2: 4, 1: 13, 3: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 578\n",
      "{'distance_to_goal': 0.014919435605406761, 'success': 1.0, 'spl': 0.27693292728224456, 'reward': 5.510800302401192, 'stats_actions': {3: 123, 2: 61, 1: 105, 0: 1}}\n",
      "\n",
      "Episodes finished: 579\n",
      "{'distance_to_goal': 0.1835595965385437, 'success': 1.0, 'spl': 1.0, 'reward': 5.918879568576815, 'stats_actions': {3: 4, 1: 13, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 580\n",
      "{'distance_to_goal': 0.0861135870218277, 'success': 1.0, 'spl': 0.7001465634719612, 'reward': 6.761475867629055, 'stats_actions': {3: 21, 1: 28, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 581\n",
      "{'distance_to_goal': 0.08030598610639572, 'success': 1.0, 'spl': 0.5164162553263175, 'reward': 7.67257367163897, 'stats_actions': {3: 67, 2: 11, 1: 67, 0: 1}}\n",
      "\n",
      "Episodes finished: 582\n",
      "{'distance_to_goal': 0.09091862291097641, 'success': 1.0, 'spl': 0.7589969049705986, 'reward': 5.970875257551674, 'stats_actions': {2: 2, 3: 18, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 583\n",
      "{'distance_to_goal': 0.09199076890945435, 'success': 1.0, 'spl': 0.47411413905831973, 'reward': 6.720156257152562, 'stats_actions': {3: 129, 1: 116, 2: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 584\n",
      "{'distance_to_goal': 0.13099901378154755, 'success': 1.0, 'spl': 0.6734199570103357, 'reward': 9.83427224934103, 'stats_actions': {2: 16, 3: 53, 1: 52, 0: 1}}\n",
      "\n",
      "Episodes finished: 585\n",
      "{'distance_to_goal': 0.056405968964099884, 'success': 1.0, 'spl': 0.9701276580448716, 'reward': 8.534381899535662, 'stats_actions': {2: 12, 3: 11, 1: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 586\n",
      "{'distance_to_goal': 0.09352642297744751, 'success': 1.0, 'spl': 0.4791117627373367, 'reward': 5.607904498577119, 'stats_actions': {2: 12, 1: 32, 3: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 587\n",
      "{'distance_to_goal': 0.0747331753373146, 'success': 1.0, 'spl': 0.9778667527367393, 'reward': 5.981047655045988, 'stats_actions': {2: 8, 3: 5, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 588\n",
      "{'distance_to_goal': 0.06658171117305756, 'success': 1.0, 'spl': 0.8536930241772932, 'reward': 8.118463206887252, 'stats_actions': {2: 11, 3: 17, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 589\n",
      "{'distance_to_goal': 0.0916774570941925, 'success': 1.0, 'spl': 0.9702964538736082, 'reward': 6.366368445158007, 'stats_actions': {3: 5, 1: 18, 2: 7, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:30:01.101689 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:30:01.174885 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Sands.navmesh\n",
      "I1122 12:30:01.101718 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:30:01.101723 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:30:01.101727 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:30:01.101874 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:30:01.103211 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:30:01.103219 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:30:01.104058 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Sands.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:30:01.139669 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Sands.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Sands.scene_instance.json\n",
      "I1122 12:30:01.139686 316358080 MetadataMediatI1122 12:30:01.175709 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 590\n",
      "{'distance_to_goal': 0.07672935724258423, 'success': 1.0, 'spl': 0.9260411028639687, 'reward': 5.3077825903892535, 'stats_actions': {2: 3, 1: 14, 3: 7, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "or.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Sands.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:30:01.139693 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Sands.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Sands.stage_config.json\n",
      "I1122 12:30:01.139698 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Sands.stage_config.json from original name : data/scene_datasets/gibson/Sands.glb | This file  does not exist.\n",
      "I1122 12:30:01.142489 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Sands.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:30:01.142534 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Sands.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:30:01.142539 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:30:01.142546 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Sands.navmesh\n",
      "I1122 12:30:01.142552 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Sands.navmesh\n",
      "I1122 12:30:01.142669 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:30:01.142678 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:30:01.142683 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Sands.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Sands.scn\n",
      "E1122 12:30:01.142689 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Sands.scn does not exist.  Aborting load.\n",
      "W1122 12:30:01.142697 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Sands.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:30:01.142762 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:30:01.142768 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Sands.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:30:01.142786 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Sands.glb with render asset : data/scene_datasets/gibson/Sands.glb and collision asset : data/scene_datasets/gibson/Sands.glb\n",
      "I1122 12:30:01.142796 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:30:01.142799 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Sands.glb.\n",
      "I1122 12:30:01.142802 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Sands.glb \n",
      "I1122 12:30:01.142814 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Sands.glb\n",
      "I1122 12:30:01.173979 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Sands.glb\n",
      "W1122 12:30:01.173998 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:30:01.174010 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Sands.glb yields 1 candidates.  Using data/scene_datasets/gibson/Sands.glb.\n",
      "I1122 12:30:01.174022 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Sands.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:30:01.174027 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:30:01.174039 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Sands.glb yields 1 candidates.  Using data/scene_datasets/gibson/Sands.glb.\n",
      "I1122 12:30:01.174047 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Sands.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:30:01.174050 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:30:01.174062 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Sands.glb with renderer.\n",
      "I1122 12:30:01.182356 316358080 PathFinder.cpp:382] Building navmesh with 154x145 cells\n",
      "I1122 12:30:01.252177 316358080 PathFinder.cpp:652] Created navmesh with 140 vertices 68 polygons\n",
      "I1122 12:30:01.252199 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 591\n",
      "{'distance_to_goal': 0.043794550001621246, 'success': 1.0, 'spl': 0.9436709996167266, 'reward': 7.50231381028891, 'stats_actions': {2: 3, 3: 11, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 592\n",
      "{'distance_to_goal': 0.08915501087903976, 'success': 1.0, 'spl': 0.6017159950154592, 'reward': 7.383054595291618, 'stats_actions': {1: 37, 3: 12, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 593\n",
      "{'distance_to_goal': 0.098796047270298, 'success': 1.0, 'spl': 0.7204733067903294, 'reward': 6.769328037202361, 'stats_actions': {3: 32, 1: 28, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 594\n",
      "{'distance_to_goal': 0.029759595170617104, 'success': 1.0, 'spl': 0.8666160111227846, 'reward': 9.523130915388471, 'stats_actions': {2: 4, 3: 13, 1: 35, 0: 1}}\n",
      "\n",
      "Episodes finished: 595\n",
      "{'distance_to_goal': 0.044904932379722595, 'success': 1.0, 'spl': 0.9224829660999289, 'reward': 8.179499612450606, 'stats_actions': {3: 12, 1: 27, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 596\n",
      "{'distance_to_goal': 0.06901097297668457, 'success': 0.0, 'spl': 0.0, 'reward': 0.0922138690948969, 'stats_actions': {2: 111, 3: 146, 1: 243}}\n",
      "\n",
      "Episodes finished: 597\n",
      "{'distance_to_goal': 0.13771513104438782, 'success': 1.0, 'spl': 1.0, 'reward': 5.44453716158867, 'stats_actions': {2: 5, 1: 13, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 598\n",
      "{'distance_to_goal': 0.07084111869335175, 'success': 1.0, 'spl': 0.958800603062614, 'reward': 7.296557295918468, 'stats_actions': {3: 6, 1: 22, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 599\n",
      "{'distance_to_goal': 14.873772621154785, 'success': 0.0, 'spl': 0.0, 'reward': -9.350945644378639, 'stats_actions': {3: 55, 1: 66, 2: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 600\n",
      "{'distance_to_goal': 0.06664101779460907, 'success': 1.0, 'spl': 0.5862886297397703, 'reward': 10.45027041256429, 'stats_actions': {2: 17, 3: 51, 1: 64, 0: 1}}\n",
      "\n",
      "Episodes finished: 601\n",
      "{'distance_to_goal': 0.05155622586607933, 'success': 1.0, 'spl': 0.9342221035333358, 'reward': 8.00558366671205, 'stats_actions': {3: 14, 1: 26, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 602\n",
      "{'distance_to_goal': 0.07471898198127747, 'success': 1.0, 'spl': 0.9354480126112663, 'reward': 6.328398808240893, 'stats_actions': {3: 11, 1: 20, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 603\n",
      "{'distance_to_goal': 0.10728871077299118, 'success': 1.0, 'spl': 0.9673937942883043, 'reward': 5.001290695965291, 'stats_actions': {3: 8, 1: 12, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 604\n",
      "{'distance_to_goal': 0.021397864446043968, 'success': 1.0, 'spl': 0.8422945632184277, 'reward': 7.2819292763620656, 'stats_actions': {2: 4, 3: 14, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 605\n",
      "{'distance_to_goal': 0.13736587762832642, 'success': 1.0, 'spl': 0.5446827492357456, 'reward': 5.209424722194673, 'stats_actions': {2: 9, 1: 50, 3: 60, 0: 1}}\n",
      "\n",
      "Episodes finished: 606\n",
      "{'distance_to_goal': 0.09584256261587143, 'success': 1.0, 'spl': 0.9430400541217757, 'reward': 7.615588521063333, 'stats_actions': {3: 9, 1: 24, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 607\n",
      "{'distance_to_goal': 0.09347816556692123, 'success': 1.0, 'spl': 0.935401071297928, 'reward': 6.300974349081519, 'stats_actions': {3: 9, 2: 3, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 608\n",
      "{'distance_to_goal': 0.057132117450237274, 'success': 1.0, 'spl': 0.6354595630378839, 'reward': 7.848598091900354, 'stats_actions': {2: 14, 3: 25, 1: 39, 0: 1}}\n",
      "\n",
      "Episodes finished: 609\n",
      "{'distance_to_goal': 0.10890957713127136, 'success': 1.0, 'spl': 0.9305423001337905, 'reward': 8.113936492204672, 'stats_actions': {2: 8, 1: 28, 3: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 610\n",
      "{'distance_to_goal': 0.09834910929203033, 'success': 1.0, 'spl': 0.7740730130654291, 'reward': 7.598477005362516, 'stats_actions': {2: 12, 3: 18, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 611\n",
      "{'distance_to_goal': 0.01658160611987114, 'success': 1.0, 'spl': 0.8747362886545863, 'reward': 7.484112916737799, 'stats_actions': {2: 9, 3: 14, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 612\n",
      "{'distance_to_goal': 0.07273431867361069, 'success': 1.0, 'spl': 0.809550841965637, 'reward': 5.760244349539282, 'stats_actions': {3: 10, 1: 18, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 613\n",
      "{'distance_to_goal': 0.09833800792694092, 'success': 1.0, 'spl': 0.6575342325063852, 'reward': 6.135634503364566, 'stats_actions': {2: 8, 3: 19, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 614\n",
      "{'distance_to_goal': 0.06987670809030533, 'success': 1.0, 'spl': 0.9127075514619181, 'reward': 9.994710007607944, 'stats_actions': {3: 25, 1: 36, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 615\n",
      "{'distance_to_goal': 0.056547533720731735, 'success': 1.0, 'spl': 0.7546127956957625, 'reward': 8.226236012727032, 'stats_actions': {3: 22, 1: 35, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 616\n",
      "{'distance_to_goal': 0.046243052929639816, 'success': 1.0, 'spl': 0.5754903212056606, 'reward': 8.172711147815004, 'stats_actions': {3: 30, 1: 46, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 617\n",
      "{'distance_to_goal': 0.10454148799180984, 'success': 1.0, 'spl': 0.4042174591163363, 'reward': 9.616251930892481, 'stats_actions': {3: 100, 1: 92, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 618\n",
      "{'distance_to_goal': 0.07484899461269379, 'success': 1.0, 'spl': 0.8574438107500434, 'reward': 5.1462041002511985, 'stats_actions': {3: 11, 1: 14, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 619\n",
      "{'distance_to_goal': 0.09456396102905273, 'success': 1.0, 'spl': 0.9226533125927925, 'reward': 7.193689823150639, 'stats_actions': {3: 20, 2: 6, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 620\n",
      "{'distance_to_goal': 0.06946343928575516, 'success': 1.0, 'spl': 0.9407298890808626, 'reward': 6.920531677901748, 'stats_actions': {2: 11, 1: 21, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 621\n",
      "{'distance_to_goal': 0.08775666356086731, 'success': 1.0, 'spl': 0.9210777214546009, 'reward': 8.49862707972527, 'stats_actions': {3: 23, 1: 29, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 622\n",
      "{'distance_to_goal': 0.12057826668024063, 'success': 1.0, 'spl': 0.41154630485862875, 'reward': 7.114170039594181, 'stats_actions': {2: 14, 3: 57, 1: 59, 0: 1}}\n",
      "\n",
      "Episodes finished: 623\n",
      "{'distance_to_goal': 0.07469651103019714, 'success': 1.0, 'spl': 0.724163136070798, 'reward': 6.589195548295978, 'stats_actions': {3: 16, 1: 26, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 624\n",
      "{'distance_to_goal': 0.050566237419843674, 'success': 1.0, 'spl': 0.916297529162076, 'reward': 7.491464173346763, 'stats_actions': {2: 7, 1: 24, 3: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 625\n",
      "{'distance_to_goal': 0.1447245180606842, 'success': 1.0, 'spl': 0.8766850604899769, 'reward': 6.0707892072200815, 'stats_actions': {2: 4, 3: 24, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 626\n",
      "{'distance_to_goal': 0.14135292172431946, 'success': 1.0, 'spl': 0.846068562178924, 'reward': 7.959887160062798, 'stats_actions': {2: 22, 3: 27, 1: 33, 0: 1}}\n",
      "\n",
      "Episodes finished: 627\n",
      "{'distance_to_goal': 0.1671406477689743, 'success': 1.0, 'spl': 0.9247490309090697, 'reward': 7.441649387478833, 'stats_actions': {2: 5, 1: 24, 3: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 628\n",
      "{'distance_to_goal': 0.015247655101120472, 'success': 1.0, 'spl': 0.5628112613971726, 'reward': 10.705596270374972, 'stats_actions': {3: 79, 1: 70, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 629\n",
      "{'distance_to_goal': 0.04175245016813278, 'success': 1.0, 'spl': 0.9526954411534373, 'reward': 7.0341622379422235, 'stats_actions': {3: 10, 1: 21, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 630\n",
      "{'distance_to_goal': 0.15219341218471527, 'success': 1.0, 'spl': 0.5832899232459626, 'reward': 9.276631394028673, 'stats_actions': {3: 46, 1: 55, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 631\n",
      "{'distance_to_goal': 0.08731932938098907, 'success': 1.0, 'spl': 0.9392098485354242, 'reward': 7.58043606460095, 'stats_actions': {3: 11, 1: 24, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 632\n",
      "{'distance_to_goal': 0.10962307453155518, 'success': 1.0, 'spl': 0.9291458229773978, 'reward': 7.512916483879094, 'stats_actions': {2: 4, 3: 17, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 633\n",
      "{'distance_to_goal': 0.08005452901124954, 'success': 1.0, 'spl': 0.9022322342996947, 'reward': 9.299743597209462, 'stats_actions': {3: 15, 1: 33, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 634\n",
      "{'distance_to_goal': 0.09768493473529816, 'success': 1.0, 'spl': 0.30828736062177575, 'reward': 4.054339849352837, 'stats_actions': {3: 27, 1: 32, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 635\n",
      "{'distance_to_goal': 0.11355758458375931, 'success': 1.0, 'spl': 0.93877883750127, 'reward': 11.736593973338612, 'stats_actions': {3: 23, 1: 43, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 636\n",
      "{'distance_to_goal': 0.13364823162555695, 'success': 1.0, 'spl': 0.6390938169222876, 'reward': 6.2651243895292295, 'stats_actions': {3: 23, 1: 30, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 637\n",
      "{'distance_to_goal': 0.057340990751981735, 'success': 1.0, 'spl': 0.9437335540220394, 'reward': 6.781731618195775, 'stats_actions': {3: 10, 2: 4, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 638\n",
      "{'distance_to_goal': 0.08430659770965576, 'success': 1.0, 'spl': 0.8358584692275244, 'reward': 8.343597722053534, 'stats_actions': {2: 5, 3: 18, 1: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 639\n",
      "{'distance_to_goal': 0.14592859148979187, 'success': 1.0, 'spl': 0.9173271991688072, 'reward': 7.4098489964008385, 'stats_actions': {3: 12, 1: 24, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 640\n",
      "{'distance_to_goal': 0.11151930689811707, 'success': 1.0, 'spl': 0.9541575228773607, 'reward': 8.146293326616291, 'stats_actions': {1: 26, 3: 3, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 641\n",
      "{'distance_to_goal': 0.0553920604288578, 'success': 1.0, 'spl': 0.8251287909813125, 'reward': 7.540071234554056, 'stats_actions': {3: 13, 1: 27, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 642\n",
      "{'distance_to_goal': 14.813751220703125, 'success': 0.0, 'spl': 0.0, 'reward': -7.146393661499016, 'stats_actions': {2: 10, 3: 24, 1: 28, 0: 1}}\n",
      "\n",
      "Episodes finished: 643\n",
      "{'distance_to_goal': 0.13976289331912994, 'success': 1.0, 'spl': 0.8195997227053321, 'reward': 4.119189180731773, 'stats_actions': {3: 18, 1: 11, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 644\n",
      "{'distance_to_goal': 0.03639260679483414, 'success': 1.0, 'spl': 0.7008586505406849, 'reward': 9.134325967729104, 'stats_actions': {2: 12, 1: 43, 3: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 645\n",
      "{'distance_to_goal': 0.06516142189502716, 'success': 1.0, 'spl': 0.8736974160790553, 'reward': 8.144758126139646, 'stats_actions': {2: 7, 3: 28, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 646\n",
      "{'distance_to_goal': 6.389110088348389, 'success': 0.0, 'spl': 0.0, 'reward': -4.8431963920592676, 'stats_actions': {2: 99, 1: 305, 3: 96}}\n",
      "\n",
      "Episodes finished: 647\n",
      "{'distance_to_goal': 0.08191534876823425, 'success': 1.0, 'spl': 0.6744414269856979, 'reward': 9.573759661912925, 'stats_actions': {3: 28, 1: 48, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 648\n",
      "{'distance_to_goal': 0.09507110714912415, 'success': 1.0, 'spl': 0.9438812576849429, 'reward': 8.36350780367852, 'stats_actions': {2: 9, 1: 27, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 649\n",
      "{'distance_to_goal': 0.013295118696987629, 'success': 1.0, 'spl': 0.7585584611022729, 'reward': 8.93176606904716, 'stats_actions': {2: 12, 3: 26, 1: 38, 0: 1}}\n",
      "\n",
      "Episodes finished: 650\n",
      "{'distance_to_goal': 0.10550641268491745, 'success': 1.0, 'spl': 0.467150967029168, 'reward': 6.317680499851709, 'stats_actions': {3: 24, 1: 42, 2: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 651\n",
      "{'distance_to_goal': 0.09213300049304962, 'success': 1.0, 'spl': 0.9366737707018186, 'reward': 7.786519038081175, 'stats_actions': {2: 11, 3: 17, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 652\n",
      "{'distance_to_goal': 0.09846983850002289, 'success': 1.0, 'spl': 0.9943649300310966, 'reward': 6.152952776551249, 'stats_actions': {2: 9, 1: 16, 3: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 653\n",
      "{'distance_to_goal': 0.05175866559147835, 'success': 1.0, 'spl': 0.878933164596141, 'reward': 6.148945069760086, 'stats_actions': {3: 15, 1: 19, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 654\n",
      "{'distance_to_goal': 0.1386093646287918, 'success': 1.0, 'spl': 0.9842292079160762, 'reward': 5.536964918971063, 'stats_actions': {3: 6, 1: 14, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 655\n",
      "{'distance_to_goal': 0.0612759068608284, 'success': 1.0, 'spl': 0.4124854542316795, 'reward': 7.589840864837172, 'stats_actions': {2: 18, 1: 63, 3: 51, 0: 1}}\n",
      "\n",
      "Episodes finished: 656\n",
      "{'distance_to_goal': 0.08501206338405609, 'success': 1.0, 'spl': 0.9210129831780283, 'reward': 5.36035596907139, 'stats_actions': {3: 9, 1: 15, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 657\n",
      "{'distance_to_goal': 0.09312047064304352, 'success': 1.0, 'spl': 0.4554094131432684, 'reward': 5.419387788176538, 'stats_actions': {3: 33, 1: 37, 2: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 658\n",
      "{'distance_to_goal': 0.13821448385715485, 'success': 1.0, 'spl': 0.912289356079383, 'reward': 12.054444856047642, 'stats_actions': {3: 16, 1: 46, 2: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 659\n",
      "{'distance_to_goal': 0.09121230989694595, 'success': 1.0, 'spl': 0.8256111461794624, 'reward': 7.906857453286651, 'stats_actions': {3: 20, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 660\n",
      "{'distance_to_goal': 0.14190679788589478, 'success': 1.0, 'spl': 0.8840938266734093, 'reward': 9.65926961660386, 'stats_actions': {3: 14, 1: 36, 2: 13, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:32:26.121459 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:32:26.121484 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:32:26.121490 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:32:26.121492 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:32:26.121627 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:32:26.122704 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:32:26.122710 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:32:26.123535 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Scioto.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:32:26.163906 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Scioto.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Scioto.scene_instance.json\n",
      "I1122 12:32:26.163926 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Scioto.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:32:26.163933 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Scioto.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Scioto.stage_config.json\n",
      "I1122 12:32:26.163938 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Scioto.stage_config.json from original name : data/scene_datasets/gibson/Scioto.glb | This file  does not exist.\n",
      "I1122 12:32:26.163990 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Scioto.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:32:26.164016 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Scioto.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:32:26.164019 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:32:26.164027 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Scioto.navmesh\n",
      "I1122 12:32:26.164031 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Scioto.navmesh\n",
      "I1122 12:32:26.164228 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:32:26.164237 316358080 SceneGraph.h:85] Created DrawableGI1122 12:32:26.197541 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Scioto.navmesh\n",
      "roup: \n",
      "I1122 12:32:26.164242 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Scioto.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Scioto.scn\n",
      "E1122 12:32:26.164247 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Scioto.scn does not exist.  Aborting load.\n",
      "W1122 12:32:26.164253 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Scioto.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:32:26.164302 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:32:26.164309 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Scioto.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:32:26.164323 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Scioto.glb with render asset : data/scene_datasets/gibson/Scioto.glb and collision asset : data/scene_datasets/gibson/Scioto.glb\n",
      "I1122 12:32:26.164335 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:32:26.164337 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:32:26.164340 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Scioto.glb \n",
      "I1122 12:32:26.164351 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Scioto.glb\n",
      "I1122 12:32:26.196141 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Scioto.glb\n",
      "W1122 12:32:26.196161 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I112I1122 12:32:26.198408 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 661\n",
      "{'distance_to_goal': 0.0635470375418663, 'success': 1.0, 'spl': 0.39788540155671365, 'reward': 5.850563375055795, 'stats_actions': {3: 18, 1: 42, 2: 15, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 12:32:26.196171 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Scioto.glb yields 1 candidates.  Using data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:32:26.196185 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Scioto.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:32:26.196189 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:32:26.196202 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Scioto.glb yields 1 candidates.  Using data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:32:26.196209 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Scioto.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:32:26.196213 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:32:26.196224 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Scioto.glb with renderer.\n",
      "I1122 12:32:26.208864 316358080 PathFinder.cpp:382] Building navmesh with 239x204 cells\n",
      "I1122 12:32:26.383460 316358080 PathFinder.cpp:652] Created navmesh with 433 vertices 218 polygons\n",
      "I1122 12:32:26.383751 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 662\n",
      "{'distance_to_goal': 6.238680839538574, 'success': 0.0, 'spl': 0.0, 'reward': -0.27886009216306307, 'stats_actions': {3: 174, 1: 243, 2: 83}}\n",
      "\n",
      "Episodes finished: 663\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 664\n",
      "{'distance_to_goal': 11.019129753112793, 'success': 0.0, 'spl': 0.0, 'reward': -5.350283622741629, 'stats_actions': {2: 65, 3: 78, 1: 357}}\n",
      "\n",
      "Episodes finished: 665\n",
      "{'distance_to_goal': 0.12687191367149353, 'success': 1.0, 'spl': 0.9908773238836961, 'reward': 11.484379459619529, 'stats_actions': {3: 23, 1: 41, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 666\n",
      "{'distance_to_goal': 0.08589328080415726, 'success': 1.0, 'spl': 0.7351402264441159, 'reward': 9.156549555957323, 'stats_actions': {2: 5, 1: 41, 3: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 667\n",
      "{'distance_to_goal': 7.595539093017578, 'success': 0.0, 'spl': 0.0, 'reward': -5.120835304260198, 'stats_actions': {3: 138, 1: 229, 2: 133}}\n",
      "\n",
      "Episodes finished: 668\n",
      "{'distance_to_goal': 0.06008050590753555, 'success': 1.0, 'spl': 0.27264430245511967, 'reward': 7.3658472856879715, 'stats_actions': {2: 40, 3: 106, 1: 112, 0: 1}}\n",
      "\n",
      "Episodes finished: 669\n",
      "{'distance_to_goal': 0.05575311556458473, 'success': 1.0, 'spl': 0.9565302550845338, 'reward': 6.3799915896356145, 'stats_actions': {2: 5, 1: 18, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 670\n",
      "{'distance_to_goal': 0.17036110162734985, 'success': 1.0, 'spl': 0.7837544505417505, 'reward': 8.751405026912696, 'stats_actions': {3: 42, 1: 37, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 671\n",
      "{'distance_to_goal': 0.03056260570883751, 'success': 1.0, 'spl': 0.9349856756297162, 'reward': 8.031390538364652, 'stats_actions': {3: 10, 2: 5, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 672\n",
      "{'distance_to_goal': 0.074246346950531, 'success': 1.0, 'spl': 0.5058853682396334, 'reward': 5.036139986515046, 'stats_actions': {3: 18, 1: 43, 2: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 673\n",
      "{'distance_to_goal': 0.009116891771554947, 'success': 1.0, 'spl': 0.8193914952090637, 'reward': 4.913905626386405, 'stats_actions': {3: 8, 1: 13, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 674\n",
      "{'distance_to_goal': 0.14839109778404236, 'success': 1.0, 'spl': 1.0, 'reward': 3.3132896387577055, 'stats_actions': {3: 10, 1: 4, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 675\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 676\n",
      "{'distance_to_goal': 0.053310561925172806, 'success': 1.0, 'spl': 0.4784736276718543, 'reward': 11.518716720789696, 'stats_actions': {2: 20, 3: 55, 1: 91, 0: 1}}\n",
      "\n",
      "Episodes finished: 677\n",
      "{'distance_to_goal': 0.13977432250976562, 'success': 1.0, 'spl': 0.5958966027145144, 'reward': 10.705103187561054, 'stats_actions': {3: 40, 1: 66, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 678\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {1: 1}}\n",
      "\n",
      "Episodes finished: 679\n",
      "{'distance_to_goal': 0.0696350485086441, 'success': 1.0, 'spl': 0.9762741459622309, 'reward': 6.445882300734523, 'stats_actions': {2: 5, 3: 14, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 680\n",
      "{'distance_to_goal': 0.06789231300354004, 'success': 1.0, 'spl': 0.8621001471202646, 'reward': 10.66863360404969, 'stats_actions': {3: 12, 1: 41, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 681\n",
      "{'distance_to_goal': 8.062199592590332, 'success': 0.0, 'spl': 0.0, 'reward': -4.5753860473632235, 'stats_actions': {2: 64, 3: 239, 1: 197}}\n",
      "\n",
      "Episodes finished: 682\n",
      "{'distance_to_goal': 0.07994148880243301, 'success': 1.0, 'spl': 0.9295683968170153, 'reward': 12.773236306607734, 'stats_actions': {3: 15, 1: 48, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 683\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 684\n",
      "{'distance_to_goal': 0.052758559584617615, 'success': 1.0, 'spl': 0.3509481179000268, 'reward': 7.940037155747425, 'stats_actions': {2: 55, 1: 119, 3: 74, 0: 1}}\n",
      "\n",
      "Episodes finished: 685\n",
      "{'distance_to_goal': 0.016597628593444824, 'success': 1.0, 'spl': 0.8970533321387428, 'reward': 8.332776017189031, 'stats_actions': {3: 10, 1: 28, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 686\n",
      "{'distance_to_goal': 0.07982993870973587, 'success': 1.0, 'spl': 0.9214153268823468, 'reward': 9.765902769267566, 'stats_actions': {3: 10, 1: 34, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 687\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 688\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 689\n",
      "{'distance_to_goal': 0.023365888744592667, 'success': 1.0, 'spl': 0.8444701025820271, 'reward': 10.301337213367232, 'stats_actions': {2: 4, 3: 17, 1: 40, 0: 1}}\n",
      "\n",
      "Episodes finished: 690\n",
      "{'distance_to_goal': 0.18235965073108673, 'success': 1.0, 'spl': 0.3700971820294913, 'reward': 8.57921806991104, 'stats_actions': {2: 32, 1: 88, 3: 67, 0: 1}}\n",
      "\n",
      "Episodes finished: 691\n",
      "{'distance_to_goal': 16.28096580505371, 'success': 0.0, 'spl': 0.0, 'reward': -7.118701515197735, 'stats_actions': {2: 11, 3: 50, 1: 69, 0: 1}}\n",
      "\n",
      "Episodes finished: 692\n",
      "{'distance_to_goal': 7.152154922485352, 'success': 0.0, 'spl': 0.0, 'reward': -5.068586826324398, 'stats_actions': {2: 91, 3: 152, 1: 257}}\n",
      "\n",
      "Episodes finished: 693\n",
      "{'distance_to_goal': 0.05650776997208595, 'success': 1.0, 'spl': 0.8075441667599298, 'reward': 6.693468865007194, 'stats_actions': {2: 40, 3: 49, 1: 85, 0: 1}}\n",
      "\n",
      "Episodes finished: 694\n",
      "{'distance_to_goal': 0.032874200493097305, 'success': 1.0, 'spl': 0.4690924958301707, 'reward': 6.642850019782786, 'stats_actions': {3: 41, 2: 42, 1: 71, 0: 1}}\n",
      "\n",
      "Episodes finished: 695\n",
      "{'distance_to_goal': 11.771103858947754, 'success': 0.0, 'spl': 0.0, 'reward': -4.951275825500401, 'stats_actions': {2: 58, 3: 234, 1: 208}}\n",
      "\n",
      "Episodes finished: 696\n",
      "{'distance_to_goal': 7.019759178161621, 'success': 0.0, 'spl': 0.0, 'reward': -4.5191259384155025, 'stats_actions': {2: 82, 3: 194, 1: 224}}\n",
      "\n",
      "Episodes finished: 697\n",
      "{'distance_to_goal': 0.06250866502523422, 'success': 1.0, 'spl': 0.771285119477702, 'reward': 10.933668970167647, 'stats_actions': {3: 17, 1: 49, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 698\n",
      "{'distance_to_goal': 0.05657339468598366, 'success': 1.0, 'spl': 0.9710863454901753, 'reward': 9.579378963559876, 'stats_actions': {3: 14, 1: 32, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 699\n",
      "{'distance_to_goal': 0.05215992406010628, 'success': 1.0, 'spl': 0.871983355575015, 'reward': 11.963645816296351, 'stats_actions': {2: 10, 3: 15, 1: 47, 0: 1}}\n",
      "\n",
      "Episodes finished: 700\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 701\n",
      "{'distance_to_goal': 0.10024193674325943, 'success': 1.0, 'spl': 0.8622885838702035, 'reward': 9.330252753198153, 'stats_actions': {3: 21, 1: 35, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 702\n",
      "{'distance_to_goal': 10.48137378692627, 'success': 0.0, 'spl': 0.0, 'reward': -5.420168876647879, 'stats_actions': {2: 90, 3: 89, 1: 321}}\n",
      "\n",
      "Episodes finished: 703\n",
      "{'distance_to_goal': 7.25947904586792, 'success': 0.0, 'spl': 0.0, 'reward': -3.719277858734084, 'stats_actions': {3: 181, 1: 229, 2: 90}}\n",
      "\n",
      "Episodes finished: 704\n",
      "{'distance_to_goal': 0.15333285927772522, 'success': 1.0, 'spl': 0.30263179504548804, 'reward': 7.3430307042598875, 'stats_actions': {2: 44, 3: 88, 1: 100, 0: 1}}\n",
      "\n",
      "Episodes finished: 705\n",
      "{'distance_to_goal': 0.09794049710035324, 'success': 1.0, 'spl': 0.8651033862353971, 'reward': 9.884107537567624, 'stats_actions': {3: 29, 1: 38, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 706\n",
      "{'distance_to_goal': 12.889846801757812, 'success': 0.0, 'spl': 0.0, 'reward': -4.986189842224059, 'stats_actions': {3: 108, 1: 287, 2: 105}}\n",
      "\n",
      "Episodes finished: 707\n",
      "{'distance_to_goal': 0.09264181554317474, 'success': 1.0, 'spl': 0.937198642408283, 'reward': 10.365740485787398, 'stats_actions': {2: 4, 3: 15, 1: 37, 0: 1}}\n",
      "\n",
      "Episodes finished: 708\n",
      "{'distance_to_goal': 0.11606445908546448, 'success': 1.0, 'spl': 0.745510582435616, 'reward': 7.497452005147939, 'stats_actions': {3: 24, 1: 31, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 709\n",
      "{'distance_to_goal': 15.125439643859863, 'success': 0.0, 'spl': 0.0, 'reward': -8.481577873229885, 'stats_actions': {3: 240, 1: 221, 2: 39}}\n",
      "\n",
      "Episodes finished: 710\n",
      "{'distance_to_goal': 0.14863340556621552, 'success': 1.0, 'spl': 0.7650963432160349, 'reward': 7.570754507184038, 'stats_actions': {3: 16, 1: 33, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 711\n",
      "{'distance_to_goal': 0.12869632244110107, 'success': 1.0, 'spl': 0.2082484707353583, 'reward': 5.550076279640244, 'stats_actions': {2: 40, 3: 105, 1: 163, 0: 1}}\n",
      "\n",
      "Episodes finished: 712\n",
      "{'distance_to_goal': 11.085526466369629, 'success': 0.0, 'spl': 0.0, 'reward': 3.7497518920898463, 'stats_actions': {3: 49, 1: 51, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 713\n",
      "{'distance_to_goal': 9.704577445983887, 'success': 0.0, 'spl': 0.0, 'reward': -6.121315002441305, 'stats_actions': {2: 59, 3: 218, 1: 223}}\n",
      "\n",
      "Episodes finished: 714\n",
      "{'distance_to_goal': 16.15491485595703, 'success': 0.0, 'spl': 0.0, 'reward': -11.577246665954489, 'stats_actions': {3: 166, 1: 235, 2: 99}}\n",
      "\n",
      "Episodes finished: 715\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 716\n",
      "{'distance_to_goal': 0.1779734045267105, 'success': 1.0, 'spl': 0.5907810257286977, 'reward': 6.059173755049709, 'stats_actions': {3: 27, 1: 30, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 717\n",
      "{'distance_to_goal': 0.02844885364174843, 'success': 1.0, 'spl': 0.9226101655237943, 'reward': 5.862430224269631, 'stats_actions': {3: 7, 1: 16, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 718\n",
      "{'distance_to_goal': 0.06504460424184799, 'success': 1.0, 'spl': 0.7026084550201751, 'reward': 11.393819645941269, 'stats_actions': {2: 15, 3: 22, 1: 58, 0: 1}}\n",
      "\n",
      "Episodes finished: 719\n",
      "{'distance_to_goal': 0.10303880274295807, 'success': 1.0, 'spl': 0.7466594374385045, 'reward': 10.247665657401093, 'stats_actions': {3: 19, 1: 46, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 720\n",
      "{'distance_to_goal': 0.07464496046304703, 'success': 1.0, 'spl': 0.9930513679240321, 'reward': 9.560747457444677, 'stats_actions': {1: 31, 2: 11, 3: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 721\n",
      "{'distance_to_goal': 0.10675454139709473, 'success': 1.0, 'spl': 0.6046885536427714, 'reward': 12.060899534225479, 'stats_actions': {2: 19, 1: 75, 3: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 722\n",
      "{'distance_to_goal': 0.09097593277692795, 'success': 1.0, 'spl': 0.7978377404204373, 'reward': 4.52090484648943, 'stats_actions': {3: 10, 2: 2, 1: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 723\n",
      "{'distance_to_goal': 0.0746312290430069, 'success': 1.0, 'spl': 0.3557398598664269, 'reward': 11.9677729457617, 'stats_actions': {3: 177, 2: 62, 1: 185, 0: 1}}\n",
      "\n",
      "Episodes finished: 724\n",
      "{'distance_to_goal': 0.12307696044445038, 'success': 1.0, 'spl': 0.9329103678522254, 'reward': 10.83928548157216, 'stats_actions': {3: 13, 1: 40, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 725\n",
      "{'distance_to_goal': 0.07362940162420273, 'success': 1.0, 'spl': 0.8217634396706549, 'reward': 11.575413109362138, 'stats_actions': {3: 19, 1: 49, 2: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 726\n",
      "{'distance_to_goal': 0.08615928143262863, 'success': 1.0, 'spl': 0.26731867037513973, 'reward': 5.499101338684558, 'stats_actions': {3: 107, 1: 95, 2: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 727\n",
      "{'distance_to_goal': 6.556050777435303, 'success': 0.0, 'spl': 0.0, 'reward': -4.353570938110288, 'stats_actions': {3: 130, 1: 299, 2: 71}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:38:02.431835 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:38:02.492729 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Sisters.navmesh\n",
      "I1122 12:38:02.431862 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:38:02.431867 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:38:02.431870 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:38:02.432020 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:38:02.433919 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:38:02.433928 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:38:02.434906 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Sisters.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:38:02.474050 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Sisters.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Sisters.scene_instance.json\n",
      "I1122 12:38:02.474067 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Sisters.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:38:02.474073 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Sisters.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Sisters.stage_config.json\n",
      "I1122 12:38:02.474077 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Sisters.stage_config.json from original name : data/scene_datasets/gibson/Sisters.glb | This file  does not exist.\n",
      "I1122 12:38:02.474128 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Sisters.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:38:02.474154 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Sisters.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:38:02.474159 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:38:02.474166 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Sisters.navmesh\n",
      "I1122 12:38:02.474171 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Sisters.navmesh\n",
      "I1122 12:38:02.474253 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:38:02.474260 316358080 SceneGraph.h:85] CreatI1122 12:38:02.493630 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 728\n",
      "{'distance_to_goal': 10.13860034942627, 'success': 0.0, 'spl': 0.0, 'reward': -4.416521072387646, 'stats_actions': {3: 112, 1: 282, 2: 106}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ed DrawableGroup: \n",
      "I1122 12:38:02.474265 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Sisters.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Sisters.scn\n",
      "E1122 12:38:02.474270 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Sisters.scn does not exist.  Aborting load.\n",
      "W1122 12:38:02.474277 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Sisters.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:38:02.474326 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:38:02.474332 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Sisters.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:38:02.474347 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Sisters.glb with render asset : data/scene_datasets/gibson/Sisters.glb and collision asset : data/scene_datasets/gibson/Sisters.glb\n",
      "I1122 12:38:02.474357 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:38:02.474360 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Sisters.glb.\n",
      "I1122 12:38:02.474364 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Sisters.glb \n",
      "I1122 12:38:02.474373 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Sisters.glb\n",
      "I1122 12:38:02.492045 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Sisters.glb\n",
      "W1122 12:38:02.492063 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:38:02.492074 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Sisters.glb yields 1 candidates.  Using data/scene_datasets/gibson/Sisters.glb.\n",
      "I1122 12:38:02.492089 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Sisters.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:38:02.492092 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:38:02.492105 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Sisters.glb yields 1 candidates.  Using data/scene_datasets/gibson/Sisters.glb.\n",
      "I1122 12:38:02.492112 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Sisters.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:38:02.492116 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:38:02.492128 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Sisters.glb with renderer.\n",
      "I1122 12:38:02.498545 316358080 PathFinder.cpp:382] Building navmesh with 203x169 cells\n",
      "I1122 12:38:02.557044 316358080 PathFinder.cpp:652] Created navmesh with 76 vertices 35 polygons\n",
      "I1122 12:38:02.557114 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 729\n",
      "{'distance_to_goal': 0.10835620015859604, 'success': 1.0, 'spl': 0.915795711777145, 'reward': 8.254735268652444, 'stats_actions': {3: 14, 1: 28, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 730\n",
      "{'distance_to_goal': 0.028222713619470596, 'success': 1.0, 'spl': 0.9633589949699112, 'reward': 9.239918536990888, 'stats_actions': {2: 13, 1: 31, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 731\n",
      "{'distance_to_goal': 0.08005833625793457, 'success': 1.0, 'spl': 0.974739884588552, 'reward': 6.101210308074954, 'stats_actions': {1: 16, 2: 8, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 732\n",
      "{'distance_to_goal': 0.0649225115776062, 'success': 1.0, 'spl': 0.8605789199361749, 'reward': 5.566470158100131, 'stats_actions': {2: 5, 1: 16, 3: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 733\n",
      "{'distance_to_goal': 0.09256915748119354, 'success': 1.0, 'spl': 0.9379064688457618, 'reward': 4.746673310399058, 'stats_actions': {2: 5, 1: 11, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 734\n",
      "{'distance_to_goal': 0.08736137300729752, 'success': 1.0, 'spl': 0.9619462074868447, 'reward': 6.641842499673369, 'stats_actions': {3: 4, 2: 8, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 735\n",
      "{'distance_to_goal': 0.05501313880085945, 'success': 1.0, 'spl': 0.9584297398328555, 'reward': 5.296963961571456, 'stats_actions': {3: 6, 1: 13, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 736\n",
      "{'distance_to_goal': 0.03317943587899208, 'success': 1.0, 'spl': 0.9464499459514831, 'reward': 10.079114684909591, 'stats_actions': {3: 12, 1: 35, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 737\n",
      "{'distance_to_goal': 0.1352173537015915, 'success': 1.0, 'spl': 0.9766980030219405, 'reward': 7.033979843258862, 'stats_actions': {2: 9, 1: 21, 3: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 738\n",
      "{'distance_to_goal': 0.13231852650642395, 'success': 1.0, 'spl': 0.44010916020868585, 'reward': 3.9880016219615917, 'stats_actions': {3: 116, 1: 110, 2: 41, 0: 1}}\n",
      "\n",
      "Episodes finished: 739\n",
      "{'distance_to_goal': 0.08540760725736618, 'success': 1.0, 'spl': 0.9009113052459379, 'reward': 4.436854737102985, 'stats_actions': {3: 7, 1: 10, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 740\n",
      "{'distance_to_goal': 0.14418472349643707, 'success': 1.0, 'spl': 0.9741646698671387, 'reward': 5.649587649703027, 'stats_actions': {2: 5, 3: 13, 1: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 741\n",
      "{'distance_to_goal': 0.13722571730613708, 'success': 1.0, 'spl': 0.9788635904683475, 'reward': 9.376599470376973, 'stats_actions': {3: 12, 1: 31, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 742\n",
      "{'distance_to_goal': 0.06495728343725204, 'success': 1.0, 'spl': 0.9549193200335137, 'reward': 7.313914748728279, 'stats_actions': {2: 2, 3: 13, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 743\n",
      "{'distance_to_goal': 0.11809572577476501, 'success': 1.0, 'spl': 0.9440597717788713, 'reward': 5.8881431925296805, 'stats_actions': {2: 7, 1: 16, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 744\n",
      "{'distance_to_goal': 0.16022972762584686, 'success': 1.0, 'spl': 0.9482810031546342, 'reward': 6.682517121434216, 'stats_actions': {2: 12, 1: 21, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 745\n",
      "{'distance_to_goal': 0.03316584229469299, 'success': 1.0, 'spl': 0.9933745125680086, 'reward': 4.967283586263657, 'stats_actions': {3: 6, 1: 11, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 746\n",
      "{'distance_to_goal': 0.06134964898228645, 'success': 1.0, 'spl': 0.9277099779019569, 'reward': 6.0514165405929115, 'stats_actions': {3: 11, 1: 17, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 747\n",
      "{'distance_to_goal': 0.06318600475788116, 'success': 1.0, 'spl': 0.9553022698634824, 'reward': 6.628501502871517, 'stats_actions': {3: 11, 1: 19, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 748\n",
      "{'distance_to_goal': 0.07556774467229843, 'success': 1.0, 'spl': 0.930346468333466, 'reward': 6.528212448656562, 'stats_actions': {3: 11, 2: 2, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 749\n",
      "{'distance_to_goal': 0.09754631668329239, 'success': 1.0, 'spl': 0.9049609407012762, 'reward': 9.911128877103334, 'stats_actions': {2: 2, 3: 26, 1: 36, 0: 1}}\n",
      "\n",
      "Episodes finished: 750\n",
      "{'distance_to_goal': 0.06680681556463242, 'success': 1.0, 'spl': 0.926479392743714, 'reward': 7.379477821886544, 'stats_actions': {2: 7, 1: 23, 3: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 751\n",
      "{'distance_to_goal': 0.04043007269501686, 'success': 1.0, 'spl': 0.9122334069776282, 'reward': 8.728830982297664, 'stats_actions': {3: 24, 2: 2, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 752\n",
      "{'distance_to_goal': 0.12994609773159027, 'success': 1.0, 'spl': 0.9752433218112351, 'reward': 8.061666355729109, 'stats_actions': {2: 10, 3: 15, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 753\n",
      "{'distance_to_goal': 0.0465727336704731, 'success': 1.0, 'spl': 0.8996247407854214, 'reward': 7.310048817843202, 'stats_actions': {3: 10, 2: 10, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 754\n",
      "{'distance_to_goal': 0.14999012649059296, 'success': 1.0, 'spl': 0.9870360901679247, 'reward': 10.43746554672719, 'stats_actions': {3: 11, 1: 35, 2: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 755\n",
      "{'distance_to_goal': 0.13352803885936737, 'success': 1.0, 'spl': 0.9145580413382159, 'reward': 4.826817906498911, 'stats_actions': {3: 14, 2: 2, 1: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 756\n",
      "{'distance_to_goal': 0.021168023347854614, 'success': 1.0, 'spl': 0.7105483010643896, 'reward': 7.009116533994694, 'stats_actions': {3: 30, 1: 55, 2: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 757\n",
      "{'distance_to_goal': 0.09899702668190002, 'success': 1.0, 'spl': 0.9751323421742235, 'reward': 5.917008451223375, 'stats_actions': {3: 8, 1: 16, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 758\n",
      "{'distance_to_goal': 0.1168237254023552, 'success': 1.0, 'spl': 0.8848863663103075, 'reward': 5.263438220322134, 'stats_actions': {2: 11, 3: 18, 1: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 759\n",
      "{'distance_to_goal': 0.03518274053931236, 'success': 1.0, 'spl': 0.8477261488499526, 'reward': 8.255639116913091, 'stats_actions': {1: 36, 2: 15, 3: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 760\n",
      "{'distance_to_goal': 0.1381450742483139, 'success': 1.0, 'spl': 0.895002356905182, 'reward': 7.839370298981671, 'stats_actions': {3: 4, 1: 26, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 761\n",
      "{'distance_to_goal': 0.09783004224300385, 'success': 1.0, 'spl': 0.9461729075311472, 'reward': 7.272498651146893, 'stats_actions': {2: 12, 3: 10, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 762\n",
      "{'distance_to_goal': 0.1118989810347557, 'success': 1.0, 'spl': 0.9662054010228665, 'reward': 7.562200540602212, 'stats_actions': {3: 10, 1: 24, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 763\n",
      "{'distance_to_goal': 0.039691321551799774, 'success': 1.0, 'spl': 0.9154149295985534, 'reward': 4.980515148937703, 'stats_actions': {3: 10, 1: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 764\n",
      "{'distance_to_goal': 0.0640530064702034, 'success': 1.0, 'spl': 0.9548773534778724, 'reward': 4.075701985061169, 'stats_actions': {2: 2, 3: 16, 1: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 765\n",
      "{'distance_to_goal': 0.05181390419602394, 'success': 1.0, 'spl': 0.9111073661399108, 'reward': 7.797584117501978, 'stats_actions': {3: 10, 1: 25, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 766\n",
      "{'distance_to_goal': 0.06745854020118713, 'success': 1.0, 'spl': 0.8455743783540425, 'reward': 7.942733339071278, 'stats_actions': {2: 9, 3: 15, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 767\n",
      "{'distance_to_goal': 0.07741505652666092, 'success': 1.0, 'spl': 0.9610651808774693, 'reward': 4.875515451133252, 'stats_actions': {2: 5, 1: 11, 3: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 768\n",
      "{'distance_to_goal': 0.04183076322078705, 'success': 1.0, 'spl': 0.9253937025987138, 'reward': 5.8297445160150545, 'stats_actions': {2: 3, 3: 13, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 769\n",
      "{'distance_to_goal': 0.08175818622112274, 'success': 1.0, 'spl': 0.9502200413294363, 'reward': 3.713572810292244, 'stats_actions': {3: 4, 1: 6, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 770\n",
      "{'distance_to_goal': 0.09432706981897354, 'success': 1.0, 'spl': 0.8632882545086191, 'reward': 7.113888033330444, 'stats_actions': {3: 30, 1: 26, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 771\n",
      "{'distance_to_goal': 0.12079692631959915, 'success': 1.0, 'spl': 0.91566491223912, 'reward': 6.32384046763182, 'stats_actions': {2: 6, 3: 13, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 772\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {2: 1}}\n",
      "\n",
      "Episodes finished: 773\n",
      "{'distance_to_goal': 0.16300326585769653, 'success': 1.0, 'spl': 0.918044239586253, 'reward': 7.218883769512181, 'stats_actions': {3: 14, 2: 4, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 774\n",
      "{'distance_to_goal': 0.02437797747552395, 'success': 1.0, 'spl': 0.8824666280891118, 'reward': 7.313163450136785, 'stats_actions': {3: 11, 1: 24, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 775\n",
      "{'distance_to_goal': 0.19232478737831116, 'success': 1.0, 'spl': 0.9374325516620124, 'reward': 5.851960109472279, 'stats_actions': {2: 12, 3: 12, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 776\n",
      "{'distance_to_goal': 0.08590269088745117, 'success': 0.0, 'spl': 0.0, 'reward': -2.2726867198943967, 'stats_actions': {3: 121, 2: 115, 1: 264}}\n",
      "\n",
      "Episodes finished: 777\n",
      "{'distance_to_goal': 0.060805220156908035, 'success': 1.0, 'spl': 0.9646874480298676, 'reward': 10.205846581906089, 'stats_actions': {3: 11, 1: 36, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 778\n",
      "{'distance_to_goal': 0.10966779291629791, 'success': 1.0, 'spl': 0.9278083963510981, 'reward': 5.10999172627926, 'stats_actions': {3: 12, 1: 13, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 779\n",
      "{'distance_to_goal': 0.16092373430728912, 'success': 1.0, 'spl': 0.9801090843067518, 'reward': 6.108460363745692, 'stats_actions': {3: 6, 1: 17, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 780\n",
      "{'distance_to_goal': 0.05038847401738167, 'success': 1.0, 'spl': 0.875123278792264, 'reward': 3.3935156635940076, 'stats_actions': {3: 8, 1: 5, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 781\n",
      "{'distance_to_goal': 0.022405607625842094, 'success': 1.0, 'spl': 0.9054449632703584, 'reward': 7.607914941385392, 'stats_actions': {3: 14, 1: 25, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 782\n",
      "{'distance_to_goal': 0.06917526572942734, 'success': 1.0, 'spl': 0.9542622887685216, 'reward': 10.707926098406324, 'stats_actions': {2: 9, 3: 15, 1: 41, 0: 1}}\n",
      "\n",
      "Episodes finished: 783\n",
      "{'distance_to_goal': 0.04544258117675781, 'success': 1.0, 'spl': 0.9265930423601205, 'reward': 6.082578125000002, 'stats_actions': {3: 10, 1: 17, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 784\n",
      "{'distance_to_goal': 0.10072074830532074, 'success': 1.0, 'spl': 0.9708219814498912, 'reward': 5.567155752778055, 'stats_actions': {3: 5, 1: 14, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 785\n",
      "{'distance_to_goal': 0.06833424419164658, 'success': 1.0, 'spl': 0.8417685675136957, 'reward': 6.153902732431892, 'stats_actions': {2: 3, 3: 16, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 786\n",
      "{'distance_to_goal': 0.08440128713846207, 'success': 1.0, 'spl': 0.8795853702396802, 'reward': 7.820420089662079, 'stats_actions': {3: 22, 2: 2, 1: 27, 0: 1}}\n",
      "\n",
      "Episodes finished: 787\n",
      "{'distance_to_goal': 0.11071430891752243, 'success': 1.0, 'spl': 0.963785992527431, 'reward': 6.89000518113375, 'stats_actions': {3: 9, 1: 20, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 788\n",
      "{'distance_to_goal': 0.056434787809848785, 'success': 1.0, 'spl': 0.9657183132853149, 'reward': 3.8783189734816554, 'stats_actions': {3: 4, 1: 7, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 789\n",
      "{'distance_to_goal': 0.07921203970909119, 'success': 1.0, 'spl': 0.9596143497908657, 'reward': 7.791646915674213, 'stats_actions': {3: 12, 1: 25, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 790\n",
      "{'distance_to_goal': 0.07258981466293335, 'success': 1.0, 'spl': 0.9578246105889257, 'reward': 5.146108267307282, 'stats_actions': {3: 4, 1: 12, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 791\n",
      "{'distance_to_goal': 0.035207852721214294, 'success': 1.0, 'spl': 0.8735198293413434, 'reward': 5.222111549973489, 'stats_actions': {3: 13, 1: 14, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 792\n",
      "{'distance_to_goal': 0.08653299510478973, 'success': 1.0, 'spl': 0.9238383242259574, 'reward': 7.0075003606081046, 'stats_actions': {2: 7, 1: 21, 3: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 793\n",
      "{'distance_to_goal': 0.07498909533023834, 'success': 1.0, 'spl': 0.954702998196521, 'reward': 7.718008798956877, 'stats_actions': {2: 9, 3: 8, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 794\n",
      "{'distance_to_goal': 0.14077626168727875, 'success': 1.0, 'spl': 0.9607420854281914, 'reward': 5.126904049515725, 'stats_actions': {2: 4, 3: 17, 1: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 795\n",
      "{'distance_to_goal': 0.10158725827932358, 'success': 1.0, 'spl': 0.6530167764586019, 'reward': 7.021260680258281, 'stats_actions': {3: 24, 1: 31, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 796\n",
      "{'distance_to_goal': 0.1319495439529419, 'success': 1.0, 'spl': 0.9935465840661915, 'reward': 7.161146674156193, 'stats_actions': {2: 9, 1: 21, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 797\n",
      "{'distance_to_goal': 0.10861844569444656, 'success': 1.0, 'spl': 0.9828740067449361, 'reward': 5.792355789840223, 'stats_actions': {3: 11, 1: 15, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 798\n",
      "{'distance_to_goal': 0.09346830099821091, 'success': 1.0, 'spl': 0.8633558504193674, 'reward': 7.587667391598232, 'stats_actions': {3: 16, 1: 26, 2: 3, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:39:35.848887 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:39:35.848913 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:39:35.848917 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:39:35.848920 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:39:35.910140 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Swormville.navmesh\n",
      "I1122 12:39:35.849066 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:39:35.850064 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:39:35.850070 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:39:35.851887 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Swormville.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:39:35.887678 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Swormville.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Swormville.scene_instance.json\n",
      "I1122 12:39:35.887696 316358080 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Swormville.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:39:35.887701 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Swormville.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Swormville.stage_config.json\n",
      "I1122 12:39:35.887706 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Swormville.stage_config.json from original name : data/scene_datasets/gibson/Swormville.glb | This file  does not exist.\n",
      "I1122 12:39:35.887755 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Swormville.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:39:35.887781 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Swormville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:39:35.887785 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:39:35.887792 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Swormville.navmesh\n",
      "I1122 12:39:35.887796 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Swormville.navmesh\n",
      "I1122 12:39:35.887928 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:39:35.887948 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:39:35.887979 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Swormville.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Swormville.scn\n",
      "E1122 12:39:35.887985 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Swormville.scn does not exist.  Aborting load.\n",
      "W1122 12:39:35.887992 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Swormville.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:39:35.888113 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:39:35.888140 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Swormville.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:39:35.888157 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Swormville.glb with render asset : data/scene_datasets/gibson/Swormville.glb and collision asset : data/scene_datasets/gibson/Swormville.glb\n",
      "I1122 12:39:35.888167 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:39:35.888185 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Swormville.glb.\n",
      "I1122 12:39:35.888188 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Swormville.glb \n",
      "I1122 12:39:35.888221 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Swormville.glb\n",
      "I1122 12:39:35.909343 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Swormville.glb\n",
      "W1122 12:39:35.909361 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:39:35.909373 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Swormville.glb yields 1 candidates.  Using data/scene_datasets/gibson/Swormville.glb.\n",
      "I1122 12:39:35.909387 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Swormville.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:39:35.909392 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:39:35.909404 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Swormville.glb yields 1 candidates.  Using data/scene_datasets/gibson/Swormville.glb.\n",
      "I1122 12:39:35.909412 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Swormville.glb' specified inI1122 12:39:35.911648 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n",
      " Scene Attributes exists in dataset library.\n",
      "I1122 12:39:35.909416 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:39:35.909430 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Swormville.glb with renderer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 799\n",
      "{'distance_to_goal': 0.09051117300987244, 'success': 1.0, 'spl': 0.9389629962680708, 'reward': 9.166452537775045, 'stats_actions': {3: 16, 2: 4, 1: 31, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:39:35.916656 316358080 PathFinder.cpp:382] Building navmesh with 142x210 cells\n",
      "I1122 12:39:35.977921 316358080 PathFinder.cpp:652] Created navmesh with 143 vertices 73 polygons\n",
      "I1122 12:39:35.977944 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 800\n",
      "{'distance_to_goal': 0.08042006939649582, 'success': 1.0, 'spl': 0.9205731916267066, 'reward': 10.575751271545897, 'stats_actions': {2: 13, 3: 20, 1: 39, 0: 1}}\n",
      "\n",
      "Episodes finished: 801\n",
      "{'distance_to_goal': 0.14506284892559052, 'success': 1.0, 'spl': 0.8432268525388988, 'reward': 6.774840582013134, 'stats_actions': {2: 3, 3: 29, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 802\n",
      "{'distance_to_goal': 0.17824648320674896, 'success': 1.0, 'spl': 0.9061675537453542, 'reward': 4.533714519143104, 'stats_actions': {2: 3, 3: 13, 1: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 803\n",
      "{'distance_to_goal': 0.06617428362369537, 'success': 1.0, 'spl': 0.9846840049358427, 'reward': 6.9028403991460845, 'stats_actions': {3: 13, 2: 12, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 804\n",
      "{'distance_to_goal': 0.0768749862909317, 'success': 1.0, 'spl': 0.954197697378804, 'reward': 8.75481059491635, 'stats_actions': {2: 11, 1: 29, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 805\n",
      "{'distance_to_goal': 0.12768584489822388, 'success': 1.0, 'spl': 0.9317053458174689, 'reward': 5.922150657176974, 'stats_actions': {3: 16, 1: 17, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 806\n",
      "{'distance_to_goal': 0.05832108482718468, 'success': 1.0, 'spl': 0.9637090750189242, 'reward': 11.30199938789011, 'stats_actions': {1: 40, 3: 9, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 807\n",
      "{'distance_to_goal': 0.11526882648468018, 'success': 1.0, 'spl': 1.0, 'reward': 5.200189032554627, 'stats_actions': {1: 12, 2: 5, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 808\n",
      "{'distance_to_goal': 0.05577101558446884, 'success': 1.0, 'spl': 0.9358826679932472, 'reward': 10.065156489908702, 'stats_actions': {3: 16, 1: 35, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 809\n",
      "{'distance_to_goal': 0.08973109722137451, 'success': 1.0, 'spl': 0.9583898718910159, 'reward': 8.931463665962225, 'stats_actions': {3: 7, 1: 29, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 810\n",
      "{'distance_to_goal': 0.05628007650375366, 'success': 1.0, 'spl': 0.739116192769303, 'reward': 6.720731489658358, 'stats_actions': {3: 20, 1: 47, 2: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 811\n",
      "{'distance_to_goal': 0.028551099821925163, 'success': 1.0, 'spl': 0.7332114849562915, 'reward': 7.468584043458116, 'stats_actions': {3: 19, 1: 45, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 812\n",
      "{'distance_to_goal': 0.11224985867738724, 'success': 1.0, 'spl': 0.4726941879911899, 'reward': 9.678691227138053, 'stats_actions': {2: 28, 3: 82, 1: 80, 0: 1}}\n",
      "\n",
      "Episodes finished: 813\n",
      "{'distance_to_goal': 0.17972126603126526, 'success': 1.0, 'spl': 0.8856164974787676, 'reward': 6.721966470479971, 'stats_actions': {2: 7, 3: 32, 1: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 814\n",
      "{'distance_to_goal': 0.08430144190788269, 'success': 1.0, 'spl': 0.9659068086403115, 'reward': 8.239516078233724, 'stats_actions': {3: 14, 2: 6, 1: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 815\n",
      "{'distance_to_goal': 0.10371614992618561, 'success': 1.0, 'spl': 0.9629965031504351, 'reward': 5.640527920126917, 'stats_actions': {3: 10, 1: 15, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 816\n",
      "{'distance_to_goal': 0.079559825360775, 'success': 1.0, 'spl': 0.8472450939298232, 'reward': 7.164709507524972, 'stats_actions': {2: 10, 3: 18, 1: 25, 0: 1}}\n",
      "\n",
      "Episodes finished: 817\n",
      "{'distance_to_goal': 0.14474648237228394, 'success': 1.0, 'spl': 0.9629397865357664, 'reward': 11.013054268360147, 'stats_actions': {2: 12, 1: 40, 3: 14, 0: 1}}\n",
      "\n",
      "Episodes finished: 818\n",
      "{'distance_to_goal': 4.676690578460693, 'success': 0.0, 'spl': 0.0, 'reward': 0.23072195053106337, 'stats_actions': {2: 127, 3: 152, 1: 221}}\n",
      "\n",
      "Episodes finished: 819\n",
      "{'distance_to_goal': 0.09192715585231781, 'success': 1.0, 'spl': 0.9730497268026241, 'reward': 7.744298105835921, 'stats_actions': {2: 11, 3: 15, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 820\n",
      "{'distance_to_goal': 0.11504419147968292, 'success': 1.0, 'spl': 0.951451159898949, 'reward': 6.377677442431454, 'stats_actions': {2: 3, 3: 18, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 821\n",
      "{'distance_to_goal': 0.09917820990085602, 'success': 1.0, 'spl': 0.9029687308051355, 'reward': 8.189025983214384, 'stats_actions': {3: 43, 1: 29, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 822\n",
      "{'distance_to_goal': 0.10374543815851212, 'success': 1.0, 'spl': 0.9760630765406474, 'reward': 5.862522319257261, 'stats_actions': {2: 11, 1: 16, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 823\n",
      "{'distance_to_goal': 0.11972114443778992, 'success': 1.0, 'spl': 0.9253611816826302, 'reward': 5.137902804613115, 'stats_actions': {2: 4, 1: 13, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 824\n",
      "{'distance_to_goal': 0.12236687541007996, 'success': 1.0, 'spl': 0.9487539308304062, 'reward': 10.265560981035243, 'stats_actions': {3: 17, 1: 39, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 825\n",
      "{'distance_to_goal': 0.13135689496994019, 'success': 1.0, 'spl': 0.8369676359964056, 'reward': 7.74920205354691, 'stats_actions': {3: 20, 1: 29, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 826\n",
      "{'distance_to_goal': 0.04776604101061821, 'success': 1.0, 'spl': 0.9672038283723596, 'reward': 8.284981456547982, 'stats_actions': {3: 9, 1: 26, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 827\n",
      "{'distance_to_goal': 0.008628139272332191, 'success': 1.0, 'spl': 0.9626483521790785, 'reward': 9.191458435282117, 'stats_actions': {2: 6, 3: 15, 1: 30, 0: 1}}\n",
      "\n",
      "Episodes finished: 828\n",
      "{'distance_to_goal': 9.534052848815918, 'success': 0.0, 'spl': 0.0, 'reward': -4.949705123901306, 'stats_actions': {3: 101, 1: 302, 2: 97}}\n",
      "\n",
      "Episodes finished: 829\n",
      "{'distance_to_goal': 0.09961959719657898, 'success': 1.0, 'spl': 0.8917013561042132, 'reward': 6.259031449556354, 'stats_actions': {3: 13, 2: 4, 1: 19, 0: 1}}\n",
      "\n",
      "Episodes finished: 830\n",
      "{'distance_to_goal': 0.08646154403686523, 'success': 1.0, 'spl': 0.8757795567137532, 'reward': 7.6229002761840885, 'stats_actions': {3: 14, 1: 26, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 831\n",
      "{'distance_to_goal': 0.04809246212244034, 'success': 1.0, 'spl': 0.9166815918294358, 'reward': 7.191411894261841, 'stats_actions': {3: 22, 1: 23, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 832\n",
      "{'distance_to_goal': 0.008077254518866539, 'success': 1.0, 'spl': 0.9696373596857162, 'reward': 6.22931078411639, 'stats_actions': {3: 11, 1: 17, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 833\n",
      "{'distance_to_goal': 0.04215233772993088, 'success': 1.0, 'spl': 0.8687449576720395, 'reward': 8.174716463387018, 'stats_actions': {3: 26, 1: 29, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 834\n",
      "{'distance_to_goal': 0.15512512624263763, 'success': 1.0, 'spl': 0.6100066056467596, 'reward': 6.02174216806889, 'stats_actions': {2: 13, 3: 27, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 835\n",
      "{'distance_to_goal': 0.0449487678706646, 'success': 1.0, 'spl': 0.5528381140363682, 'reward': 7.729141083508736, 'stats_actions': {2: 13, 3: 37, 1: 45, 0: 1}}\n",
      "\n",
      "Episodes finished: 836\n",
      "{'distance_to_goal': 0.12357247620820999, 'success': 1.0, 'spl': 0.9517908093888956, 'reward': 7.536165034472947, 'stats_actions': {3: 29, 1: 24, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 837\n",
      "{'distance_to_goal': 0.13892695307731628, 'success': 1.0, 'spl': 0.9131731390917327, 'reward': 7.302490531206137, 'stats_actions': {2: 10, 3: 12, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 838\n",
      "{'distance_to_goal': 0.10548415780067444, 'success': 1.0, 'spl': 0.9660103993051101, 'reward': 5.950001415014269, 'stats_actions': {3: 10, 1: 20, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 839\n",
      "{'distance_to_goal': 0.07490688562393188, 'success': 1.0, 'spl': 0.8860512425384238, 'reward': 4.8821084570884725, 'stats_actions': {3: 13, 1: 16, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 840\n",
      "{'distance_to_goal': 0.010956319980323315, 'success': 1.0, 'spl': 0.6391813639630717, 'reward': 7.088671785183253, 'stats_actions': {3: 20, 1: 33, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 841\n",
      "{'distance_to_goal': 7.561672687530518, 'success': 0.0, 'spl': 0.0, 'reward': -4.583278179168647, 'stats_actions': {3: 229, 1: 167, 2: 104}}\n",
      "\n",
      "Episodes finished: 842\n",
      "{'distance_to_goal': 0.0717729926109314, 'success': 1.0, 'spl': 0.9305581398665759, 'reward': 5.430963089466096, 'stats_actions': {3: 7, 1: 14, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 843\n",
      "{'distance_to_goal': 0.09986837953329086, 'success': 1.0, 'spl': 1.0, 'reward': 6.411976427137854, 'stats_actions': {3: 7, 1: 18, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 844\n",
      "{'distance_to_goal': 0.10323301702737808, 'success': 1.0, 'spl': 0.9757456590651814, 'reward': 10.731587882936008, 'stats_actions': {2: 8, 3: 13, 1: 37, 0: 1}}\n",
      "\n",
      "Episodes finished: 845\n",
      "{'distance_to_goal': 0.113235242664814, 'success': 1.0, 'spl': 0.5660344106722139, 'reward': 3.965661260783672, 'stats_actions': {3: 63, 1: 65, 2: 23, 0: 1}}\n",
      "\n",
      "Episodes finished: 846\n",
      "{'distance_to_goal': 0.12835493683815002, 'success': 1.0, 'spl': 1.0, 'reward': 3.7912803256511687, 'stats_actions': {3: 9, 1: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 847\n",
      "{'distance_to_goal': 0.10844524204730988, 'success': 1.0, 'spl': 0.8576106588939919, 'reward': 8.634864999651917, 'stats_actions': {3: 54, 1: 39, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 848\n",
      "{'distance_to_goal': 0.15411481261253357, 'success': 1.0, 'spl': 0.9342338675331087, 'reward': 8.91784958481789, 'stats_actions': {3: 27, 1: 31, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 849\n",
      "{'distance_to_goal': 0.09240017086267471, 'success': 1.0, 'spl': 0.9803356877821627, 'reward': 8.31067075580359, 'stats_actions': {3: 12, 1: 27, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 850\n",
      "{'distance_to_goal': 0.05406803637742996, 'success': 1.0, 'spl': 0.9211228066561515, 'reward': 8.633156389892108, 'stats_actions': {3: 11, 1: 29, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 851\n",
      "{'distance_to_goal': 0.1111801415681839, 'success': 1.0, 'spl': 0.9352920273415003, 'reward': 11.824711238741886, 'stats_actions': {3: 24, 1: 44, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 852\n",
      "{'distance_to_goal': 0.10383925586938858, 'success': 1.0, 'spl': 1.0, 'reward': 4.176659010350704, 'stats_actions': {2: 5, 3: 11, 1: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 853\n",
      "{'distance_to_goal': 0.07195022702217102, 'success': 1.0, 'spl': 0.9268603312734593, 'reward': 7.44540092349053, 'stats_actions': {2: 9, 3: 16, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 854\n",
      "{'distance_to_goal': 0.09380790591239929, 'success': 1.0, 'spl': 0.8985350412952012, 'reward': 8.590357304811485, 'stats_actions': {2: 12, 1: 30, 3: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 855\n",
      "{'distance_to_goal': 0.09221088141202927, 'success': 1.0, 'spl': 0.928683992642602, 'reward': 4.943841345608236, 'stats_actions': {3: 7, 1: 12, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 856\n",
      "{'distance_to_goal': 0.05781691148877144, 'success': 1.0, 'spl': 0.7077197098849584, 'reward': 9.505325636118657, 'stats_actions': {3: 30, 1: 50, 2: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 857\n",
      "{'distance_to_goal': 0.1279888153076172, 'success': 1.0, 'spl': 0.525047117714586, 'reward': 6.2078971862793, 'stats_actions': {3: 30, 1: 35, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 858\n",
      "{'distance_to_goal': 0.11825793236494064, 'success': 1.0, 'spl': 0.9192464614603014, 'reward': 6.588110132515434, 'stats_actions': {2: 4, 3: 14, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 859\n",
      "{'distance_to_goal': 0.1175108551979065, 'success': 1.0, 'spl': 0.943549186699779, 'reward': 10.255415742397314, 'stats_actions': {2: 6, 3: 19, 1: 36, 0: 1}}\n",
      "\n",
      "Episodes finished: 860\n",
      "{'distance_to_goal': 0.05096236243844032, 'success': 1.0, 'spl': 0.9696065080187611, 'reward': 10.502967843860397, 'stats_actions': {3: 10, 1: 37, 2: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 861\n",
      "{'distance_to_goal': 0.08175583183765411, 'success': 1.0, 'spl': 0.9260305982375917, 'reward': 5.968407780528072, 'stats_actions': {2: 12, 1: 17, 3: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 862\n",
      "{'distance_to_goal': 0.051594264805316925, 'success': 1.0, 'spl': 0.937229910336619, 'reward': 10.057882930934436, 'stats_actions': {3: 19, 1: 35, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 863\n",
      "{'distance_to_goal': 0.0641062930226326, 'success': 1.0, 'spl': 0.9690746184610953, 'reward': 9.009340018928057, 'stats_actions': {3: 8, 1: 29, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 864\n",
      "{'distance_to_goal': 4.818277835845947, 'success': 0.0, 'spl': 0.0, 'reward': -4.875461578369081, 'stats_actions': {3: 93, 1: 318, 2: 89}}\n",
      "\n",
      "Episodes finished: 865\n",
      "{'distance_to_goal': 0.16213279962539673, 'success': 1.0, 'spl': 0.810482882506967, 'reward': 7.170784871578222, 'stats_actions': {3: 16, 1: 27, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 866\n",
      "{'distance_to_goal': 0.11549464613199234, 'success': 1.0, 'spl': 0.9819447928382292, 'reward': 6.626555887162688, 'stats_actions': {3: 10, 1: 19, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 867\n",
      "{'distance_to_goal': 0.04732901602983475, 'success': 1.0, 'spl': 0.987645322070954, 'reward': 7.116001653373245, 'stats_actions': {3: 8, 1: 21, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 868\n",
      "{'distance_to_goal': 0.13795220851898193, 'success': 1.0, 'spl': 0.7679770128677659, 'reward': 8.337891488075261, 'stats_actions': {3: 25, 2: 11, 1: 35, 0: 1}}\n",
      "\n",
      "Episodes finished: 869\n",
      "{'distance_to_goal': 0.0760345607995987, 'success': 1.0, 'spl': 0.8908493125600343, 'reward': 7.060354008078579, 'stats_actions': {3: 22, 1: 23, 2: 1, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:42:09.707597 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Edgemere.navmesh\n",
      "I1122 12:42:09.632303 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:42:09.632329 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:42:09.632334 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:42:09.632337 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:42:09.632477 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:42:09.634243 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:42:09.634251 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:42:09.634820 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Edgemere.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:42:09.674015 316358080 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Edgemere.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Edgemere.scene_instance.json\n",
      "I1122 12:42:09.674039 316358080 MetadI1122 12:42:09.708336 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 870\n",
      "{'distance_to_goal': 0.14893850684165955, 'success': 1.0, 'spl': 0.8936726741134208, 'reward': 8.164704147577295, 'stats_actions': {3: 21, 1: 29, 2: 8, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Edgemere.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1122 12:42:09.674046 316358080 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Edgemere.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Edgemere.stage_config.json\n",
      "I1122 12:42:09.674052 316358080 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Edgemere.stage_config.json from original name : data/scene_datasets/gibson/Edgemere.glb | This file  does not exist.\n",
      "I1122 12:42:09.676810 316358080 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Edgemere.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1122 12:42:09.676853 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Edgemere.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:42:09.676858 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:42:09.676867 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Edgemere.navmesh\n",
      "I1122 12:42:09.676873 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Edgemere.navmesh\n",
      "I1122 12:42:09.677237 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:42:09.677249 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:42:09.677258 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Edgemere.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Edgemere.scn\n",
      "E1122 12:42:09.677266 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Edgemere.scn does not exist.  Aborting load.\n",
      "W1122 12:42:09.677275 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Edgemere.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:42:09.677345 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:42:09.677352 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Edgemere.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:42:09.677373 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Edgemere.glb with render asset : data/scene_datasets/gibson/Edgemere.glb and collision asset : data/scene_datasets/gibson/Edgemere.glb\n",
      "I1122 12:42:09.677385 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:42:09.677389 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Edgemere.glb.\n",
      "I1122 12:42:09.677392 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Edgemere.glb \n",
      "I1122 12:42:09.677407 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Edgemere.glb\n",
      "I1122 12:42:09.706880 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Edgemere.glb\n",
      "W1122 12:42:09.706899 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:42:09.706912 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Edgemere.glb yields 1 candidates.  Using data/scene_datasets/gibson/Edgemere.glb.\n",
      "I1122 12:42:09.706928 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Edgemere.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:42:09.706931 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:42:09.706944 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Edgemere.glb yields 1 candidates.  Using data/scene_datasets/gibson/Edgemere.glb.\n",
      "I1122 12:42:09.706954 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Edgemere.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:42:09.706956 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:42:09.706969 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Edgemere.glb with renderer.\n",
      "I1122 12:42:09.716094 316358080 PathFinder.cpp:382] Building navmesh with 69x147 cells\n",
      "I1122 12:42:09.782516 316358080 PathFinder.cpp:652] Created navmesh with 26 vertices 10 polygons\n",
      "I1122 12:42:09.782536 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 871\n",
      "{'distance_to_goal': 0.09586884081363678, 'success': 1.0, 'spl': 1.0, 'reward': 4.6698179095983505, 'stats_actions': {3: 7, 1: 10, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 872\n",
      "{'distance_to_goal': 0.019077807664871216, 'success': 1.0, 'spl': 0.7837824531503309, 'reward': 6.009834364652636, 'stats_actions': {2: 3, 3: 15, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 873\n",
      "{'distance_to_goal': 0.04564328119158745, 'success': 1.0, 'spl': 0.8845598771076102, 'reward': 5.943629780560734, 'stats_actions': {2: 6, 3: 2, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 874\n",
      "{'distance_to_goal': 0.032208967953920364, 'success': 1.0, 'spl': 0.6040468624791209, 'reward': 3.9329531852900983, 'stats_actions': {3: 15, 1: 15, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 875\n",
      "{'distance_to_goal': 0.08666946738958359, 'success': 1.0, 'spl': 0.9800553851657443, 'reward': 4.368455149233341, 'stats_actions': {2: 3, 3: 12, 1: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 876\n",
      "{'distance_to_goal': 0.06938319653272629, 'success': 1.0, 'spl': 0.9015360358094495, 'reward': 6.18078388720751, 'stats_actions': {3: 5, 1: 18, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 877\n",
      "{'distance_to_goal': 0.05094725266098976, 'success': 1.0, 'spl': 0.6289451931809031, 'reward': 6.318584188073882, 'stats_actions': {3: 26, 1: 31, 2: 12, 0: 1}}\n",
      "\n",
      "Episodes finished: 878\n",
      "{'distance_to_goal': 0.09607081860303879, 'success': 1.0, 'spl': 0.7928419702253859, 'reward': 4.24545156031847, 'stats_actions': {3: 20, 1: 11, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 879\n",
      "{'distance_to_goal': 0.054689425975084305, 'success': 1.0, 'spl': 0.7313915268707193, 'reward': 5.173724508732558, 'stats_actions': {2: 5, 3: 15, 1: 17, 0: 1}}\n",
      "\n",
      "Episodes finished: 880\n",
      "{'distance_to_goal': 0.1552983820438385, 'success': 1.0, 'spl': 0.9465718013037078, 'reward': 7.047599471807485, 'stats_actions': {3: 10, 2: 10, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 881\n",
      "{'distance_to_goal': 0.08645542711019516, 'success': 1.0, 'spl': 0.7851366945154882, 'reward': 6.262306627333171, 'stats_actions': {3: 22, 1: 22, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 882\n",
      "{'distance_to_goal': 0.09603980928659439, 'success': 1.0, 'spl': 0.8757930570481607, 'reward': 4.177128792703152, 'stats_actions': {2: 7, 1: 9, 3: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 883\n",
      "{'distance_to_goal': 0.10684064030647278, 'success': 1.0, 'spl': 0.9311695236603222, 'reward': 5.093119057416917, 'stats_actions': {3: 11, 1: 13, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 884\n",
      "{'distance_to_goal': 0.030684944242239, 'success': 1.0, 'spl': 0.8569545072574279, 'reward': 6.621735004335645, 'stats_actions': {3: 11, 1: 21, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 885\n",
      "{'distance_to_goal': 0.0970539003610611, 'success': 1.0, 'spl': 0.9433940364134448, 'reward': 4.394234618544578, 'stats_actions': {3: 5, 1: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 886\n",
      "{'distance_to_goal': 0.04646092653274536, 'success': 1.0, 'spl': 0.940164740873771, 'reward': 4.841616351604462, 'stats_actions': {3: 5, 1: 12, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 887\n",
      "{'distance_to_goal': 0.10711569339036942, 'success': 1.0, 'spl': 0.899396767702565, 'reward': 3.4071304270625116, 'stats_actions': {2: 4, 1: 5, 3: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 888\n",
      "{'distance_to_goal': 0.11990784108638763, 'success': 1.0, 'spl': 0.9685045618710183, 'reward': 4.651353707909584, 'stats_actions': {2: 2, 1: 10, 3: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 889\n",
      "{'distance_to_goal': 0.15677490830421448, 'success': 1.0, 'spl': 0.8759736524985345, 'reward': 7.89978047728539, 'stats_actions': {3: 8, 1: 27, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 890\n",
      "{'distance_to_goal': 0.10810554027557373, 'success': 1.0, 'spl': 0.9981223751969608, 'reward': 5.584058613777163, 'stats_actions': {3: 6, 1: 14, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 891\n",
      "{'distance_to_goal': 0.080535389482975, 'success': 1.0, 'spl': 0.8642767181662678, 'reward': 6.742140124738221, 'stats_actions': {2: 4, 3: 18, 1: 22, 0: 1}}\n",
      "\n",
      "Episodes finished: 892\n",
      "{'distance_to_goal': 0.1714332103729248, 'success': 1.0, 'spl': 0.9639860580619595, 'reward': 6.369124841690066, 'stats_actions': {3: 7, 1: 18, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 893\n",
      "{'distance_to_goal': 0.029018459841609, 'success': 1.0, 'spl': 0.9642963354359283, 'reward': 4.972304992154241, 'stats_actions': {3: 9, 1: 12, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 894\n",
      "{'distance_to_goal': 0.07957945764064789, 'success': 1.0, 'spl': 0.8461208126370613, 'reward': 6.109494982361796, 'stats_actions': {3: 12, 1: 19, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 895\n",
      "{'distance_to_goal': 0.20400367677211761, 'success': 0.0, 'spl': 0.0, 'reward': 2.1456286245584493, 'stats_actions': {3: 9, 1: 11, 0: 1}}\n",
      "\n",
      "Episodes finished: 896\n",
      "{'distance_to_goal': 0.04511059820652008, 'success': 1.0, 'spl': 0.9298328919450836, 'reward': 6.657604169249538, 'stats_actions': {2: 5, 3: 15, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 897\n",
      "{'distance_to_goal': 0.017071710899472237, 'success': 1.0, 'spl': 0.96104054687233, 'reward': 5.032506459876896, 'stats_actions': {1: 12, 2: 9, 3: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 898\n",
      "{'distance_to_goal': 0.0580221563577652, 'success': 1.0, 'spl': 0.8427357283646008, 'reward': 7.833588504195219, 'stats_actions': {3: 10, 1: 28, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 899\n",
      "{'distance_to_goal': 0.022366009652614594, 'success': 1.0, 'spl': 0.967394710645449, 'reward': 4.153310860693455, 'stats_actions': {3: 8, 1: 8, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 900\n",
      "{'distance_to_goal': 0.05635424703359604, 'success': 1.0, 'spl': 0.9549431801795619, 'reward': 8.031457375586037, 'stats_actions': {3: 5, 1: 25, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 901\n",
      "{'distance_to_goal': 0.16332978010177612, 'success': 1.0, 'spl': 0.9278769314597017, 'reward': 6.625200226306919, 'stats_actions': {2: 10, 3: 5, 1: 20, 0: 1}}\n",
      "\n",
      "Episodes finished: 902\n",
      "{'distance_to_goal': 0.0493660569190979, 'success': 1.0, 'spl': 1.0, 'reward': 4.062845757007599, 'stats_actions': {2: 11, 3: 6, 1: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 903\n",
      "{'distance_to_goal': 0.03322681784629822, 'success': 1.0, 'spl': 0.9280666711753907, 'reward': 6.865957981348041, 'stats_actions': {2: 3, 3: 15, 1: 21, 0: 1}}\n",
      "\n",
      "Episodes finished: 904\n",
      "{'distance_to_goal': 0.02636297047138214, 'success': 1.0, 'spl': 0.8852079653148918, 'reward': 6.336418249011043, 'stats_actions': {2: 6, 1: 19, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 905\n",
      "{'distance_to_goal': 0.07086515426635742, 'success': 1.0, 'spl': 0.8689395309453067, 'reward': 6.2155722999572784, 'stats_actions': {2: 8, 3: 4, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 906\n",
      "{'distance_to_goal': 0.10639357566833496, 'success': 1.0, 'spl': 0.8681813654195066, 'reward': 6.910031881332403, 'stats_actions': {3: 13, 1: 23, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 907\n",
      "{'distance_to_goal': 0.06827287375926971, 'success': 1.0, 'spl': 0.854828175137488, 'reward': 6.005384591221811, 'stats_actions': {3: 11, 1: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 908\n",
      "{'distance_to_goal': 0.04194113612174988, 'success': 1.0, 'spl': 0.9138984535610373, 'reward': 5.724005423784258, 'stats_actions': {3: 11, 2: 4, 1: 16, 0: 1}}\n",
      "\n",
      "Episodes finished: 909\n",
      "{'distance_to_goal': 0.15334391593933105, 'success': 1.0, 'spl': 1.0, 'reward': 5.59159564971924, 'stats_actions': {3: 5, 1: 14, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 910\n",
      "{'distance_to_goal': 0.11113715916872025, 'success': 1.0, 'spl': 0.9227451181741517, 'reward': 3.436515676677227, 'stats_actions': {2: 5, 1: 5, 3: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 911\n",
      "{'distance_to_goal': 0.0880030170083046, 'success': 1.0, 'spl': 0.9723850888415779, 'reward': 4.704000109136105, 'stats_actions': {3: 11, 1: 11, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 912\n",
      "{'distance_to_goal': 0.015257662162184715, 'success': 1.0, 'spl': 0.8983778893404906, 'reward': 5.303122865334154, 'stats_actions': {3: 16, 1: 14, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 913\n",
      "{'distance_to_goal': 0.02155432663857937, 'success': 1.0, 'spl': 0.9683227513887684, 'reward': 3.820929685011506, 'stats_actions': {2: 2, 3: 2, 1: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 914\n",
      "{'distance_to_goal': 0.05438277870416641, 'success': 1.0, 'spl': 0.8452857105237033, 'reward': 5.3967600759863865, 'stats_actions': {3: 25, 1: 16, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 915\n",
      "{'distance_to_goal': 0.027914954349398613, 'success': 1.0, 'spl': 0.4848449794861183, 'reward': 6.12600170977415, 'stats_actions': {2: 18, 1: 43, 3: 31, 0: 1}}\n",
      "\n",
      "Episodes finished: 916\n",
      "{'distance_to_goal': 0.07508639991283417, 'success': 0.0, 'spl': 0.0, 'reward': -3.3586698025464763, 'stats_actions': {2: 136, 3: 131, 1: 233}}\n",
      "\n",
      "Episodes finished: 917\n",
      "{'distance_to_goal': 0.05622527003288269, 'success': 1.0, 'spl': 0.9697909330461698, 'reward': 4.685266600847244, 'stats_actions': {2: 5, 1: 10, 3: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 918\n",
      "{'distance_to_goal': 0.02083553932607174, 'success': 1.0, 'spl': 0.9557296793999157, 'reward': 5.856757768169047, 'stats_actions': {3: 3, 1: 15, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 919\n",
      "{'distance_to_goal': 0.10119286924600601, 'success': 1.0, 'spl': 0.9330328199243954, 'reward': 5.626686635911467, 'stats_actions': {3: 5, 1: 15, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 920\n",
      "{'distance_to_goal': 0.03801250457763672, 'success': 1.0, 'spl': 0.9042540295426609, 'reward': 5.969805879592897, 'stats_actions': {3: 12, 1: 17, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 921\n",
      "{'distance_to_goal': 0.1398419886827469, 'success': 1.0, 'spl': 0.8738868414606707, 'reward': 4.841154105067255, 'stats_actions': {3: 14, 1: 13, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 922\n",
      "{'distance_to_goal': 0.10419820994138718, 'success': 1.0, 'spl': 1.0, 'reward': 4.427161958515644, 'stats_actions': {3: 8, 1: 9, 2: 5, 0: 1}}\n",
      "\n",
      "Episodes finished: 923\n",
      "{'distance_to_goal': 0.15378211438655853, 'success': 1.0, 'spl': 0.9460578990108591, 'reward': 5.364139352440835, 'stats_actions': {3: 2, 1: 14, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 924\n",
      "{'distance_to_goal': 0.1864347755908966, 'success': 1.0, 'spl': 1.0, 'reward': 5.981100205183032, 'stats_actions': {3: 10, 1: 17, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 925\n",
      "{'distance_to_goal': 0.13321857154369354, 'success': 1.0, 'spl': 0.9990383479994818, 'reward': 5.390601561665536, 'stats_actions': {3: 10, 1: 14, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 926\n",
      "{'distance_to_goal': 0.1285390853881836, 'success': 1.0, 'spl': 0.873194400995511, 'reward': 6.078992996215823, 'stats_actions': {3: 7, 1: 18, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 927\n",
      "{'distance_to_goal': 0.05265634134411812, 'success': 1.0, 'spl': 0.961062873877857, 'reward': 5.349339565485717, 'stats_actions': {3: 6, 1: 13, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 928\n",
      "{'distance_to_goal': 0.06178896129131317, 'success': 1.0, 'spl': 0.8695067782074228, 'reward': 3.960406463742256, 'stats_actions': {1: 8, 3: 5, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 929\n",
      "{'distance_to_goal': 0.10523061454296112, 'success': 1.0, 'spl': 0.6413867939219895, 'reward': 5.936957610249524, 'stats_actions': {2: 14, 3: 25, 1: 29, 0: 1}}\n",
      "\n",
      "Episodes finished: 930\n",
      "{'distance_to_goal': 0.09298309683799744, 'success': 1.0, 'spl': 0.9535178868164773, 'reward': 5.973514229059221, 'stats_actions': {2: 5, 1: 16, 3: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 931\n",
      "{'distance_to_goal': 0.10144887119531631, 'success': 1.0, 'spl': 0.9305701875412576, 'reward': 6.098109119832518, 'stats_actions': {3: 6, 1: 17, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 932\n",
      "{'distance_to_goal': 0.08460299670696259, 'success': 1.0, 'spl': 0.8775431662955337, 'reward': 5.813134220242502, 'stats_actions': {3: 8, 1: 17, 2: 4, 0: 1}}\n",
      "\n",
      "Episodes finished: 933\n",
      "{'distance_to_goal': 0.0, 'success': 1.0, 'spl': 0.8816265968454173, 'reward': 4.843859357833863, 'stats_actions': {1: 13, 2: 13, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 934\n",
      "{'distance_to_goal': 0.011449476704001427, 'success': 1.0, 'spl': 0.3021074166578592, 'reward': 3.9194960532337424, 'stats_actions': {3: 49, 1: 35, 2: 26, 0: 1}}\n",
      "\n",
      "Episodes finished: 935\n",
      "{'distance_to_goal': 0.11921477317810059, 'success': 1.0, 'spl': 0.9454018512473354, 'reward': 4.774896907806397, 'stats_actions': {3: 7, 1: 11, 2: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 936\n",
      "{'distance_to_goal': 0.1263640820980072, 'success': 1.0, 'spl': 0.8700396573530907, 'reward': 4.300224491357803, 'stats_actions': {3: 9, 2: 1, 1: 10, 0: 1}}\n",
      "\n",
      "Episodes finished: 937\n",
      "{'distance_to_goal': 0.1281040906906128, 'success': 1.0, 'spl': 0.9056529187527725, 'reward': 5.828509831428531, 'stats_actions': {3: 9, 1: 17, 2: 8, 0: 1}}\n",
      "\n",
      "Episodes finished: 938\n",
      "{'distance_to_goal': 0.046078141778707504, 'success': 1.0, 'spl': 0.9021078870940431, 'reward': 5.507005745321514, 'stats_actions': {3: 7, 1: 15, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 939\n",
      "{'distance_to_goal': 0.09759789705276489, 'success': 1.0, 'spl': 0.8012556012371731, 'reward': 5.117110631465914, 'stats_actions': {3: 10, 1: 15, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 940\n",
      "{'distance_to_goal': 0.12315449118614197, 'success': 1.0, 'spl': 0.7935382039077036, 'reward': 5.170998359918596, 'stats_actions': {3: 19, 1: 16, 2: 2, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:43:25.827850 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:43:25.827877 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:43:25.827880 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:43:25.827883 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:43:25.828019 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:43:25.829612 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:43:25.829619 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:43:25.830219 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Eudora.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:43:25.867640 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eudora.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:43:25.867659 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eudora.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:43:25.867663 316358080 SceneDatasetAttributes.cpp:85] ::addI1122 12:43:25.893196 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Eudora.navmesh\n",
      "NewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:43:25.867672 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Eudora.navmesh\n",
      "I1122 12:43:25.867681 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Eudora.navmesh\n",
      "I1122 12:43:25.867769 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:43:25.867776 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:43:25.867781 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Eudora.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Eudora.scn\n",
      "E1122 12:43:25.867789 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Eudora.scn does not exist.  Aborting load.\n",
      "W1122 12:43:25.867795 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Eudora.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:43:25.867844 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:43:25.867851 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Eudora.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:43:25.867871 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Eudora.glb with render asset : data/scene_datasets/gibson/Eudora.glb and collision asset : data/scene_datasets/gibson/Eudora.glb\n",
      "I1122 12:43:25.867882 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:43:25.867885 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:43:25.867888 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Eudora.glb \n",
      "I1122 12:43:25.869357 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Eudora.glb\n",
      "I1122 12:43:25.891932 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Eudora.glb\n",
      "W1122 12:43:25.891950 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:43:25.891963 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eudora.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:43:25.891978 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/I1122 12:43:25.893905 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 941\n",
      "{'distance_to_goal': 0.1303955316543579, 'success': 1.0, 'spl': 0.8603953312381082, 'reward': 5.34718430042267, 'stats_actions': {3: 7, 1: 15, 2: 2, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scene_datasets/gibson/Eudora.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:43:25.891983 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:43:25.891995 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Eudora.glb yields 1 candidates.  Using data/scene_datasets/gibson/Eudora.glb.\n",
      "I1122 12:43:25.892004 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Eudora.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:43:25.892007 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:43:25.892020 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Eudora.glb with renderer.\n",
      "I1122 12:43:25.899878 316358080 PathFinder.cpp:382] Building navmesh with 142x112 cells\n",
      "I1122 12:43:25.951303 316358080 PathFinder.cpp:652] Created navmesh with 63 vertices 27 polygons\n",
      "I1122 12:43:25.951484 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 942\n",
      "{'distance_to_goal': 0.131639763712883, 'success': 1.0, 'spl': 0.17888520658356444, 'reward': 3.2963406974077785, 'stats_actions': {2: 51, 1: 154, 3: 190, 0: 1}}\n",
      "\n",
      "Episodes finished: 943\n",
      "{'distance_to_goal': 0.1394854485988617, 'success': 1.0, 'spl': 0.6638748106826978, 'reward': 6.527875543832782, 'stats_actions': {3: 37, 1: 33, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 944\n",
      "{'distance_to_goal': 3.1886682510375977, 'success': 0.0, 'spl': 0.0, 'reward': -5.696821451187068, 'stats_actions': {3: 271, 1: 188, 2: 41}}\n",
      "\n",
      "Episodes finished: 945\n",
      "{'distance_to_goal': 5.750218391418457, 'success': 0.0, 'spl': 0.0, 'reward': -3.6768569946288574, 'stats_actions': {3: 241, 1: 198, 2: 61}}\n",
      "\n",
      "Episodes finished: 946\n",
      "{'distance_to_goal': 0.05130588263273239, 'success': 1.0, 'spl': 0.9097212601437334, 'reward': 6.147207968533042, 'stats_actions': {3: 13, 1: 18, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 947\n",
      "{'distance_to_goal': 6.339783191680908, 'success': 0.0, 'spl': 0.0, 'reward': -4.099721431732144, 'stats_actions': {3: 254, 1: 192, 2: 54}}\n",
      "\n",
      "Episodes finished: 948\n",
      "{'distance_to_goal': 0.15852206945419312, 'success': 1.0, 'spl': 1.0, 'reward': 3.5695791983604432, 'stats_actions': {2: 4, 1: 5, 3: 1, 0: 1}}\n",
      "\n",
      "Episodes finished: 949\n",
      "{'distance_to_goal': 0.08483754843473434, 'success': 1.0, 'spl': 0.11838082396345327, 'reward': 2.9676286342740252, 'stats_actions': {3: 219, 1: 179, 2: 48, 0: 1}}\n",
      "\n",
      "Episodes finished: 950\n",
      "{'distance_to_goal': 0.09976916760206223, 'success': 1.0, 'spl': 0.7132519740568826, 'reward': 7.266192555725581, 'stats_actions': {3: 58, 1: 58, 2: 15, 0: 1}}\n",
      "\n",
      "Episodes finished: 951\n",
      "{'distance_to_goal': 5.6441755294799805, 'success': 0.0, 'spl': 0.0, 'reward': -3.81203842163083, 'stats_actions': {2: 44, 3: 250, 1: 206}}\n",
      "\n",
      "Episodes finished: 952\n",
      "{'distance_to_goal': 0.10261819511651993, 'success': 1.0, 'spl': 0.9987323604669165, 'reward': 5.124202550351621, 'stats_actions': {2: 4, 3: 4, 1: 12, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:45:03.273859 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Mosquito.navmesh\n",
      "I1122 12:45:03.201088 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:45:03.201115 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:45:03.201120 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:45:03.201123 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:45:03.201256 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:45:03.202131 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:45:03.202138 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:45:03.202708 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Mosquito.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:45:03.238462 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Mosquito.glb yields 1 candidates.  Using data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:45:03.238478 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Mosquito.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:45:03.238482 316358080 SceneDatasetAttributes.cpp:8I1122 12:45:03.274681 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 953\n",
      "{'distance_to_goal': 5.268004417419434, 'success': 0.0, 'spl': 0.0, 'reward': -3.414608955383261, 'stats_actions': {3: 252, 1: 209, 2: 39}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:45:03.238490 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Mosquito.navmesh\n",
      "I1122 12:45:03.238498 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Mosquito.navmesh\n",
      "I1122 12:45:03.238732 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:45:03.238739 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:45:03.238744 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Mosquito.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Mosquito.scn\n",
      "E1122 12:45:03.238750 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Mosquito.scn does not exist.  Aborting load.\n",
      "W1122 12:45:03.238757 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Mosquito.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:45:03.238799 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:45:03.238806 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Mosquito.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:45:03.238826 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Mosquito.glb with render asset : data/scene_datasets/gibson/Mosquito.glb and collision asset : data/scene_datasets/gibson/Mosquito.glb\n",
      "I1122 12:45:03.238834 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:45:03.238838 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:45:03.238840 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Mosquito.glb \n",
      "I1122 12:45:03.240854 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Mosquito.glb\n",
      "I1122 12:45:03.272953 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Mosquito.glb\n",
      "W1122 12:45:03.272971 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:45:03.272984 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Mosquito.glb yields 1 candidates.  Using data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:45:03.272998 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Mosquito.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:45:03.273002 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:45:03.273016 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Mosquito.glb yields 1 candidates.  Using data/scene_datasets/gibson/Mosquito.glb.\n",
      "I1122 12:45:03.273025 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Mosquito.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:45:03.273028 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:45:03.273041 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Mosquito.glb with renderer.\n",
      "I1122 12:45:03.278192 316358080 PathFinder.cpp:382] Building navmesh with 224x469 cells\n",
      "I1122 12:45:03.379976 316358080 PathFinder.cpp:652] Created navmesh with 588 vertices 287 polygons\n",
      "I1122 12:45:03.380007 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 954\n",
      "{'distance_to_goal': 5.301131725311279, 'success': 0.0, 'spl': 0.0, 'reward': 4.807531833648783, 'stats_actions': {3: 227, 1: 173, 2: 100}}\n",
      "\n",
      "Episodes finished: 955\n",
      "{'distance_to_goal': 0.10101558268070221, 'success': 1.0, 'spl': 0.5326319108497023, 'reward': 20.133405117392613, 'stats_actions': {3: 190, 1: 177, 2: 90, 0: 1}}\n",
      "\n",
      "Episodes finished: 956\n",
      "{'distance_to_goal': 4.270597457885742, 'success': 0.0, 'spl': 0.0, 'reward': 12.218683242797937, 'stats_actions': {3: 127, 1: 270, 2: 103}}\n",
      "\n",
      "Episodes finished: 957\n",
      "{'distance_to_goal': 14.959000587463379, 'success': 0.0, 'spl': 0.0, 'reward': 1.7527151107789047, 'stats_actions': {3: 235, 1: 200, 2: 65}}\n",
      "\n",
      "Episodes finished: 958\n",
      "{'distance_to_goal': 13.205747604370117, 'success': 0.0, 'spl': 0.0, 'reward': -2.5852413177489844, 'stats_actions': {3: 244, 1: 199, 2: 57}}\n",
      "\n",
      "Episodes finished: 959\n",
      "{'distance_to_goal': 1.6404095888137817, 'success': 0.0, 'spl': 0.0, 'reward': -4.854721307754459, 'stats_actions': {3: 134, 1: 234, 2: 132}}\n",
      "\n",
      "Episodes finished: 960\n",
      "{'distance_to_goal': 0.1333627551794052, 'success': 1.0, 'spl': 0.8835786338353414, 'reward': 7.188298469185836, 'stats_actions': {2: 4, 3: 22, 1: 24, 0: 1}}\n",
      "\n",
      "Episodes finished: 961\n",
      "{'distance_to_goal': 11.119765281677246, 'success': 0.0, 'spl': 0.0, 'reward': -2.418756484985316, 'stats_actions': {3: 254, 1: 172, 2: 74}}\n",
      "\n",
      "Episodes finished: 962\n",
      "{'distance_to_goal': 0.0967695489525795, 'success': 1.0, 'spl': 0.7984031604846357, 'reward': 10.169144376218327, 'stats_actions': {1: 44, 3: 25, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 963\n",
      "{'distance_to_goal': 0.20217259228229523, 'success': 0.0, 'spl': 0.0, 'reward': 8.099397918582017, 'stats_actions': {3: 180, 1: 178, 2: 56, 0: 1}}\n",
      "\n",
      "Episodes finished: 964\n",
      "{'distance_to_goal': 0.029958846047520638, 'success': 1.0, 'spl': 0.8369675031088423, 'reward': 8.233908608481297, 'stats_actions': {2: 11, 3: 22, 1: 33, 0: 1}}\n",
      "\n",
      "Episodes finished: 965\n",
      "{'distance_to_goal': 4.873688697814941, 'success': 0.0, 'spl': 0.0, 'reward': -6.013873338699268, 'stats_actions': {2: 105, 3: 200, 1: 195}}\n",
      "\n",
      "Episodes finished: 966\n",
      "{'distance_to_goal': 17.786409378051758, 'success': 0.0, 'spl': 0.0, 'reward': -6.385637283325102, 'stats_actions': {3: 310, 1: 144, 2: 46}}\n",
      "\n",
      "Episodes finished: 967\n",
      "{'distance_to_goal': 0.07755421847105026, 'success': 1.0, 'spl': 0.7729069724899703, 'reward': 7.8704411771893605, 'stats_actions': {3: 21, 1: 38, 2: 18, 0: 1}}\n",
      "\n",
      "Episodes finished: 968\n",
      "{'distance_to_goal': 5.742256164550781, 'success': 0.0, 'spl': 0.0, 'reward': 2.1300373077393555, 'stats_actions': {2: 126, 1: 236, 3: 138}}\n",
      "\n",
      "Episodes finished: 969\n",
      "{'distance_to_goal': 7.529639720916748, 'success': 0.0, 'spl': 0.0, 'reward': -3.612380504608103, 'stats_actions': {3: 170, 1: 237, 2: 93}}\n",
      "\n",
      "Episodes finished: 970\n",
      "{'distance_to_goal': 0.11966831237077713, 'success': 1.0, 'spl': 0.9468172920647809, 'reward': 11.210833663642417, 'stats_actions': {2: 14, 3: 47, 1: 44, 0: 1}}\n",
      "\n",
      "Episodes finished: 971\n",
      "{'distance_to_goal': 0.13509808480739594, 'success': 1.0, 'spl': 0.9074376031182547, 'reward': 12.648911276459703, 'stats_actions': {1: 48, 2: 5, 3: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 972\n",
      "{'distance_to_goal': 15.519657135009766, 'success': 0.0, 'spl': 0.0, 'reward': -6.505179405212369, 'stats_actions': {3: 271, 1: 147, 2: 82}}\n",
      "\n",
      "Episodes finished: 973\n",
      "{'distance_to_goal': 0.07257787138223648, 'success': 1.0, 'spl': 0.2717705227329008, 'reward': 2.879744535386566, 'stats_actions': {2: 79, 1: 115, 3: 88, 0: 1}}\n",
      "\n",
      "Episodes finished: 974\n",
      "{'distance_to_goal': 0.05968246981501579, 'success': 1.0, 'spl': 0.9495486315384826, 'reward': 6.889376482516529, 'stats_actions': {3: 4, 1: 20, 2: 6, 0: 1}}\n",
      "\n",
      "Episodes finished: 975\n",
      "{'distance_to_goal': 0.09849517792463303, 'success': 1.0, 'spl': 0.7508840729842228, 'reward': 12.428464546501653, 'stats_actions': {2: 17, 3: 39, 1: 61, 0: 1}}\n",
      "\n",
      "Episodes finished: 976\n",
      "{'distance_to_goal': 0.08146730810403824, 'success': 1.0, 'spl': 0.929684918298188, 'reward': 7.537804275453095, 'stats_actions': {3: 11, 1: 24, 2: 7, 0: 1}}\n",
      "\n",
      "Episodes finished: 977\n",
      "{'distance_to_goal': 9.45946979522705, 'success': 0.0, 'spl': 0.0, 'reward': -5.864709854125923, 'stats_actions': {3: 203, 1: 223, 2: 74}}\n",
      "\n",
      "Episodes finished: 978\n",
      "{'distance_to_goal': 13.152771949768066, 'success': 0.0, 'spl': 0.0, 'reward': -1.076653480529766, 'stats_actions': {3: 248, 1: 191, 2: 61}}\n",
      "\n",
      "Episodes finished: 979\n",
      "{'distance_to_goal': 0.10673891752958298, 'success': 1.0, 'spl': 0.9696218942477188, 'reward': 6.252978489696983, 'stats_actions': {3: 14, 1: 18, 2: 13, 0: 1}}\n",
      "\n",
      "Episodes finished: 980\n",
      "{'distance_to_goal': 0.07755419611930847, 'success': 1.0, 'spl': 0.9323682645746639, 'reward': 4.2100118172168735, 'stats_actions': {3: 6, 1: 9, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 981\n",
      "{'distance_to_goal': 0.0505334846675396, 'success': 1.0, 'spl': 0.9484583097497642, 'reward': 6.711324711591008, 'stats_actions': {3: 6, 1: 19, 2: 2, 0: 1}}\n",
      "\n",
      "Episodes finished: 982\n",
      "{'distance_to_goal': 0.06686598807573318, 'success': 1.0, 'spl': 0.9479496246307003, 'reward': 8.563427362144, 'stats_actions': {3: 14, 1: 28, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 983\n",
      "{'distance_to_goal': 0.005114065483212471, 'success': 1.0, 'spl': 0.9168316605690635, 'reward': 11.236147569343455, 'stats_actions': {3: 8, 1: 41, 2: 9, 0: 1}}\n",
      "\n",
      "Episodes finished: 984\n",
      "{'distance_to_goal': 0.10480242967605591, 'success': 1.0, 'spl': 0.22817018682703377, 'reward': 7.8728643488884185, 'stats_actions': {3: 123, 1: 185, 2: 49, 0: 1}}\n",
      "\n",
      "Episodes finished: 985\n",
      "{'distance_to_goal': 14.510589599609375, 'success': 0.0, 'spl': 0.0, 'reward': 0.5686302185059411, 'stats_actions': {3: 222, 1: 204, 2: 74}}\n",
      "\n",
      "Episodes finished: 986\n",
      "{'distance_to_goal': 14.910846710205078, 'success': 0.0, 'spl': 0.0, 'reward': 1.5071830749512438, 'stats_actions': {3: 223, 2: 91, 1: 186}}\n",
      "\n",
      "Episodes finished: 987\n",
      "{'distance_to_goal': 0.04555555433034897, 'success': 1.0, 'spl': 0.945239739306456, 'reward': 10.891245364248759, 'stats_actions': {3: 12, 1: 38, 2: 3, 0: 1}}\n",
      "\n",
      "Episodes finished: 988\n",
      "{'distance_to_goal': 11.951689720153809, 'success': 0.0, 'spl': 0.0, 'reward': -2.604502677917437, 'stats_actions': {3: 231, 1: 187, 2: 82}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:49:47.411017 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:49:47.485736 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Scioto.navmesh\n",
      "I1122 12:49:47.411043 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:49:47.411047 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:49:47.411051 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:49:47.411208 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:49:47.412979 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:49:47.412987 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:49:47.413789 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Scioto.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:49:47.448949 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Scioto.glb yields 1 candidates.  Using data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:49:47.448966 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Scioto.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:49:47.448971 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:49:47.448978 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Scioto.navmesh\n",
      "I1122 12:49:47.448987 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Scioto.navmesh\n",
      "I1122 12:49:47.449198 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:49:47.449206 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:49:47.449213 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Scioto.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Scioto.scn\n",
      "E1122 12:49:47.449218 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Scioto.scn does not exist.  Aborting load.\n",
      "W1122 12:49:47.449225 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Scioto.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:49:47.449272 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:49:47.449278 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Scioto.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:49:47.449299 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Scioto.glb with render asset : data/scene_datasets/gibson/Scioto.glb and collision asset : data/scene_datasets/gibson/Scioto.glb\n",
      "I1122 12:49:47.449311 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:49:47.449314 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:49:47.449316 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Scioto.glb \n",
      "I1122 12:49:47.449327 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Scioto.glb\n",
      "I1122 12:49:47.484709 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Scioto.glb\n",
      "W1122 12:49:47.484725 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:49:47.484736 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_I1122 12:49:47.486759 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 989\n",
      "{'distance_to_goal': 0.11321799457073212, 'success': 1.0, 'spl': 0.6954000284578369, 'reward': 8.249231823086744, 'stats_actions': {2: 3, 1: 37, 3: 16, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "datasets/gibson/Scioto.glb yields 1 candidates.  Using data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:49:47.484751 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Scioto.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:49:47.484755 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:49:47.484768 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Scioto.glb yields 1 candidates.  Using data/scene_datasets/gibson/Scioto.glb.\n",
      "I1122 12:49:47.484777 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Scioto.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:49:47.484781 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:49:47.484792 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Scioto.glb with renderer.\n",
      "I1122 12:49:47.494843 316358080 PathFinder.cpp:382] Building navmesh with 239x204 cells\n",
      "I1122 12:49:47.671339 316358080 PathFinder.cpp:652] Created navmesh with 433 vertices 218 polygons\n",
      "I1122 12:49:47.672143 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 990\n",
      "{'distance_to_goal': inf, 'success': 0.0, 'spl': nan, 'reward': nan, 'stats_actions': {3: 1}}\n",
      "\n",
      "Episodes finished: 991\n",
      "{'distance_to_goal': 7.437218189239502, 'success': 0.0, 'spl': 0.0, 'reward': -5.301171779632489, 'stats_actions': {3: 141, 1: 269, 2: 90}}\n",
      "\n",
      "Episodes finished: 992\n",
      "{'distance_to_goal': 0.052885495126247406, 'success': 1.0, 'spl': 0.454192264318901, 'reward': 7.345795229971412, 'stats_actions': {2: 12, 3: 88, 1: 70, 0: 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 12:50:08.751788 316358080 PhysicsManager.cpp:50] Deconstructing PhysicsManager\n",
      "I1122 12:50:08.826177 42045 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1122 12:50:08.751814 316358080 SemanticScene.h:43] Deconstructing SemanticScene\n",
      "I1122 12:50:08.751818 316358080 SceneManager.h:25] Deconstructing SceneManager\n",
      "I1122 12:50:08.751822 316358080 SceneGraph.h:25] Deconstructing SceneGraph\n",
      "I1122 12:50:08.751974 316358080 Sensor.cpp:69] Deconstructing Sensor\n",
      "I1122 12:50:08.754307 316358080 Renderer.cpp:71] Deconstructing Renderer\n",
      "I1122 12:50:08.754316 316358080 WindowlessContext.h:17] Deconstructing WindowlessContext\n",
      "I1122 12:50:08.755717 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Cantwell.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:50:08.790119 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantwell.glb yields 1 candidates.  Using data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:50:08.790138 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:50:08.790141 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:50:08.790149 316358080 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1122 12:50:08.790158 316358080 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1122 12:50:08.790275 316358080 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1122 12:50:08.790282 316358080 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1122 12:50:08.790287 316358080 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Cantwell.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Cantwell.scn\n",
      "E1122 12:50:08.790293 316358080 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Cantwell.scn does not exist.  Aborting load.\n",
      "W1122 12:50:08.790300 316358080 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Cantwell.scn : exist : 0 : loaded as expected type : 0\n",
      "I1122 12:50:08.790347 316358080 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1122 12:50:08.790354 316358080 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Cantwell.glb and dataset : default which is currently active dataset.\n",
      "I1122 12:50:08.790372 316358080 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Cantwell.glb with render assetI1122 12:50:08.827111 42045 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes finished: 993\n",
      "{'distance_to_goal': 0.08418509364128113, 'success': 1.0, 'spl': 0.8562458140139985, 'reward': 10.331370784044278, 'stats_actions': {3: 27, 1: 42, 2: 13, 0: 1}}\n",
      "\n",
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n",
      "Saving to: /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/stats/habitat_gibson_val_challenge_sim_depth_train_sliding_off_train_noise_multiplier_1.0.pickle\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " : data/scene_datasets/gibson/Cantwell.glb and collision asset : data/scene_datasets/gibson/Cantwell.glb\n",
      "I1122 12:50:08.790383 316358080 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1122 12:50:08.790386 316358080 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:50:08.790390 316358080 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Cantwell.glb \n",
      "I1122 12:50:08.792766 316358080 ResourceManager.cpp:1281] Importing Basis files as BC3 for Cantwell.glb\n",
      "I1122 12:50:08.825461 316358080 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Cantwell.glb\n",
      "W1122 12:50:08.825480 316358080 Simulator.cpp:427] \n",
      "---\n",
      "Simulator::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1122 12:50:08.825492 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantwell.glb yields 1 candidates.  Using data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:50:08.825508 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:50:08.825512 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:50:08.825526 316358080 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantwell.glb yields 1 candidates.  Using data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1122 12:50:08.825534 316358080 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:50:08.825538 316358080 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1122 12:50:08.825551 316358080 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Cantwell.glb with renderer.\n",
      "I1122 12:50:08.833089 316358080 PathFinder.cpp:382] Building navmesh with 306x145 cells\n",
      "I1122 12:50:08.919651 316358080 PathFinder.cpp:652] Created navmesh with 199 vertices 94 polygons\n",
      "I1122 12:50:08.919876 316358080 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/stats/habitat_gibson_val_challenge_sim_depth_train_sliding_off_train_noise_multiplier_1.0.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3n/1mkr33q53s53441zsn3079w00000gr/T/ipykernel_42045/154062424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving to: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/stats/habitat_gibson_val_challenge_sim_depth_train_sliding_off_train_noise_multiplier_1.0.pickle'"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(jupyter_dir, \"data\")\n",
    "if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
    "\n",
    "pickle_file = os.path.join(data_dir, sim_name + \"_\" + sim_eval_mode + \"_\" + model_name + \".pickle\")\n",
    "\n",
    "print(\"Model file: \" + model_path)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Pickle file: \" + pickle_file)\n",
    "print(\"\")\n",
    "\n",
    "stats_episodes = eval_model(model_path)\n",
    "\n",
    "print(\"Saving to: \" + pickle_file)\n",
    "print(\"\")\n",
    "with open(pickle_file, \"wb\") as p:\n",
    "    pickle.dump(stats_episodes, p)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8323013a-654e-4635-9866-036b88679b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/data/habitat_gibson_val_challenge_sim_depth_train_sliding_off_train_noise_multiplier_1.0.pickle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(jupyter_dir, \"data\")\n",
    "if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
    "\n",
    "pickle_file = os.path.join(data_dir, sim_name + \"_\" + sim_eval_mode + \"_\" + model_name + \".pickle\")\n",
    "\n",
    "print(\"Saving to: \" + pickle_file)\n",
    "print(\"\")\n",
    "with open(pickle_file, \"wb\") as p:\n",
    "    pickle.dump(stats_episodes, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c0b8d9-826a-48b0-a9f8-b02af6c7d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688128772635815\n",
      "963\n",
      "994\n",
      "0.9075804776739356\n",
      "0.7647743309741751\n"
     ]
    }
   ],
   "source": [
    "valid = np.array([ np.isfinite(s[1][\"distance_to_goal\"]) for s in stats_episodes.items() ])\n",
    "\n",
    "print(np.count_nonzero(valid) / valid.shape[0])\n",
    "print(np.count_nonzero(valid))\n",
    "print(valid.shape[0])\n",
    "\n",
    "success = np.array([ s[1][\"success\"] for s in stats_episodes.items() ])\n",
    "spl = np.array([ s[1][\"spl\"] for s in stats_episodes.items() ])\n",
    "\n",
    "success = success[valid]\n",
    "spl = spl[valid]\n",
    "\n",
    "print(np.mean(success))\n",
    "print(np.mean(spl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
