{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2651cff-fc55-484f-8c1b-f5bb9183afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a2784d-6a54-43be-a957-2920bfc81778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "\n",
    "from habitat.config import Config as CN\n",
    "from habitat.utils.visualizations.utils import images_to_video, observations_to_image\n",
    "\n",
    "from habitat_baselines.common.baseline_registry import baseline_registry\n",
    "from habitat_baselines.common.environments import get_env_class, NavRLEnv\n",
    "from habitat_baselines.config.default import get_config\n",
    "from habitat_baselines.utils.common import batch_obs, generate_video\n",
    "from habitat_baselines.utils.env_utils import construct_envs\n",
    "\n",
    "from my_habitat_baselines.resnet_policy import PointNavResNetPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bb63ca-9eb0-492b-81d2-cc1c7aafbc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jupyter_dir = \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter\"\n",
    "\n",
    "jupyter_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41618d93-9236-4fdf-876a-2f5281cd2599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--model-path /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models\n",
      "--sensors RGB_SENSOR\n",
      "--hidden-size 512\n",
      "--normalize-visual-inputs 1\n",
      "--backbone resnet50\n",
      "--num-recurrent-layers 2\n",
      "TEST_EPISODE_COUNT 5\n",
      "TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER Proportional\n",
      "TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER 0.5\n",
      "TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV 45\n",
      "TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV 45\n",
      "TASK_CONFIG.SIMULATOR.TURN_ANGLE 30\n",
      "TASK_CONFIG.SIMULATOR.AGENT_0.RADIUS 0.20\n",
      "TASK_CONFIG.DATASET.DATA_PATH obstacle_1/{split}/{split}.json.gz\n",
      "TASK_CONFIG.DATASET.SPLIT minival\n",
      "TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY False\n",
      "TASK_CONFIG.SIMULATOR.RGB_SENSOR.POSITION [0,0.6096,0]\n",
      "TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.POSITION [0,0.6096,0]\n",
      "VIDEO_OPTION ['disk']\n",
      "TASK_CONFIG.TASK.TOP_DOWN_MAP.MAP_RESOLUTION 5000\n",
      "\n",
      "Namespace(backbone='resnet50', hidden_size=512, model_path='/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models', normalize_visual_inputs=1, num_recurrent_layers=2, opts=['TEST_EPISODE_COUNT', '5', 'TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER', 'Proportional', 'TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER', '0.5', 'TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV', '45', 'TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV', '45', 'TASK_CONFIG.SIMULATOR.TURN_ANGLE', '30', 'TASK_CONFIG.SIMULATOR.AGENT_0.RADIUS', '0.20', 'TASK_CONFIG.DATASET.DATA_PATH', 'obstacle_1/{split}/{split}.json.gz', 'TASK_CONFIG.DATASET.SPLIT', 'minival', 'TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY', 'False', 'TASK_CONFIG.SIMULATOR.RGB_SENSOR.POSITION', '[0,0.6096,0]', 'TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.POSITION', '[0,0.6096,0]', 'VIDEO_OPTION', \"['disk']\", 'TASK_CONFIG.TASK.TOP_DOWN_MAP.MAP_RESOLUTION', '5000'], sensors='RGB_SENSOR')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# specify args\n",
    "#\n",
    "\n",
    "model_path = \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models\"\n",
    "\n",
    "arg_string = \"\"\n",
    "\n",
    "arg_string += \"--model-path %s\" % model_path\n",
    "\n",
    "arg_string += \\\n",
    "\"\"\"\n",
    "--sensors RGB_SENSOR\n",
    "--hidden-size 512\n",
    "--normalize-visual-inputs 1\n",
    "--backbone resnet50\n",
    "--num-recurrent-layers 2\n",
    "TEST_EPISODE_COUNT 5\n",
    "TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER Proportional\n",
    "TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER 0.5\n",
    "TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV 45\n",
    "TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV 45\n",
    "TASK_CONFIG.SIMULATOR.TURN_ANGLE 30\n",
    "TASK_CONFIG.SIMULATOR.AGENT_0.RADIUS 0.20\n",
    "TASK_CONFIG.DATASET.DATA_PATH obstacle_1/{split}/{split}.json.gz\n",
    "TASK_CONFIG.DATASET.SPLIT minival\n",
    "TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY False\n",
    "TASK_CONFIG.SIMULATOR.RGB_SENSOR.POSITION [0,0.6096,0]\n",
    "TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.POSITION [0,0.6096,0]\n",
    "VIDEO_OPTION ['disk']\n",
    "TASK_CONFIG.TASK.TOP_DOWN_MAP.MAP_RESOLUTION 5000\n",
    "\"\"\"\n",
    "\n",
    "print(arg_string)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model-path\", type=str, required=True)\n",
    "parser.add_argument(\"--sensors\", type=str, required=True)\n",
    "parser.add_argument(\"--hidden-size\", type=int, required=True)\n",
    "parser.add_argument(\n",
    "    \"--normalize-visual-inputs\", type=int, required=True, choices=[0, 1]\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--backbone\",\n",
    "    type=str,\n",
    "    required=True,\n",
    "    choices=[\"resnet50\", \"se_resneXt50\"],\n",
    ")\n",
    "parser.add_argument(\"--num-recurrent-layers\", type=int, required=True)\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    "    help=\"Modify config options from command line\",\n",
    ")\n",
    "args = parser.parse_args(arg_string.split())\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef3a949-a4c3-49ba-b2a6-f6612e4faf06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_TASK_CONFIG_PATH: configs/tasks/pointnav_gibson.yaml\n",
      "CHECKPOINT_FOLDER: data/new_checkpoints\n",
      "CHECKPOINT_INTERVAL: -1\n",
      "CMD_TRAILING_OPTS: []\n",
      "ENV_NAME: NavRLEnv\n",
      "EVAL:\n",
      "  SPLIT: val\n",
      "  USE_CKPT_CONFIG: True\n",
      "EVAL_CKPT_PATH_DIR: data/new_checkpoints\n",
      "FORCE_BLIND_POLICY: False\n",
      "FORCE_TORCH_SINGLE_THREADED: True\n",
      "LOG_FILE: train.log\n",
      "LOG_INTERVAL: 25\n",
      "NUM_CHECKPOINTS: 100\n",
      "NUM_ENVIRONMENTS: 1\n",
      "NUM_PROCESSES: -1\n",
      "NUM_UPDATES: 10000\n",
      "ORBSLAM2:\n",
      "  ANGLE_TH: 0.2617993877991494\n",
      "  BETA: 100\n",
      "  CAMERA_HEIGHT: 1.25\n",
      "  DEPTH_DENORM: 10.0\n",
      "  DIST_REACHED_TH: 0.15\n",
      "  DIST_TO_STOP: 0.05\n",
      "  D_OBSTACLE_MAX: 4.0\n",
      "  D_OBSTACLE_MIN: 0.1\n",
      "  H_OBSTACLE_MAX: 1.25\n",
      "  H_OBSTACLE_MIN: 0.375\n",
      "  MAP_CELL_SIZE: 0.1\n",
      "  MAP_SIZE: 40\n",
      "  MIN_PTS_IN_OBSTACLE: 320.0\n",
      "  NEXT_WAYPOINT_TH: 0.5\n",
      "  NUM_ACTIONS: 3\n",
      "  PLANNER_MAX_STEPS: 500\n",
      "  PREPROCESS_MAP: True\n",
      "  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml\n",
      "  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt\n",
      "PROFILING:\n",
      "  CAPTURE_START_STEP: -1\n",
      "  NUM_STEPS_TO_CAPTURE: -1\n",
      "RL:\n",
      "  DDPPO:\n",
      "    backbone: resnet18\n",
      "    distrib_backend: GLOO\n",
      "    force_distributed: False\n",
      "    num_recurrent_layers: 1\n",
      "    pretrained: False\n",
      "    pretrained_encoder: False\n",
      "    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth\n",
      "    reset_critic: True\n",
      "    rnn_type: GRU\n",
      "    sync_frac: 0.6\n",
      "    train_encoder: True\n",
      "  POLICY:\n",
      "    ACTION_DIST:\n",
      "      action_activation: tanh\n",
      "      max_log_std: 2\n",
      "      max_std: 1\n",
      "      min_log_std: -5\n",
      "      min_std: 1e-06\n",
      "      use_log_std: False\n",
      "      use_softplus: False\n",
      "    OBS_TRANSFORMS:\n",
      "      CENTER_CROPPER:\n",
      "        HEIGHT: 256\n",
      "        WIDTH: 256\n",
      "      CUBE2EQ:\n",
      "        HEIGHT: 256\n",
      "        SENSOR_UUIDS: []\n",
      "        WIDTH: 512\n",
      "      CUBE2FISH:\n",
      "        FOV: 180\n",
      "        HEIGHT: 256\n",
      "        PARAMS: (0.2, 0.2, 0.2)\n",
      "        SENSOR_UUIDS: []\n",
      "        WIDTH: 256\n",
      "      ENABLED_TRANSFORMS: ()\n",
      "      EQ2CUBE:\n",
      "        HEIGHT: 256\n",
      "        SENSOR_UUIDS: []\n",
      "        WIDTH: 256\n",
      "      RESIZE_SHORTEST_EDGE:\n",
      "        SIZE: 256\n",
      "    action_distribution_type: categorical\n",
      "    name: PointNavResNetPolicy\n",
      "  PPO:\n",
      "    clip_param: 0.2\n",
      "    entropy_coef: 0.01\n",
      "    eps: 1e-05\n",
      "    gamma: 0.99\n",
      "    hidden_size: 512\n",
      "    lr: 0.00025\n",
      "    max_grad_norm: 0.5\n",
      "    num_mini_batch: 2\n",
      "    num_steps: 128\n",
      "    ppo_epoch: 4\n",
      "    reward_window_size: 50\n",
      "    tau: 0.95\n",
      "    use_double_buffered_sampler: False\n",
      "    use_gae: True\n",
      "    use_linear_clip_decay: True\n",
      "    use_linear_lr_decay: True\n",
      "    use_normalized_advantage: False\n",
      "    value_loss_coef: 0.5\n",
      "  REWARD_MEASURE: distance_to_goal\n",
      "  SLACK_REWARD: -0.01\n",
      "  SUCCESS_MEASURE: spl\n",
      "  SUCCESS_REWARD: 2.5\n",
      "  preemption:\n",
      "    append_slurm_job_id: False\n",
      "    save_resume_state_interval: 100\n",
      "    save_state_batch_only: False\n",
      "SENSORS: ['RGB_SENSOR']\n",
      "SIMULATOR_GPU_ID: 0\n",
      "TASK_CONFIG:\n",
      "  DATASET:\n",
      "    CONTENT_SCENES: ['*']\n",
      "    DATA_PATH: data/datasets/pointnav/gibson/v2/val/val.json.gz\n",
      "    SCENES_DIR: data/scene_datasets\n",
      "    SPLIT: minival\n",
      "    TYPE: PointNav-v1\n",
      "  ENVIRONMENT:\n",
      "    GENERATE_ON_FLY: False\n",
      "    ITERATOR_OPTIONS:\n",
      "      CYCLE: True\n",
      "      GROUP_BY_SCENE: True\n",
      "      MAX_SCENE_REPEAT_EPISODES: -1\n",
      "      MAX_SCENE_REPEAT_STEPS: 10000\n",
      "      NUM_EPISODE_SAMPLE: -1\n",
      "      SHUFFLE: False\n",
      "      STEP_REPETITION_RANGE: 0.2\n",
      "    MAX_EPISODE_SECONDS: 10000000\n",
      "    MAX_EPISODE_STEPS: 500\n",
      "  PYROBOT:\n",
      "    BASE_CONTROLLER: proportional\n",
      "    BASE_PLANNER: none\n",
      "    BUMP_SENSOR:\n",
      "      TYPE: PyRobotBumpSensor\n",
      "    DEPTH_SENSOR:\n",
      "      CENTER_CROP: False\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 5.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      TYPE: PyRobotDepthSensor\n",
      "      WIDTH: 640\n",
      "    LOCOBOT:\n",
      "      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']\n",
      "      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']\n",
      "      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']\n",
      "    RGB_SENSOR:\n",
      "      CENTER_CROP: False\n",
      "      HEIGHT: 480\n",
      "      TYPE: PyRobotRGBSensor\n",
      "      WIDTH: 640\n",
      "    ROBOT: locobot\n",
      "    ROBOTS: ['locobot']\n",
      "    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']\n",
      "  SEED: 100\n",
      "  SIMULATOR:\n",
      "    ACTION_SPACE_CONFIG: v0\n",
      "    AGENTS: ['AGENT_0']\n",
      "    AGENT_0:\n",
      "      HEIGHT: 1.5\n",
      "      IS_SET_START_STATE: False\n",
      "      RADIUS: 0.2\n",
      "      SENSORS: ['RGB_SENSOR']\n",
      "      START_POSITION: [0, 0, 0]\n",
      "      START_ROTATION: [0, 0, 0, 1]\n",
      "    ARM_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      UUID: robot_arm_depth\n",
      "      WIDTH: 640\n",
      "    ARM_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      UUID: robot_arm_rgb\n",
      "      WIDTH: 640\n",
      "    DEFAULT_AGENT_ID: 0\n",
      "    DEPTH_SENSOR:\n",
      "      HEIGHT: 256\n",
      "      HFOV: 45\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 0.6096, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      WIDTH: 256\n",
      "    EQUIRECT_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      TYPE: HabitatSimEquirectangularDepthSensor\n",
      "      WIDTH: 640\n",
      "    EQUIRECT_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      TYPE: HabitatSimEquirectangularRGBSensor\n",
      "      WIDTH: 640\n",
      "    EQUIRECT_SEMANTIC_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      TYPE: HabitatSimEquirectangularSemanticSensor\n",
      "      WIDTH: 640\n",
      "    FISHEYE_DEPTH_SENSOR:\n",
      "      ALPHA: 0.57\n",
      "      FOCAL_LENGTH: [364.84, 364.86]\n",
      "      HEIGHT: 480\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      PRINCIPAL_POINT_OFFSET: None\n",
      "      SENSOR_MODEL_TYPE: DOUBLE_SPHERE\n",
      "      TYPE: HabitatSimFisheyeDepthSensor\n",
      "      WIDTH: 640\n",
      "      XI: -0.27\n",
      "    FISHEYE_RGB_SENSOR:\n",
      "      ALPHA: 0.57\n",
      "      FOCAL_LENGTH: [364.84, 364.86]\n",
      "      HEIGHT: 640\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      PRINCIPAL_POINT_OFFSET: None\n",
      "      SENSOR_MODEL_TYPE: DOUBLE_SPHERE\n",
      "      TYPE: HabitatSimFisheyeRGBSensor\n",
      "      WIDTH: 640\n",
      "      XI: -0.27\n",
      "    FISHEYE_SEMANTIC_SENSOR:\n",
      "      ALPHA: 0.57\n",
      "      FOCAL_LENGTH: [364.84, 364.86]\n",
      "      HEIGHT: 640\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      PRINCIPAL_POINT_OFFSET: None\n",
      "      SENSOR_MODEL_TYPE: DOUBLE_SPHERE\n",
      "      TYPE: HabitatSimFisheyeSemanticSensor\n",
      "      WIDTH: 640\n",
      "      XI: -0.27\n",
      "    FORWARD_STEP_SIZE: 0.25\n",
      "    HABITAT_SIM_V0:\n",
      "      ALLOW_SLIDING: False\n",
      "      ENABLE_PHYSICS: False\n",
      "      GPU_DEVICE_ID: 0\n",
      "      GPU_GPU: False\n",
      "      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json\n",
      "    HEAD_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      UUID: robot_head_depth\n",
      "      WIDTH: 640\n",
      "    HEAD_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      UUID: robot_head_rgb\n",
      "      WIDTH: 640\n",
      "    NOISE_MODEL:\n",
      "      CONTROLLER: Proportional\n",
      "      NOISE_MULTIPLIER: 0.5\n",
      "    RGB_SENSOR:\n",
      "      HEIGHT: 256\n",
      "      HFOV: 45\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 0.6096, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      WIDTH: 256\n",
      "    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb\n",
      "    SEED: 100\n",
      "    SEMANTIC_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimSemanticSensor\n",
      "      WIDTH: 640\n",
      "    THIRD_DEPTH_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      MAX_DEPTH: 10.0\n",
      "      MIN_DEPTH: 0.0\n",
      "      NORMALIZE_DEPTH: True\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimDepthSensor\n",
      "      UUID: robot_third_rgb\n",
      "      WIDTH: 640\n",
      "    THIRD_RGB_SENSOR:\n",
      "      HEIGHT: 480\n",
      "      HFOV: 90\n",
      "      ORIENTATION: [0.0, 0.0, 0.0]\n",
      "      POSITION: [0, 1.25, 0]\n",
      "      SENSOR_SUBTYPE: PINHOLE\n",
      "      TYPE: HabitatSimRGBSensor\n",
      "      UUID: robot_third_rgb\n",
      "      WIDTH: 640\n",
      "    TILT_ANGLE: 15\n",
      "    TURN_ANGLE: 30\n",
      "    TYPE: Sim-v0\n",
      "  TASK:\n",
      "    ACTIONS:\n",
      "      ANSWER:\n",
      "        TYPE: AnswerAction\n",
      "      LOOK_DOWN:\n",
      "        TYPE: LookDownAction\n",
      "      LOOK_UP:\n",
      "        TYPE: LookUpAction\n",
      "      MOVE_FORWARD:\n",
      "        TYPE: MoveForwardAction\n",
      "      STOP:\n",
      "        TYPE: StopAction\n",
      "      TELEPORT:\n",
      "        TYPE: TeleportAction\n",
      "      TURN_LEFT:\n",
      "        TYPE: TurnLeftAction\n",
      "      TURN_RIGHT:\n",
      "        TYPE: TurnRightAction\n",
      "      VELOCITY_CONTROL:\n",
      "        ANG_VEL_RANGE: [-10.0, 10.0]\n",
      "        LIN_VEL_RANGE: [0.0, 0.25]\n",
      "        MIN_ABS_ANG_SPEED: 1.0\n",
      "        MIN_ABS_LIN_SPEED: 0.025\n",
      "        TIME_STEP: 1.0\n",
      "        TYPE: VelocityAction\n",
      "    ANSWER_ACCURACY:\n",
      "      TYPE: AnswerAccuracy\n",
      "    COLLISIONS:\n",
      "      TYPE: Collisions\n",
      "    COMPASS_SENSOR:\n",
      "      TYPE: CompassSensor\n",
      "    CORRECT_ANSWER:\n",
      "      TYPE: CorrectAnswer\n",
      "    DISTANCE_TO_GOAL:\n",
      "      DISTANCE_TO: POINT\n",
      "      TYPE: DistanceToGoal\n",
      "    EPISODE_INFO:\n",
      "      TYPE: EpisodeInfo\n",
      "    GOAL_SENSOR_UUID: pointgoal_with_gps_compass\n",
      "    GPS_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      TYPE: GPSSensor\n",
      "    HEADING_SENSOR:\n",
      "      TYPE: HeadingSensor\n",
      "    IMAGEGOAL_SENSOR:\n",
      "      TYPE: ImageGoalSensor\n",
      "    INSTRUCTION_SENSOR:\n",
      "      TYPE: InstructionSensor\n",
      "    INSTRUCTION_SENSOR_UUID: instruction\n",
      "    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL']\n",
      "    OBJECTGOAL_SENSOR:\n",
      "      GOAL_SPEC: TASK_CATEGORY_ID\n",
      "      GOAL_SPEC_MAX_VAL: 50\n",
      "      TYPE: ObjectGoalSensor\n",
      "    POINTGOAL_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      GOAL_FORMAT: POLAR\n",
      "      TYPE: PointGoalSensor\n",
      "    POINTGOAL_WITH_GPS_COMPASS_SENSOR:\n",
      "      DIMENSIONALITY: 2\n",
      "      GOAL_FORMAT: POLAR\n",
      "      TYPE: PointGoalWithGPSCompassSensor\n",
      "    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT']\n",
      "    PROXIMITY_SENSOR:\n",
      "      MAX_DETECTION_RADIUS: 2.0\n",
      "      TYPE: ProximitySensor\n",
      "    QUESTION_SENSOR:\n",
      "      TYPE: QuestionSensor\n",
      "    SENSORS: ['POINTGOAL_WITH_GPS_COMPASS_SENSOR']\n",
      "    SOFT_SPL:\n",
      "      TYPE: SoftSPL\n",
      "    SPL:\n",
      "      TYPE: SPL\n",
      "    SUCCESS:\n",
      "      SUCCESS_DISTANCE: 0.2\n",
      "      TYPE: Success\n",
      "    SUCCESS_DISTANCE: 0.2\n",
      "    TOP_DOWN_MAP:\n",
      "      DRAW_BORDER: True\n",
      "      DRAW_GOAL_AABBS: True\n",
      "      DRAW_GOAL_POSITIONS: True\n",
      "      DRAW_SHORTEST_PATH: True\n",
      "      DRAW_SOURCE: True\n",
      "      DRAW_VIEW_POINTS: True\n",
      "      FOG_OF_WAR:\n",
      "        DRAW: True\n",
      "        FOV: 90\n",
      "        VISIBILITY_DIST: 5.0\n",
      "      MAP_PADDING: 3\n",
      "      MAP_RESOLUTION: 5000\n",
      "      MAX_EPISODE_STEPS: 1000\n",
      "      TYPE: TopDownMap\n",
      "    TYPE: Nav-v0\n",
      "TENSORBOARD_DIR: tb\n",
      "TEST_EPISODE_COUNT: 5\n",
      "TORCH_GPU_ID: 0\n",
      "TOTAL_NUM_STEPS: 75000000.0\n",
      "TRAINER_NAME: ppo\n",
      "VERBOSE: False\n",
      "VIDEO_DIR: video_dir\n",
      "VIDEO_OPTION: ['disk']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load and customize config\n",
    "#\n",
    "\n",
    "habitat_dir = \"/Users/mroberts/code/github/habitat-lab\"\n",
    "os.chdir(habitat_dir)\n",
    "\n",
    "config = get_config(\n",
    "    \"habitat_baselines/config/pointnav/ppo_pointnav.yaml\"\n",
    ")\n",
    "\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.SIMULATOR.NOISE_MODEL = CN()\n",
    "config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER = None\n",
    "config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER = None\n",
    "config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV = None\n",
    "config.TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.HFOV = None\n",
    "config.TASK_CONFIG.ENVIRONMENT.GENERATE_ON_FLY = None\n",
    "config.freeze()\n",
    "\n",
    "config.merge_from_list(args.opts)\n",
    "\n",
    "# config.defrost()\n",
    "# config.TASK_CONFIG.SIMULATOR.ACTION_SPACE_CONFIG = \"pyrobotnoisy\"\n",
    "# config.freeze()\n",
    "\n",
    "# config.defrost()\n",
    "# config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.ROBOT = \"LoCoBot\"\n",
    "# config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.CONTROLLER = \"ILQR\"    # our pre-trained model lists \"proportional\" in the filename, so don't change to ILQR \n",
    "# config.TASK_CONFIG.SIMULATOR.NOISE_MODEL.NOISE_MULTIPLIER = 1.0 # our pre-trained model lists \"0.5\" in the filename, so don't change to 1.0\n",
    "# config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.ENVIRONMENT.ITERATOR_OPTIONS.SHUFFLE = False\n",
    "config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.SIMULATOR.HABITAT_SIM_V0.ALLOW_SLIDING = False\n",
    "config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "config.TASK_CONFIG.DATASET.CONTENT_SCENES = [\"*\"]\n",
    "config.TASK_CONFIG.DATASET.DATA_PATH = \"data/datasets/pointnav/gibson/v2/val/val.json.gz\" # don't have obstacle_1 scenes, so use Gibson instead\n",
    "config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "config.NUM_ENVIRONMENTS = 1\n",
    "config.freeze()\n",
    "\n",
    "config.defrost()\n",
    "if args.sensors == \"\":\n",
    "    config.SENSORS = []\n",
    "else:\n",
    "    config.SENSORS = args.sensors.split(\",\")\n",
    "# TODO(akadian): collisions are not working\n",
    "# config.TASK_CONFIG.TASK.MEASUREMENTS.append(\"COLLISIONS\")\n",
    "config.freeze()\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a2b3d44-4712-4361-a385-79deed72992d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# create device\n",
    "#\n",
    "\n",
    "device = (\n",
    "    torch.device(\"cuda:{}\".format(config.TORCH_GPU_ID))\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00c2c16-5c9a-46c4-9e6d-99e9a287d815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 20:04:32,473 Initializing dataset PointNav-v1\n",
      "2021-11-17 20:04:32,493 initializing sim Sim-v0\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I1117 20:04:36.979046 12177 simulator.py:221] Loaded navmesh data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1117 20:04:32.496129 63790528 ManagedFileBasedContainer.h:210] <Dataset>::convertFilenameToPassedExt : Filename : default changed to proposed scene_dataset_config.json filename : default.scene_dataset_config.json\n",
      "I1117 20:04:32.496166 63790528 AttributesManagerBase.h:365] <Dataset>::createFromJsonOrDefaultInternal : Proposing JSON name : default.scene_dataset_config.json from original name : default | This file  does not exist.\n",
      "I1117 20:04:32.496249 63790528 AssetAttributesManager.cpp:120] Asset attributes (capsule3DSolid : capsule3DSolid_hemiRings_4_cylRings_1_segments_12_halfLen_0.75_useTexCoords_false_useTangents_false) created and registered.\n",
      "I1117 20:04:32.496290 63790528 AssetAttributesManager.cpp:120] Asset attributes (capsule3DWireframe : capsule3DWireframe_hemiRings_8_cylRings_1_segments_16_halfLen_1) created and registered.\n",
      "I1117 20:04:32.496325 63790528 AssetAttributesManager.cpp:120] Asset attributes (coneSolid : coneSolid_segments_12_halfLen_1.25_rings_1_useTexCoords_false_useTangents_false_capEnd_true) created and registered.\n",
      "I1117 20:04:32.496346 63790528 AssetAttributesManager.cpp:120] Asset attributes (coneWireframe : coneWireframe_segments_32_halfLen_1.25) created and registered.\n",
      "I1117 20:04:32.496358 63790528 AssetAttributesManager.cpp:120] Asset attributes (cubeSolid : cubeSolid) created and registered.\n",
      "I1117 20:04:32.496367 63790528 AssetAttributesManager.cpp:120] Asset attributes (cubeWireframe : cubeWireframe) created and registered.\n",
      "I1117 20:04:32.496394 63790528 AssetAttributesManager.cpp:120] Asset attributes (cylinderSolid : cylinderSolid_rings_1_segments_12_halfLen_1_useTexCoords_false_useTangents_false_capEnds_true) created and registered.\n",
      "I1117 20:04:32.496416 63790528 AssetAttributesManager.cpp:120] Asset attributes (cylinderWireframe : cylinderWireframe_rings_1_segments_32_halfLen_1) created and registered.\n",
      "I1117 20:04:32.496430 63790528 AssetAttributesManager.cpp:120] Asset attributes (icosphereSolid : icosphereSolid_subdivs_1) created and registered.\n",
      "I1117 20:04:32.496443 63790528 AssetAttributesManager.cpp:120] Asset attributes (icosphereWireframe : icosphereWireframe_subdivs_1) created and registered.\n",
      "I1117 20:04:32.496464 63790528 AssetAttributesManager.cpp:120] Asset attributes (uvSphereSolid : uvSphereSolid_rings_8_segments_16_useTexCoords_false_useTangents_false) created and registered.\n",
      "I1117 20:04:32.496480 63790528 AssetAttributesManager.cpp:120] Asset attributes (uvSphereWireframe : uvSphereWireframe_rings_16_segments_32) created and registered.\n",
      "I1117 20:04:32.496488 63790528 AssetAttributesManager.cpp:108] ::constructor : Built default primitive asset templates : 12\n",
      "I1117 20:04:32.496887 63790528 SceneDatasetAttributesManager.cpp:36] File (default) not found, so new default dataset attributes created and registered.\n",
      "I1117 20:04:32.496893 63790528 MetadataMediator.cpp:127] ::createSceneDataset : Dataset default successfully created.\n",
      "I1117 20:04:32.496906 63790528 AttributesManagerBase.h:365] <Physics MaI1117 20:04:36.979830 12177 simulator.py:233] Recomputing navmesh for agent's height 1.5 and radius 0.2.\n",
      "nager>::createFromJsonOrDefaultInternal : Proposing JSON name : ./data/default.physics_config.json from original name : ./data/default.physics_config.json | This file  does not exist.\n",
      "I1117 20:04:32.496922 63790528 PhysicsAttributesManager.cpp:26] File (./data/default.physics_config.json) not found, so new default physics manager attributes created and registered.\n",
      "I1117 20:04:32.496928 63790528 MetadataMediator.cpp:212] ::setActiveSceneDatasetName : Previous active dataset  changed to default successfully.\n",
      "I1117 20:04:32.496932 63790528 MetadataMediator.cpp:183] ::setCurrPhysicsAttributesHandle : Old physics manager attributes  changed to ./data/default.physics_config.json successfully.\n",
      "I1117 20:04:32.496937 63790528 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Cantwell.glb and dataset : default which is currently active dataset.\n",
      "I1117 20:04:32.570899 63790528 ManagedFileBasedContainer.h:210] <Scene Instance>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Cantwell.glb changed to proposed scene_instance.json filename : data/scene_datasets/gibson/Cantwell.scene_instance.json\n",
      "I1117 20:04:32.570920 63790528 MetadataMediator.cpp:311] ::getSceneAttributesByName : Dataset : default has no preloaded SceneAttributes or StageAttributes named : data/scene_datasets/gibson/Cantwell.glb so loading/creating a new StageAttributes with this name, and then creating a SceneAttributes with the same name that references this stage.\n",
      "I1117 20:04:32.570930 63790528 ManagedFileBasedContainer.h:210] <Stage Template>::convertFilenameToPassedExt : Filename : data/scene_datasets/gibson/Cantwell.glb changed to proposed stage_config.json filename : data/scene_datasets/gibson/Cantwell.stage_config.json\n",
      "I1117 20:04:32.570936 63790528 AttributesManagerBase.h:365] <Stage Template>::createFromJsonOrDefaultInternal : Proposing JSON name : data/scene_datasets/gibson/Cantwell.stage_config.json from original name : data/scene_datasets/gibson/Cantwell.glb | This file  does not exist.\n",
      "I1117 20:04:32.570999 63790528 AbstractObjectAttributesManagerBase.h:183] File (data/scene_datasets/gibson/Cantwell.glb) exists but is not a recognized config filename extension, so new default Stage Template attributes created and registered.\n",
      "I1117 20:04:32.571056 63790528 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1117 20:04:32.571090 63790528 SceneDatasetAttributes.cpp:79] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes 'no_lights' specified in Scene Attributes but does not exist in dataset, so creating.\n",
      "I1117 20:04:32.571099 63790528 ManagedFileBasedContainer.h:210] <Lighting Layout>::convertFilenameToPassedExt : Filename : no_lights changed to proposed lighting_config.json filename : no_lights.lighting_config.json\n",
      "I1117 20:04:32.571105 63790528 ManagedFileBasedContainer.h:210] <Lighting Layout>::convertFilenameToPassedExt : Filename : no_lights changed to proposed lighting_config.json filename : no_lights.lighting_config.json\n",
      "I1117 20:04:32.571108 63790528 AttributesManagerBase.h:365] <Lighting Layout>::createFromJsonOrDefaultInternal : Proposing JSON name : no_lights.lighting_config.json from original name : no_lights | This file  does not exist.\n",
      "I1117 20:04:32.571128 63790528 LightLayoutAttributesManager.cpp:34] File (no_lights) not found, so new default light layout attributes created and registered.\n",
      "I1117 20:04:32.571158 63790528 Simulator.cpp:198] ::setSceneInstanceAttributes : Navmesh file location in scene instance : data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1117 20:04:32.571167 63790528 Simulator.cpp:205] ::setSceneInstanceAttributes : Loading navmesh from data/scene_datasets/gibson/Cantwell.navmesh\n",
      "I1117 20:04:32.571435 63790528 Simulator.cpp:208] ::setSceneInstanceAttributes : Navmesh Loaded.\n",
      "I1117 20:04:32.571453 63790528 SceneGraph.h:85] Created DrawableGroup: \n",
      "I1117 20:04:32.571461 63790528 Simulator.cpp:243] ::setSceneInstanceAttributes : SceneInstance : data/scene_datasets/gibson/Cantwell.glb proposed Semantic Scene Descriptor filename : data/scene_datasets/gibson/Cantwell.scn\n",
      "E1117 20:04:32.571472 63790528 SemanticScene.h:155] ::loadSemanticSceneDescriptor : File data/scene_datasets/gibson/Cantwell.scn does not exist.  Aborting load.\n",
      "W1117 20:04:32.571482 63790528 Simulator.cpp:267] ::setSceneInstanceAttributes : All attempts to load SSD with SceneAttributes-provided name data/scene_datasets/gibson/Cantwell.scn : exist : 0 : loaded as expected type : 0\n",
      "I1117 20:04:32.571575 63790528 Simulator.cpp:316] ::createSceneInstance : Using scene instance-specified Light key : -no_lights-\n",
      "I1117 20:04:32.571583 63790528 MetadataMediator.cpp:68] ::setSimulatorConfiguration : Set new simulator config for scene/stage : data/scene_datasets/gibson/Cantwell.glb and dataset : default which is currently active dataset.\n",
      "I1117 20:04:32.571602 63790528 Simulator.cpp:374] ::createSceneInstance : Start to load stage named : data/scene_datasets/gibson/Cantwell.glb with render asset : data/scene_datasets/gibson/Cantwell.glb and collision asset : data/scene_datasets/gibson/Cantwell.glb\n",
      "I1117 20:04:32.571624 63790528 ResourceManager.cpp:249] ::loadStage : Not loading semantic mesh\n",
      "I1117 20:04:32.571630 63790528 ResourceManager.cpp:277] ::loadStage : start load render asset data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1117 20:04:32.571633 63790528 ResourceManager.cpp:691] ::loadStageInternal : Attempting to load stage data/scene_datasets/gibson/Cantwell.glb \n",
      "I1117 20:04:32.571655 63790528 ResourceManager.cpp:1281] Importing Basis files as BC3 for Cantwell.glb\n",
      "I1117 20:04:36.978017 63790528 Simulator.cpp:392] ::createSceneInstance : Successfully loaded stage named : data/scene_datasets/gibson/Cantwell.glb\n",
      "W1117 20:04:36.978035 63790528 Simulator.cpp:427] \n",
      "---\n",
      "Simulato2021-11-17 20:04:37,086 Initializing task Nav-v0\n",
      "r::createSceneInstance : The active scene does not contain semantic annotations. \n",
      "---\n",
      "I1117 20:04:36.978044 63790528 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantwell.glb yields 1 candidates.  Using data/scene_datasets/gibson/Cantwell.glb.\n",
      "I1117 20:04:36.978056 63790528 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1117 20:04:36.978060 63790528 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1117 20:04:36.978070 63790528 MetadataMediator.cpp:262] ::getSceneAttributesByName : Query dataset : default for SceneAttributes named : data/scene_datasets/gibson/Cantwell.glb yields 1 candidates.  Using data/scene_datase"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer: AMD Radeon Pro 5500M OpenGL Engine by ATI Technologies Inc.\n",
      "OpenGL version: 4.1 ATI-3.10.22\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_ES2_compatibility\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_texture_storage\n",
      "    GL_EXT_texture_filter_anisotropic\n",
      "    GL_EXT_debug_label\n",
      "    GL_EXT_debug_marker\n",
      "Using driver workarounds:\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    apple-buffer-texture-unbind-on-buffer-modify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ts/gibson/Cantwell.glb.\n",
      "I1117 20:04:36.978076 63790528 SceneDatasetAttributes.cpp:45] ::addNewSceneInstanceToDataset : Dataset : 'default' : Stage Attributes 'data/scene_datasets/gibson/Cantwell.glb' specified in Scene Attributes exists in dataset library.\n",
      "I1117 20:04:36.978080 63790528 SceneDatasetAttributes.cpp:85] ::addNewSceneInstanceToDataset : Dataset : 'default' : Lighting Layout Attributes no_lights specified in Scene Attributes exists in dataset library.\n",
      "I1117 20:04:36.978092 63790528 Simulator.cpp:171] ::reconfigure : createSceneInstance success == true for active scene name : data/scene_datasets/gibson/Cantwell.glb with renderer.\n",
      "I1117 20:04:36.992566 63790528 PathFinder.cpp:382] Building navmesh with 306x145 cells\n",
      "I1117 20:04:37.082011 63790528 PathFinder.cpp:652] Created navmesh with 199 vertices 94 polygons\n",
      "I1117 20:04:37.082381 63790528 Simulator.cpp:790] reconstruct navmesh successful\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# construct a single env instead of multiple envs for simplicity\n",
    "#\n",
    "\n",
    "env = NavRLEnv(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d445e114-c2d0-4713-9483-966dc75c62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/scene_datasets/gibson/Cantwell.glb 0\n",
      "data/scene_datasets/gibson/Cantwell.glb 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# get starting episode and scene so we can reset the environment's episode iterator\n",
    "#\n",
    "\n",
    "initial_episode_id = env.current_episode.episode_id\n",
    "initial_scene_id = env.current_episode.scene_id\n",
    "\n",
    "print(initial_scene_id, initial_episode_id)\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "print(env.current_episode.scene_id, env.current_episode.episode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc32b3ab-2370-4a99-a0ca-e39920b9203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load model\n",
    "#\n",
    "\n",
    "def load_model(\n",
    "    path,\n",
    "    observation_space,\n",
    "    action_space,\n",
    "    hidden_size,\n",
    "    normalize_visual_inputs,\n",
    "    backbone,\n",
    "    num_recurrent_layers,\n",
    "    device,\n",
    "):\n",
    "\n",
    "    model = PointNavResNetPolicy(\n",
    "        observation_space=observation_space,\n",
    "        action_space=action_space,\n",
    "        hidden_size=hidden_size,\n",
    "        normalize_visual_inputs=normalize_visual_inputs,\n",
    "        backbone=backbone,\n",
    "        num_recurrent_layers=num_recurrent_layers,\n",
    "        goal_sensor_uuid=\"pointgoal_with_gps_compass\",\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    saved_model = torch.load(path, map_location=device)\n",
    "    saved_model_state_dict = {}\n",
    "    for k, v in saved_model[\"state_dict\"].items():\n",
    "        new_k = k.replace(\"actor_critic.\", \"\")\n",
    "        saved_model_state_dict[new_k] = v\n",
    "\n",
    "    model.load_state_dict(saved_model_state_dict)\n",
    "\n",
    "    model_params = 0\n",
    "    for k,v in model.state_dict().items():\n",
    "        # print(k, torch.numel(v))\n",
    "        model_params += torch.numel(v)\n",
    "    print(model_params)\n",
    "\n",
    "    saved_model_params = 0\n",
    "    for k,v in saved_model[\"state_dict\"].items():\n",
    "        # print(k, torch.numel(v))\n",
    "        saved_model_params += torch.numel(v)\n",
    "    print(saved_model_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bad107-4828-4f2a-bb42-618a09361907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model_path, num_episodes=-1, max_num_actions_per_episode=10000):\n",
    "\n",
    "    global observation\n",
    "    \n",
    "    print(\"Resetting env to initial_episode_id and initial_scene_id...\")\n",
    "    print()\n",
    "\n",
    "    while env.current_episode.episode_id != initial_episode_id or env.current_episode.scene_id != initial_scene_id:\n",
    "        observation = env.reset()\n",
    "        \n",
    "    print()\n",
    "    print(env.current_episode.scene_id, env.current_episode.episode_id)\n",
    "    print()\n",
    "    \n",
    "    #\n",
    "    # load model\n",
    "    #\n",
    "    \n",
    "    model = load_model(\n",
    "        path=model_path,\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        hidden_size=args.hidden_size,\n",
    "        normalize_visual_inputs=bool(args.normalize_visual_inputs),\n",
    "        backbone=args.backbone,\n",
    "        num_recurrent_layers=args.num_recurrent_layers,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    #\n",
    "    # initialization before main loop\n",
    "    #\n",
    "\n",
    "    metric_name = config.TASK_CONFIG.TASK.MEASUREMENTS[0]\n",
    "    metric_cfg = getattr(config.TASK_CONFIG.TASK, metric_name)\n",
    "    measure_type = baseline_registry.get_measure(metric_cfg.TYPE)\n",
    "    metric_uuid = measure_type(None, None)._get_uuid()\n",
    "\n",
    "    assert measure_type is not None, \"invalid measurement type {}\".format(metric_cfg.TYPE)\n",
    "\n",
    "    print(metric_name)\n",
    "    print(metric_cfg)\n",
    "    print(measure_type)\n",
    "    print(metric_uuid)\n",
    "    print()\n",
    "\n",
    "    print(len(env.episodes))\n",
    "    print()\n",
    "\n",
    "    print(env.current_episode)\n",
    "    print()\n",
    "\n",
    "    print(env._env.get_metrics())\n",
    "    print()\n",
    "\n",
    "    observations = [observation]\n",
    "    batch = batch_obs(observations, device)\n",
    "\n",
    "    num_processes = 1\n",
    "\n",
    "    test_recurrent_hidden_states = torch.zeros(\n",
    "        model.net.num_recurrent_layers,\n",
    "        num_processes,\n",
    "        args.hidden_size,\n",
    "        device=device,\n",
    "    )\n",
    "    prev_actions = torch.zeros(\n",
    "        num_processes, 1, device=device, dtype=torch.long\n",
    "    )\n",
    "    not_done_masks = torch.zeros(num_processes, 1, device=device)\n",
    "    print(not_done_masks)\n",
    "\n",
    "    current_episode_num_actions = 0\n",
    "    current_episode_reward = 0.0\n",
    "    current_episode_stats_actions = defaultdict(int)\n",
    "\n",
    "    stats_episodes = dict()  # dict of dicts that stores stats per episode\n",
    "\n",
    "    #\n",
    "    # main loop\n",
    "    #\n",
    "\n",
    "    max_num_actions_per_episode = 10000\n",
    "    \n",
    "    if num_episodes == -1:\n",
    "        num_episodes = len(env.episodes)\n",
    "\n",
    "    while len(stats_episodes) < num_episodes:\n",
    "\n",
    "        #\n",
    "        # main loop: choose action\n",
    "        #\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, actions, _, test_recurrent_hidden_states = model.act(\n",
    "                batch,\n",
    "                test_recurrent_hidden_states,\n",
    "                prev_actions,\n",
    "                not_done_masks,\n",
    "                deterministic=False,\n",
    "            )\n",
    "\n",
    "            prev_actions.copy_(actions)\n",
    "\n",
    "        assert len(actions) == 1\n",
    "        action = actions[0]\n",
    "\n",
    "        # print(env.habitat_env.task.get_action_name(action.item()))\n",
    "\n",
    "        #\n",
    "        # main loop: perform action\n",
    "        #\n",
    "\n",
    "        observation, reward, done, info = env.step(action=action.item())\n",
    "\n",
    "        #\n",
    "        # main loop: update state\n",
    "        #\n",
    "\n",
    "        observations = [observation]\n",
    "        batch = batch_obs(observations, device)\n",
    "\n",
    "        dones = [done]\n",
    "        not_done_masks = torch.tensor(\n",
    "            [[0.0] if done else [1.0] for done in dones],\n",
    "            dtype=torch.float,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        current_episode_num_actions += 1\n",
    "        current_episode_reward += reward\n",
    "        current_episode_stats_actions[action.item()] += 1\n",
    "\n",
    "        assert current_episode_num_actions < max_num_actions_per_episode\n",
    "\n",
    "        if done:\n",
    "\n",
    "            # record stats\n",
    "            stats_episode = dict(info)\n",
    "            stats_episode[\"reward\"] = current_episode_reward\n",
    "            stats_episode[\"stats_actions\"] = dict(current_episode_stats_actions)\n",
    "\n",
    "            # if len(stats_episodes) % 100 == 0:\n",
    "            #     print(\"Episodes finished: {}\".format(len(stats_episodes)))\n",
    "\n",
    "            print(\"Episodes finished: {}\".format(len(stats_episodes)))\n",
    "            print(stats_episode)\n",
    "            print()\n",
    "            \n",
    "            stats_episodes[ (env.current_episode.scene_id, env.current_episode.episode_id) ] = stats_episode\n",
    "\n",
    "            # reset env\n",
    "            observation = env.reset()\n",
    "            observations = [observation]\n",
    "            batch = batch_obs(observations, device)\n",
    "\n",
    "            test_recurrent_hidden_states = torch.zeros(\n",
    "                model.net.num_recurrent_layers,\n",
    "                num_processes,\n",
    "                args.hidden_size,\n",
    "                device=device,\n",
    "            )\n",
    "            prev_actions = torch.zeros(\n",
    "                num_processes, 1, device=device, dtype=torch.long\n",
    "            )\n",
    "            not_done_masks = torch.zeros(num_processes, 1, device=device)\n",
    "\n",
    "            current_episode_num_actions = 0\n",
    "            current_episode_reward = 0.0\n",
    "            current_episode_stats_actions = defaultdict(int)\n",
    "            \n",
    "    return stats_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c9ff508-4383-4e7f-a109-be429cee5c74",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping model: rgb_train_sliding_off_noise_0.5\n",
      "\n",
      "Evaluating model: rgb_train_sliding_off_noise_0.0\n",
      "\n",
      "Resetting env to initial_episode_id and initial_scene_id...\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3n/1mkr33q53s53441zsn3079w00000gr/T/ipykernel_12177/3185643508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating model: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stats_episodes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skipping model: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3n/1mkr33q53s53441zsn3079w00000gr/T/ipykernel_12177/2249800798.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model_path, num_episodes, max_num_actions_per_episode)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_episode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minitial_episode_id\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_episode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscene_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minitial_scene_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat_baselines/common/environments.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_previous_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         self._previous_measure = self._env.get_metrics()[\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward_measure_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/srcc-env/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat/core/env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mprofiling_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRangeContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RLEnv.reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mObservations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_reward_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat/core/env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_episode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reset requires an episode\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat/core/env.py\u001b[0m in \u001b[0;36mreconfigure\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIMULATOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat/sims/habitat_simulator/habitat_simulator.py\u001b[0m in \u001b[0;36mreconfigure\u001b[0;34m(self, habitat_config)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_agents_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     def geodesic_distance(\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat/sims/habitat_simulator/habitat_simulator.py\u001b[0m in \u001b[0;36m_update_agents_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0magent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART_POSITION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0magent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART_ROTATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0magent_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 )\n\u001b[1;32m    367\u001b[0m                 \u001b[0mis_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/github/habitat-lab/habitat/sims/habitat_simulator/habitat_simulator.py\u001b[0m in \u001b[0;36mset_agent_state\u001b[0;34m(self, position, rotation, agent_id, reset_sensors)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0moriginal\u001b[0m \u001b[0mpose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mfalse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \"\"\"\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agent_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mnew_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/srcc-env/lib/python3.7/site-packages/habitat_sim/simulator.py\u001b[0m in \u001b[0;36mget_agent\u001b[0;34m(self, agent_id)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     def initialize_agent(\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# models_to_eval = {}\n",
    "\n",
    "model_name = \"rgb_train_sliding_off_noise_0.0\"\n",
    "model_path = \\\n",
    "\"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "\"job_19633792\"                        + \".\" \\\n",
    "\"sensor_RGB_SENSOR\"                   + \".\" \\\n",
    "\"train_data_gibson\"                   + \".\" \\\n",
    "\"noise_multiplier_0.0\"                + \".\" \\\n",
    "\"noise_model_controller_Proportional\" + \".\" \\\n",
    "\"agent_radius_0.20\"                   + \".\" \\\n",
    "\"success_reward_10.0\"                 + \".\" \\\n",
    "\"slack_reward_-0.01\"                  + \".\" \\\n",
    "\"collision_reward_0.0\"                + \".\" \\\n",
    "\"spl_max_collisions_500\"              + \"_\" \\\n",
    "\"ckpt.000000049\"                      + \\\n",
    "\".pth\"\n",
    "models_to_eval[model_name] = {\"model_path\" : model_path}\n",
    "\n",
    "# model_name = \"rgb_train_sliding_off_noise_0.5\"\n",
    "# model_path = \\\n",
    "# \"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "# \"job_19633792\"                        + \".\" \\\n",
    "# \"sensor_RGB_SENSOR\"                   + \".\" \\\n",
    "# \"train_data_gibson\"                   + \".\" \\\n",
    "# \"noise_multiplier_0.5\"                + \".\" \\\n",
    "# \"noise_model_controller_Proportional\" + \".\" \\\n",
    "# \"agent_radius_0.20\"                   + \".\" \\\n",
    "# \"success_reward_10.0\"                 + \".\" \\\n",
    "# \"slack_reward_-0.01\"                  + \".\" \\\n",
    "# \"collision_reward_0.0\"                + \".\" \\\n",
    "# \"spl_max_collisions_500\"              + \"_\" \\\n",
    "# \"ckpt.000000049\"                      + \\\n",
    "# \".pth\"\n",
    "# models_to_eval[model_name] = {\"model_path\" : model_path}\n",
    "\n",
    "model_name = \"rgb_train_sliding_off_noise_1.0\"\n",
    "model_path = \\\n",
    "\"/Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models/\" + \\\n",
    "\"job_19633792\"                        + \".\" \\\n",
    "\"sensor_RGB_SENSOR\"                   + \".\" \\\n",
    "\"train_data_gibson\"                   + \".\" \\\n",
    "\"noise_multiplier_1.0\"                + \".\" \\\n",
    "\"noise_model_controller_Proportional\" + \".\" \\\n",
    "\"agent_radius_0.20\"                   + \".\" \\\n",
    "\"success_reward_10.0\"                 + \".\" \\\n",
    "\"slack_reward_-0.01\"                  + \".\" \\\n",
    "\"collision_reward_0.0\"                + \".\" \\\n",
    "\"spl_max_collisions_500\"              + \"_\" \\\n",
    "\"ckpt.000000049\"                      + \\\n",
    "\".pth\"\n",
    "models_to_eval[model_name] = {\"model_path\" : model_path}\n",
    "\n",
    "for m in models_to_eval.items():\n",
    "    if \"stats_episodes\" not in m[1].keys():\n",
    "        print(\"Evaluating model: \" + m[0])\n",
    "        print(\"\")\n",
    "        m[1][\"stats_episodes\"] = eval_model(m[1][\"model_path\"])\n",
    "    else:\n",
    "        print(\"Skipping model: \" + m[0])\n",
    "        print(\"\")\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34b9a029-0f3c-466f-a263-646e86404075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models_to_eval.pickle\n",
      "\n",
      "Finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle_file = os.path.join(jupyter_dir, \"models_to_eval.pickle\")\n",
    "\n",
    "# print(\"Saving to \" + pickle_file)\n",
    "# print()\n",
    "\n",
    "# with open(pickle_file, \"wb\") as p:\n",
    "#     pickle.dump(models_to_eval, p)\n",
    "\n",
    "# print(\"Finished.\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "512106e2-5bf2-41c8-818b-ae1e7e693084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/mroberts/code/github/interiorsim/code/experiments/srcc/jupyter/models_to_eval.pickle\n",
      "\n",
      "Finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = os.path.join(jupyter_dir, \"models_to_eval.pickle\")\n",
    "\n",
    "print(\"Loading from \" + pickle_file)\n",
    "print()\n",
    "\n",
    "with open(pickle_file, \"rb\") as p:\n",
    "    models_to_eval = pickle.load(p)\n",
    "\n",
    "print(\"Finished.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3c0b8d9-826a-48b0-a9f8-b02af6c7d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688128772635815\n",
      "963\n",
      "994\n",
      "0.5244029075804777\n",
      "0.34438900960606356\n"
     ]
    }
   ],
   "source": [
    "stats_episodes = models_to_eval[\"rgb_train_sliding_off_noise_0.5\"][\"stats_episodes\"]\n",
    "\n",
    "valid = np.array([ np.isfinite(s[1][\"distance_to_goal\"]) for s in stats_episodes.items() ])\n",
    "\n",
    "print(np.count_nonzero(valid) / valid.shape[0])\n",
    "print(np.count_nonzero(valid))\n",
    "print(valid.shape[0])\n",
    "    \n",
    "success = np.array([ s[1][\"success\"] for s in stats_episodes.items() ])\n",
    "spl = np.array([ s[1][\"spl\"] for s in stats_episodes.items() ])\n",
    "\n",
    "success = success[valid]\n",
    "spl = spl[valid]\n",
    "\n",
    "print(np.mean(success))\n",
    "print(np.mean(spl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
